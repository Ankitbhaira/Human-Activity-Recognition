{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition Using Smartphone Dataset\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "This project is to build a model that predicts the human activities such as Walking, Walking_Upstairs, Walking_Downstairs, Sitting, Standing or Laying.\n",
    "\n",
    "This dataset is collected from 30 persons(referred as subjects in this dataset), performing different activities with a smartphone to their waists. The data is recorded with the help of sensors (accelerometer and Gyroscope) in that smartphone. This experiment was video recorded to label the data manually.\n",
    "\n",
    "By using the sensors(Gyroscope and accelerometer) in a smartphone, they have captured '3-axial linear acceleration'(_tAcc-XYZ_) from accelerometer and '3-axial angular velocity' (_tGyro-XYZ_) from Gyroscope with several variations. \n",
    "\n",
    "--prefix 't' in those metrics denotes time.\n",
    "--suffix 'XYZ' represents 3-axial signals in X , Y, and Z directions.\n",
    "\n",
    "### Feature names\n",
    "\n",
    "1. These sensor signals are preprocessed by applying noise filters and then sampled in fixed-width windows(sliding windows) of 2.56 seconds each with 50% overlap. ie., each window has 128 readings. \n",
    "\n",
    "2. From Each window, a feature vector was obtianed by calculating variables from the time and frequency domain.\n",
    "> In our dataset, each datapoint represents a window with different readings \n",
    "3. The accelertion signal was saperated into Body and Gravity acceleration signals(___tBodyAcc-XYZ___ and ___tGravityAcc-XYZ___) using some low pass filter with corner frequecy of 0.3Hz.\n",
    "\n",
    "4. After that, the body linear acceleration and angular velocity were derived in time to obtian _jerk signals_ (___tBodyAccJerk-XYZ___ and ___tBodyGyroJerk-XYZ___). \n",
    "\n",
    "5. The magnitude of these 3-dimensional signals were calculated using the Euclidian norm. This magnitudes are represented as features with names like _tBodyAccMag_, _tGravityAccMag_, _tBodyAccJerkMag_, _tBodyGyroMag_ and _tBodyGyroJerkMag_.\n",
    "\n",
    "6. Finally, We've got frequency domain signals from some of the available signals by applying a FFT (Fast Fourier Transform). These signals obtained were labeled with ___prefix 'f'___ just like original signals with ___prefix 't'___. These signals are labeled as ___fBodyAcc-XYZ___, ___fBodyGyroMag___ etc.,.\n",
    "\n",
    "7. These are the signals that we got so far.\n",
    "\t+ tBodyAcc-XYZ\n",
    "\t+ tGravityAcc-XYZ\n",
    "\t+ tBodyAccJerk-XYZ\n",
    "\t+ tBodyGyro-XYZ\n",
    "\t+ tBodyGyroJerk-XYZ\n",
    "\t+ tBodyAccMag\n",
    "\t+ tGravityAccMag\n",
    "\t+ tBodyAccJerkMag\n",
    "\t+ tBodyGyroMag\n",
    "\t+ tBodyGyroJerkMag\n",
    "\t+ fBodyAcc-XYZ\n",
    "\t+ fBodyAccJerk-XYZ\n",
    "\t+ fBodyGyro-XYZ\n",
    "\t+ fBodyAccMag\n",
    "\t+ fBodyAccJerkMag\n",
    "\t+ fBodyGyroMag\n",
    "\t+ fBodyGyroJerkMag\n",
    "\n",
    "8. We can esitmate some set of variables from the above signals. ie., We will estimate the following properties on each and every signal that we recoreded so far.\n",
    "\n",
    "\t+ ___mean()___: Mean value\n",
    "\t+ ___std()___: Standard deviation\n",
    "\t+ ___mad()___: Median absolute deviation \n",
    "\t+ ___max()___: Largest value in array\n",
    "\t+ ___min()___: Smallest value in array\n",
    "\t+ ___sma()___: Signal magnitude area\n",
    "\t+ ___energy()___: Energy measure. Sum of the squares divided by the number of values. \n",
    "\t+ ___iqr()___: Interquartile range \n",
    "\t+ ___entropy()___: Signal entropy\n",
    "\t+ ___arCoeff()___: Autorregresion coefficients with Burg order equal to 4\n",
    "\t+ ___correlation()___: correlation coefficient between two signals\n",
    "\t+ ___maxInds()___: index of the frequency component with largest magnitude\n",
    "\t+ ___meanFreq()___: Weighted average of the frequency components to obtain a mean frequency\n",
    "\t+ ___skewness()___: skewness of the frequency domain signal \n",
    "\t+ ___kurtosis()___: kurtosis of the frequency domain signal \n",
    "\t+ ___bandsEnergy()___: Energy of a frequency interval within the 64 bins of the FFT of each window.\n",
    "\t+ ___angle()___: Angle between to vectors.\n",
    "\n",
    "9. We can obtain some other vectors by taking the average of signals in a single window sample. These are used on the angle() variable'\n",
    "`\n",
    "\t+ gravityMean\n",
    "\t+ tBodyAccMean\n",
    "\t+ tBodyAccJerkMean\n",
    "\t+ tBodyGyroMean\n",
    "\t+ tBodyGyroJerkMean\n",
    "\n",
    "\n",
    "###  Result Set(Encoded)\n",
    "+ In the dataset, Y_labels are represented as numbers from 1 to 6 as their identifiers.\n",
    "\n",
    "\t- WALKING as __1__\n",
    "\t- WALKING_UPSTAIRS as __2__\n",
    "\t- WALKING_DOWNSTAIRS as __3__\n",
    "\t- SITTING as __4__\n",
    "\t- STANDING as __5__\n",
    "\t- LAYING as __6__\n",
    "    \n",
    "## Train and test data were separated\n",
    " - The readings from ___70%___ of the volunteers were taken as ___trianing data___ and remaining ___30%___ subjects recordings were taken for ___test data___\n",
    " \n",
    "## Data\n",
    "\n",
    "* All the data is present in 'UCI_HAR_dataset/' folder in present working directory.\n",
    "     - Feature names are present in 'UCI_HAR_dataset/features.txt'\n",
    "     - ___Train Data___\n",
    "         - 'UCI_HAR_dataset/train/X_train.txt'\n",
    "         - 'UCI_HAR_dataset/train/subject_train.txt'\n",
    "         - 'UCI_HAR_dataset/train/y_train.txt'\n",
    "     - ___Test Data___\n",
    "         - 'UCI_HAR_dataset/test/X_test.txt'\n",
    "         - 'UCI_HAR_dataset/test/subject_test.txt'\n",
    "         - 'UCI_HAR_dataset/test/y_test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick overview of the dataset :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Accelerometer and Gyroscope readings are taken from 30 volunteers(referred as subjects) while performing the following 6 Activities.\n",
    "\n",
    "    1. Walking     \n",
    "    2. WalkingUpstairs \n",
    "    3. WalkingDownstairs \n",
    "    4. Standing \n",
    "    5. Sitting \n",
    "    6. Lying.\n",
    "\n",
    "\n",
    "* Readings are divided into a window of 2.56 seconds with 50% overlapping. \n",
    "\n",
    "* Accelerometer readings are divided into gravity acceleration and body acceleration readings,\n",
    "  which has x,y and z components each.\n",
    "\n",
    "* Gyroscope readings are the measure of angular velocities which has x,y and z components.\n",
    "\n",
    "* Jerk signals are calculated for BodyAcceleration readings.\n",
    "\n",
    "* Fourier Transforms are made on the above time readings to obtain frequency readings.\n",
    "\n",
    "* Now, on all the base signal readings., mean, max, mad, sma, arcoefficient, engerybands,entropy etc., are calculated for each window.\n",
    "\n",
    "* We get a feature vector of 561 features and these features are given in the dataset.\n",
    "\n",
    "* Each window of readings is a datapoint of 561 features.\n",
    "\n",
    "* 30 subjects(volunteers) data is randomly split to 70%(21) test and 30%(7) train data.\n",
    "\n",
    "* Each datapoint corresponds one of the 6 Activities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    " + Given a new datapoint we have to predict the Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Features: 561\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# get the features from the file features.txt\n",
    "features = list()\n",
    "with open('UCI_HAR_Dataset/features.txt') as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('No of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the  train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>ActivityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>0.272544</td>\n",
       "      <td>-0.017668</td>\n",
       "      <td>-0.105699</td>\n",
       "      <td>-0.973588</td>\n",
       "      <td>-0.979174</td>\n",
       "      <td>-0.961958</td>\n",
       "      <td>-0.973196</td>\n",
       "      <td>-0.976966</td>\n",
       "      <td>-0.955513</td>\n",
       "      <td>-0.925441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.08157</td>\n",
       "      <td>0.699503</td>\n",
       "      <td>0.103912</td>\n",
       "      <td>-0.056536</td>\n",
       "      <td>0.333674</td>\n",
       "      <td>-0.389219</td>\n",
       "      <td>-0.575634</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "4062           0.272544          -0.017668          -0.105699   \n",
       "\n",
       "      tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \\\n",
       "4062         -0.973588         -0.979174         -0.961958         -0.973196   \n",
       "\n",
       "      tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  \\\n",
       "4062         -0.976966         -0.955513         -0.925441  ...   \n",
       "\n",
       "      angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "4062                     -0.08157                              0.699503   \n",
       "\n",
       "      angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "4062                          0.103912                             -0.056536   \n",
       "\n",
       "      angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  \\\n",
       "4062              0.333674             -0.389219             -0.575634   \n",
       "\n",
       "      subject  Activity  ActivityName  \n",
       "4062       21         6        LAYING  \n",
       "\n",
       "[1 rows x 564 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data from txt files to pandas dataffame\n",
    "X_train = pd.read_csv('UCI_HAR_Dataset/train/X_train.txt', delim_whitespace=True, header=None, names=features)\n",
    "\n",
    "# add subject column to the dataframe\n",
    "X_train['subject'] = pd.read_csv('UCI_HAR_Dataset/train/subject_train.txt', header=None, squeeze=True)\n",
    "\n",
    "y_train = pd.read_csv('UCI_HAR_Dataset/train/y_train.txt', names=['Activity'], squeeze=True)\n",
    "y_train_labels = y_train.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
    "                       4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
    "\n",
    "# put all columns in a single dataframe\n",
    "train = X_train\n",
    "train['Activity'] = y_train\n",
    "train['ActivityName'] = y_train_labels\n",
    "train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 564)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the  test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>ActivityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>0.216076</td>\n",
       "      <td>-0.014232</td>\n",
       "      <td>-0.104598</td>\n",
       "      <td>-0.07077</td>\n",
       "      <td>-0.170106</td>\n",
       "      <td>-0.37129</td>\n",
       "      <td>-0.12779</td>\n",
       "      <td>-0.218118</td>\n",
       "      <td>-0.369037</td>\n",
       "      <td>0.078787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858839</td>\n",
       "      <td>-0.224608</td>\n",
       "      <td>-0.754813</td>\n",
       "      <td>0.414124</td>\n",
       "      <td>-0.912845</td>\n",
       "      <td>0.047113</td>\n",
       "      <td>-0.021692</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>WALKING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "1156           0.216076          -0.014232          -0.104598   \n",
       "\n",
       "      tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \\\n",
       "1156          -0.07077         -0.170106          -0.37129          -0.12779   \n",
       "\n",
       "      tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  \\\n",
       "1156         -0.218118         -0.369037          0.078787  ...   \n",
       "\n",
       "      angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "1156                     0.858839                             -0.224608   \n",
       "\n",
       "      angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "1156                         -0.754813                              0.414124   \n",
       "\n",
       "      angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  \\\n",
       "1156             -0.912845              0.047113             -0.021692   \n",
       "\n",
       "      subject  Activity  ActivityName  \n",
       "1156       10         1       WALKING  \n",
       "\n",
       "[1 rows x 564 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data from txt files to pandas dataffame\n",
    "X_test = pd.read_csv('UCI_HAR_Dataset/test/X_test.txt', delim_whitespace=True, header=None, names=features)\n",
    "\n",
    "# add subject column to the dataframe\n",
    "X_test['subject'] = pd.read_csv('UCI_HAR_Dataset/test/subject_test.txt', header=None, squeeze=True)\n",
    "\n",
    "# get y labels from the txt file\n",
    "y_test = pd.read_csv('UCI_HAR_Dataset/test/y_test.txt', names=['Activity'], squeeze=True)\n",
    "y_test_labels = y_test.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
    "                       4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
    "\n",
    "\n",
    "# put all columns in a single dataframe\n",
    "test = X_test\n",
    "test['Activity'] = y_test\n",
    "test['ActivityName'] = y_test_labels\n",
    "test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 564)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z',\n",
       "       'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z',\n",
       "       'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z',\n",
       "       'tBodyAcc-max()-X',\n",
       "       ...\n",
       "       'angle(tBodyAccMean,gravity)', 'angle(tBodyAccJerkMean),gravityMean)',\n",
       "       'angle(tBodyGyroMean,gravityMean)',\n",
       "       'angle(tBodyGyroJerkMean,gravityMean)', 'angle(X,gravityMean)',\n",
       "       'angle(Y,gravityMean)', 'angle(Z,gravityMean)', 'subject', 'Activity',\n",
       "       'ActivityName'],\n",
       "      dtype='object', length=564)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of duplicates in train: 0\n",
      "No of duplicates in test : 0\n"
     ]
    }
   ],
   "source": [
    "print('No of duplicates in train: {}'.format(sum(train.duplicated())))\n",
    "print('No of duplicates in test : {}'.format(sum(test.duplicated())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Checking for NaN/null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 0 NaN/Null values in train\n",
      "We have 0 NaN/Null values in test\n"
     ]
    }
   ],
   "source": [
    "print('We have {} NaN/Null values in train'.format(train.isnull().values.sum()))\n",
    "print('We have {} NaN/Null values in test'.format(test.isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check for data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA60AAAHzCAYAAADLvvtxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl8VNX9//HXZGWX1aXKrpwgyrcSCrKFChUVQTajiAlVotSqVLYoVowRS1hdqnwBxVBlEUsQBESsrUBA+AoSEPhpuCgUNAUXBClgmGzz++NOxiwz2UjITHg/Hw8ew5w5c+7n3txJ8snZHC6XCxERERERERF/FFTdAYiIiIiIiIj4oqRVRERERERE/JaSVhEREREREfFbSlpFRERERETEbylpFREREREREb+lpFVERERERET8Vkh1ByAiIqUzxiQCzxQpdgGZwFFgI/CCZVn7z/M4wcAfgb9ZlnX2fNoKFMYYF7DHsqxfl1KvIXASSLUs67eVHMNnwP9YluUopd4moDfQyLKsnyozBn9zMZ2riIiUTEmriEhgWQ185v5/ENAA+B/gQSDGGBNtWda682j/LeAuYMl5RRlYngW+re4gRERExDslrSIigeVdy7LeKFpojOkPrAL+boz5tWVZX1Ww/cvOJ7hAZFlWYnXHICIiIr5pTquISA1gWdb7wNNAXfejiIiISI2gnlYRkZpjDvZQ12HGmDjLsnIAjDGhwMPAPUB7oDZwDFgPPG1Z1g/ueq4CbZ00xnjmbhpjWgKTgH7AlUAOYAELLMuaX1pgxpjDQIY7jpeBLsAJ4F0gwbKsE0XqHgbeBKZjJ+KvWpY1wf363cCfgF9jz+vdC7xsWdbbBc73GHAOaG5ZVsHzwhgzH/gD0MWyrE+9zWk1xrQC/gLcDNQB/gkk+jg3h7u90djX9xywBXjGsqzdRerWxv6jwgjsXu09wOMlXz2vWhhj/uaOzwn8A5hsWdYh93FigUXAVMuyJheJoQ7wnfuce5Z0EGNMJyAB6IV9HSxgPvbXo+h1HQA8AnQGGgI/AVuBRMuyPitStxUwGbgVaAz8G1iI/XXMLhLGlcaYl4H+2Pfubux7ZkMpsbdyt7vasqzBRV5LxJ4jPsSyrHfdZZcBSdjzaK/Cvj8/Ap4tOnLBGHM19v1ws/tcD2Ff79kF4y/tXhYRkbJRT6uISA1hWdbPwC7sX4wLLiq0DHgJyAZeA17FTqz+ALxfoN6zwBH3/2cAb4Dnl/+dwO+B/wNeBFZiJ2jzjDGPljHEXwGbsOfhzsH+Rf8RYLMxpm6Ruh2A/8VOalPcx8UYMxt4G2iDPf92GdAaWGaMmeG+Dtnu91wJFErKjDEhwDDgS8uyPvUWpDHmKmAbdmL5f9jJ1HXYiaE3bwLzgDDshC4FiAK2GWP6FGg3CPsPBU9iJ43zsL8mHwItfLTtyz9wX3/sxPAe4P+MMfntrATOuMuLGgzUAxaXdABjzG3Y16EPsBZ4Bfv3hnnY91DBuo+661zDL/fbF8Ag7K/vFQXqXgekAaOwE9D/BX4GZgOvewllA3Yi/Dfs++FG4EN3Ql0pjDG1sL82I92xvQh8jH39thljGheo2wn78xDtju1F7AQ3CVjjXsysIK/3soiIlJ16WkVEapb/uB+vADDG3IidpC21LCsmv5I7edsFdDbGtLMs64BlWYnGmN8CLYHpBVZsnQQ0BW62LOtfBdqYA2zHTu7mlCG21sAaYKhlWbnuNl4GxgDxFO7JbAr8ybKsVwocrxcwATvRuaVAD3Ez7OThcWPMOsuyNmMvJPUQcDd2r2e+37nbLineqdjX7z7Lst50H+PPwHvA5QUrGmOigVjsBPr3BXq3p2EnNouMMW0sy8rCTvp7YyfBD1qWleeuO9N9/uXxb6CPZVnn3G38ATthngbca1nWWWPMSmCkMaarZVnbC7z3XiALWO6rcXdv7JvAf7F7pA+7yycBfwceNMa8a1nW+8aYcPc1OwB0KrjqtDFmLvZq1AOx/2ACMBdoBNxpWdZKdz0H7qTRGPNXy7J2FQhnJzA4vwfTGPMpdqL4e+x7uDL8DrgBmGJZlmeVbmPMRGAWdvL6v+443wTCge6WZaUVqPsCMA77j0FzC7Rd7F4WEZHyUU+riEjN4nQ/NnA/ZgD3YQ/x9HAnVx+7n15aSptLgLiCCau7jR3YW+6U9v58LiA+P2F1exq7R/BeL/VXFHl+n/txYn7C6o7jB+zEGuzeOyzL2ordk3tnkZ6vu92PS70FaIwJA4YCn+cnrO72zhY4RkFx7sex+Qmru/6/sXskr8QeQgp24uMCnsxPWN2eBk55i6cET+YnrO7jvYo9dHeYO4kEO7kC+48K+efXDHuI93uWZZ0sof07gGbAzPyE1X2cPOyeYoD73Y/B2KtXP+Blm6RN7sdL3ce/Cnuo8b/yE1Z3uy7gz9i9/c4ibUwvMmR4rfuxTQnxl1f+70Od3EO4883F7gXPT0K7Yve6JxdMWN2exv5jwP0UV/ReFhGRclBPq4hIzVLf/XgGwLKsDOBNY0yIe1ijAdpi9yr9zl236HDGQizL+hj42D1E8tfA1e52bgRqlfb+Ao5ZlnWgSNunjDEHsJOFOu4hzgBZlmUdK/L+XwN5/JJsF5Rf9j8Fyt7CnjfZG9jgTkgHA9tLWF25LfbQ2Z1eXtuJPZy3oEjsodaPGGOK1o8oEPc6d2xfW5b1fcFKlmU5jTFp2MNwy8KF9yGmO7C/LhHYc2U3Al8Ddxljxrv/WHA39s/+EocGu88LINI9/7OoXNxD0N1fs+UAxph2wLXY1/E6oK+7fv490tH9WCx+d++qt57TL4s8/9H9WK+UcyiPf2H/kWMA8K0x5l/YPb/vWZb1TYF6+delrY/rchr4H2OMo8CcX2/3soiIlIOSVhGRmqWV+/FQfoF76GgC9pxSsBfI+QRIx+45cpTUoDGmEfZwzBFAKHbSdBh7SG6n0t5fwH98lOfvkXoJ9txGsHtwi2oAnHMPtS3Enfz+jL1YUL7F2Enr3e5Yb8NeNMdrL6tbI/fjaS/HyDXGFO0RbYj9s/SZovULyJ8P2Qj43kedEz7KvTnp7RrwS8z1wO69NMYsxe4ZvQk7MYtxH+t9L+8vqKH7cXgJdQrO84zCvkfy55mew06c04Dm/HKP5F/f/5Zy/ILO+Sgv631XKsuyfnYPpX8Ke5/ioe5/ee5h1n9wLxaWf11udf/zpR6/fD283csiIlIOSlpFRGoId3LZATsp/cJdFo0913Ev9sq9u/J7jowx87CT1tIswV65dT52IrjPsqzT7ja8Dev1pbaP8vxE4Ecfr+c7DdQxxlxiWVah5NG9kE7tgm1YlnXAGLMTe8jsw9jJay72nExf8ofMXlL0Bfd8xqILRp0BTluWVZaFlE56a9etPL2GlxTpycuX/0eJggnwm9hJ613GmC+xv95zfSS9BZ1xP/Ytwyq9LbF7Jc9hr6D8MXDAneTfjd27XbTd+hThXqgq3LKsykry8q+Pt+S2TtEC9zDzscaYcdg9wrdgL8x0J3YP/938En+cZVkLKylOEREphea0iojUHH/A/mPk3wvMG82fzzjCsqzVRYY6tnc/Fvylvug2Jg2xE9adlmX90bKsbQUS1lbYw4PL2uPVzhhTKGlzL/jzP8DuMiRS+dum9PLyWk93HJ8XKV8CNMEeejsQ+GfR4blFfIU9v7S7l9eupXjivRe4yhhzedHKxpgBxpi/GGPyhyynAc0LrPCbXy8Ye7h2WRWr797mpzN2UuUZgm1ZloU9bHiA+x+UPjQY7PPC3WYhxpjGxpiXjDH5C3sNxk4CEyzLWmBZVnqB+6/oPbbP/djFyzG7AWeNMU+VIb6yyL+fvP1BoG3BJ8aYKGPMX40xbS3LclmWtceyrJnuOM/wyz1X0nUJNcY8b4wZU0nxi4iIm5JWEZEawL21SgL2L9jTCryUP7TysiL1R2LP9QR7yG++/DmbYe7HLOxepkbuOaH576/NLyvwFnx/ScKAJHePZX7P5TTs3suy9Fq94X6c5l5QKD+WZtgrvELxhGwZ9p6ys7CTlyUlHcC94M9b2HMWxxc4RhiFr2vBmBzAnCLX5wrshZie5Jfeufz4X3AnmfniKfL1KYNniiww9Tj23qJvFlnoCuz9Q69wH+cry7I+KUP7q7CH8D7hnqda0EzgMey5zeD7Huvorgfue8S9j+z/AbcYY24pUDcIeAL7Wv6zDPGVxffYvdtdjDGexcKMMTcAtxepezn23r9F90+9DPsPFflbQW3GXrk5zhjTrUjdScB4fpn3KiIilUTDg0VEAstgdw8n2L/gX4I9j7AX9ty54ZZlHSlQfwn2vMRVxphluLcwwU5Yv8de1bVJgfr5804XGmM+tCzrZfecvjuBHcaYD7GTv4HYv+ifBBoaY4KKrIjrTTb29jA3GGM+wV7IqRv2gkHzSztxy7I2u7cVGQ/sNcbkryI7ADspm+He7qbge753L6pzK/Z82XdLOw72vMa+wPPuxOoL7EWrGlN8fuUb2CvtDgP2GWP+gf2z9S7s6zrJsqyD7liWG2PuxN7fM80Y8xH2cO4+2ElRyzLEhjuGSOyvx0fYCyLdDOzHnsNb1DLgBXf7Jc299bAs6ydjzAPYCfxuY8wq4CjwW+A3wKfY+6qCvRXQT8CfjTERwEHs/VoH8MuqyAXvsT9gJ3/rjDHvYs+P7oPde/xX96rU5809PHkhdiK6wxizAntF5Gjs3ueCPfbvYifTfzTGXO/+fwPs+x7c183d5kjgA+z9Z1e7z7ez+xz+zS+rK4uISCVRT6uISGAZhP0L9DPYPasPYicEc4DrLctaV7Cy+/lw7F+sY7C3jakFPMIvC8n0L/CWqdh7r94MPOouiwNewp57Osb9vk+xh9C+id0TdVMZYv8Zexgv2Ht3Xo69xcltBbeLKYllWRPc53EYe5ucu7CHww6zLMvbljTwS+/ru162ZPF2jJNAD+xE+nrsJOtb7ETWWaSuCzuxecx9fg9gz338AhhiWdaMIs3fg92jWItfrsEQfhn6XBZO7ATpR+yv0a+BV4GeBfbWLRjjCeAj99MSe5qLvC8FiHK/9zbsr3194Dngd5Zl5a9Q/R/spH4D9jV6GGgHvIy9kvGPwK35PeyWZe3D/sPJcuw/nvwJe3jxePe/yvQkMMX9/zHYyf6j2El8wXPNwu59nYGd2D6KfW9tB3pblvVhgbofu+NPwU58H8P+g8DLQDetFCwiUvkcLlfRdRxEREQqlzHmMNDQsqyGpVSVSuYeensEOGxZlrf5wCIiIn5NPa0iIiI12wPY810XVHcgIiIiFaE5rSIiIjWQMebv2Fu3GOz5rsuqNyIREZGKUU+riIhIzfQ99lzLHcAg98rIIiIiAUdzWkVERERERMRvqadVRERERERE/Jbfzmn97LPPXOHh4dUdhoiIiIiIiFSBn3/++XhkZGSz0ur5bdIaHh5O+/btqzsMERERERERqQJpaWlHylJPw4NFRERERETEbylpFREREREREb+lpFVERERERET8lt/OafUmOzubjIwMzp07V92hSA1Wq1YtrrrqKkJDQ6s7FBERERGRi15AJa0ZGRnUr1+fVq1a4XA4qjscqYFcLhc//vgjGRkZtG7durrDERERERG56AXU8OBz587RpEkTJaxSZRwOB02aNFFvvoiIiIiInwiopBVQwipVTveYiIiIiIj/CLiktaZ47bXX6NmzJ06n02cdy7L49NNPARg3bhxZWVk+29q7dy9Op5OUlBSf7a1cuZI+ffpw5swZT9m4cePYvn17Bc9CRERERESkailprSZr166lf//+rFu3zmedDz/8kK+++gqAF198kbCwMK/1Ro8eTceOHfnhhx9KTFoBMjMzSUpKqnjgIiIiIiIiF1BALcRUU2zfvp0WLVowfPhw4uPjGTp0KHv27GHq1Km4XC4uu+wynn76aVatWkVoaCgdOnRg7NixrFmzhiFDhrB69Wrq1KnD66+/TkhICPv376d///6eJHfOnDl8/PHHPPfcc1xzzTWkpqayadMmrr/+egYPHszu3bvZuHEjN910kyem3NxcEhIS+Pbbbzl58iRRUVGMHTuWSZMmERISwtGjR8nKyqJ///5s3LiRY8eOMXfuXFq0aMHzzz/Pp59+isvl4r777uO2226rxqsrIiIiIiI1iXpaq0FKSgrR0dG0adOGsLAw9uzZw9NPP820adNISUmhW7duHD9+nCFDhnDffffRsWNHAEJDQ+nXrx8ffvghAO+//z6DBg3ytPvQQw9x9dVX8+ijjxIdHc2qVasAeOedd7jzzjsBCA4OZvr06SQlJXHy5EnPe48dO8avf/1rkpOTWbZsGcuWLfO8duWVV7Jw4ULatGlDRkYGCxYsoF+/fmzYsIHU1FQyMjJ4++23WbRoEfPnz+e///1vlV9DERERERG5OKin9QI7deoUmzdv5sSJEyxevJgzZ86wZMkSfvzxR9q2bQvAvffeC8CGDRuKvT86OprExETatGlDq1ataNSokdfj9O/fnyFDhhAXF8e3335Lhw4dsCwLgFatWjFy5EieffZZz6JDDRs2ZN++fXzyySfUq1ev0PzZa6+9FoAGDRrQpk0bz/+zsrI4cOAAn3/+ObGxsQDk5ORw9OhRGjRoUBmXS0RERERELnJKWi+wNWvWMGzYMJ544gnAnmPat29fatWqxeHDh2nVqhWvvfYarVu3xuFwkJeXV+j9rVq1wuVy8frrr3PPPfcUei0oKMhTv3bt2nTt2pWpU6cW6o3NFxMTw0cffYRlWQwfPpyVK1dSv359pkyZwpEjR1i+fDkulwsoeTXdNm3a0LVrV5577jny8vKYO3cuV1111XldIxERERERkXwaHnyBpaSkFEoia9euTb9+/Rg6dCh//vOfiYmJIT09nd69e3PdddexdOlSPvnkk0Jt3HnnnXzxxRfceOONhcqbNGlCdnY2s2bNAuCuu+7iX//6FwMHDiwWh8PhICkpydOj2q1bNzZv3szw4cNJTEykZcuWfP/996WeT58+fahTpw4jRoxg6NChANSrV698F0VERERERMQHR35vmr9JT093tW/fvmgZRcvEt71797JkyRJmzpxZ3aEEHN1rIiIiIiJVKy0tLS0yMrJzafU0PLiGWrJkCe+88w4vv/xydYciIiIiIiJSYUpaa6iYmBhiYmKqOwwREREREZHzojmtIiIiIiIi4reUtIqIiIiIiIjfuuiSVleRLWR8lYmIiIiIiEj1u+jmtDqCgji9f3+hsvoREdUUjYiIiIiIiJQkoJNWZ3Yu4aHB5X6fryS1rO299tprbNu2jaCgIBwOB3/605+YPXs2YG+V0qpVK2rXrs0dd9xBdHQ0AA899BAA8+fP97TTp08f7rvvPkaOHAnAwYMHSUxMZPHixUyaNInPP/+chg0bkpOTQ6NGjXjyySdp3rw5K1eu5NChQ0ycOLHENgDWrVvH0qVLAQgODiYiIoL4+HjCwsLKfd1EREREREQutIBOWsNDg4mMX1Rp7aXNGllqna+++ooNGzawbNkyHA4H6enpPPHEE6xZswaA2NhYEhMTadu2rec9x44d4+effyY7O5tvvvmG5s2be15744036NmzJ23atCl2rPj4eKKiogDYuXMnY8eO5Z133ilWz1cbqampLF++nPnz59OgQQNcLhfTpk3j3Xff5a677irbRREREREREalGF92c1vPVuHFjjh49yooVK/juu+9o3749K1asKPE9K1asoG/fvgwePJi33nqr0GuTJk1i0qRJ5ObmlthG586dCQ0N5ciRI8Ve89XG4sWLefzxx2nQoAEADoeDJ598UgmriIiIiIgEDCWt5dS4cWPmzZvHrl27uPvuu7n11lvZuHGjz/p5eXm89957DBo0iNtvv53333+fc+fOeV7v3bs37dq1Y8GCBaUeu0mTJpw8ebJYua82MjIyaNmyJQC7d+8mNjaWe+65h3HjxpX1dEVERERERKpVQA8Prg5HjhyhXr16TJs2DYB9+/YxevRounbtSsOGDYvV37JlC2fPnmXChAmAncSuXbvWM9cV7J7SYcOG0aJFixKPffToUS6//HIOHTpU7DVvbVxxxRVkZGQQERHBDTfcwOLFiz1zXkVERERERAKBelrLybIsEhMTcTqdALRu3Zr69esTHOx9AacVK1bwl7/8heTkZJKTk3nppZeKDRGuV68eU6ZMYerUqT6Pu3XrVmrVqsXll1/u9XVvbcTExDBz5kxOnz7tKduxY0eZz1VERERERKS6qae1nPr168fBgweJjo6mTp06uFwuHn/8cerXr1+s7o8//siePXt48cUXPWWRkZE4nU527dpVqG7Xrl25/fbbSU9P95TNmjWLBQsWEBQURN26dXnppZdKjK1oG3379iUnJ4eHH34YgLNnzxIREcGMGTMqfP4iIiIiIiIXksPlclV3DF6lp6e72rdvX7SMgmUV3fLGl8puTwJX0XtNREREREQqV1paWlpkZGTn0uoFdE9rRRPM0/v3F3qev2+rElYRERERERH/ojmtIiIiIiIi4reUtIqIiIiIiIjfUtIqIiIiIiIifktJq4iIiIiIiPgtJa0iIiIiIiLitwJ69WBXjhNHSHi535e/WnBF23vttdfYtm0bQUFBOBwOxo0bx8aNG2natCm1a9fmnXfewel08tVXX9GhQwcAhg4dysqVKwHYvXs3N9xwAwBPPPEES5YsoX///rRp04ZbbrmFv//971x33XUALFu2jOPHjzNmzBhycnKYP38+qamphIfbcQ4cOJC777673NdAREREREQkEAR00uoICefrKddXWnstEvaVWuerr75iw4YNLFu2DIfDQXp6Ok888QQ333wzAIMHD2bw4MFkZGQwfvx4Fi9e7HnvkCFDAOjRo0eh8oLq1avHk08+yTvvvENYWFih11588UXy8vJ4++23CQ4O5uzZs/zhD3+gc+fOtG3btqKnLSIiIiIi4rc0PLicGjduzNGjR1mxYgXfffcd7du3Z8WKFZXWfsuWLenVqxcvvvhiofKcnBzWr1/PhAkTCA6295OtW7cuixcvVsIqIiIiIiI1lpLWcmrcuDHz5s1j165d3H333dx6661s3LixUo8xduxYtm7dys6dOz1lJ0+e5JJLLiEkxO4cf+utt4iNjWXYsGG88cYblXp8ERERERERfxHQw4Orw5EjR6hXrx7Tpk0DYN++fYwePZrbb7+dpk2bVsoxwsLCmDZtGhMmTOCuu+4CoGHDhvz000/k5uYSHBzMiBEjGDFihGfOq4iIiIiISE2kntZysiyLxMREnE4nAK1bt6Z+/foEBVXupezQoQMDBgxgwYIFAISGhtKvXz9eeukl8vLyAHA6nezZsweHw1GpxxYREQk0zhxnucpFRCRwqKe1nPr168fBgweJjo6mTp06uFwuHn/8cdLT0yv9WA899FChocfx8fG8/vrr3HvvvYSEhHDmzBl+97vfcf/991f6sUVERAJJeEg4PV7pUax865it1RCNiIhUJofL5aruGLxKT093tW/fvmgZBcsquuWNL5XdngSuoveaiIj4PyWtIiKBJS0tLS0yMrJzafUCuqe1ognm6f37Cz3P37dVCauIiIiIiIh/0ZxWERERERER8VtKWkVERMQvObNzy1QmIiI1W0APDxYREZGaKzw0mMj4RYXK0maNrKZoRESkuqinVURERERERPyWklYRERERERHxWwGdtFZ0w/D6ERGF/pWnve3btzNu3LjisTid9OjRg9dff91TNn36dBISEjzPc3NziY6OJjU1lZUrVzJ79mwA+vTpw6JFvwx/OnjwILGxsZ7n69atY8SIEYwYMYLY2FimTp1KVlZW+U5aREREREQkAAX0nFZfG4lX1Pns5faPf/yD/v37s2rVKkaNGkVQUBDjx49n6NChbNu2je7du5OcnEzHjh3p3bs3K1euLPT+N954g549e9KmTZtC5ampqSxfvpz58+fToEEDXC4X06ZN49133+Wuu+6qcLwiIiIiIiKBIKB7Wv1JSkoKw4YNIyIigtTUVADCwsKYMWMGzz77LPv37+eDDz7g8ccf9/r+SZMmMWnSJHJzC6+KuHjxYh5//HEaNGgAgMPh4Mknn1TCKiIiIiIiFwUlrZXg8OHDZGZmEhERwbBhw1i6dKnntQ4dOjBw4EDuu+8+kpKSCA8P99pG7969adeuHQsWLChUnpGRQcuWLQHYvXs3sbGx3HPPPV6HKIuIiIiIiNQ0SlorQUpKCpmZmcTFxZGcnExaWhpHjhzxvD548GBatGhBRIH5s95MmjSJVatWYVmWp+yKK64gIyMDgBtuuIHFixczdepUjh8/XjUnIyIiIiIi4keUtJ6nnJwc3n//fZYuXUpycjLJycmMHj2at956q9xt1atXjylTpjB16lRPWUxMDDNnzuT06dOesh07dlRK7CIiIiIiIv4uoBdiqi5bt25l6NChAJw6dYoOHTrQsGFDz+tDhw5l0KBBjB07ltq1a5er7a5du3L77beTnp4OQN++fcnJyeHhhx8G4OzZs0RERDBjxoxKOhsRERERERH/5XC5XNUdg1fp6emu9u3bFy2jYJkzx0l4iPc5ohVR2e1J4Cp6r4mISPWIjF9U6HnarJE+63rbUeB8dgYQEZGqlZaWlhYZGdm5tHoB3dNa0QTz9P79hZ7n79WqhFVERERERMS/aE6riIiIiIiI+C0lrSIiIiIiIuK3lLSKiIiIiIiI31LSKiIiIiIiIn5LSauIiIgEDFeOs7pDEBGRCyygk9Y8Z8V+cNWPiCj0r6ztjRw5kr179wKQlZVFZGQkycnJntdjYmLYv38/TqeTHj168Prrr3tey8jI4K677irW5qRJk9i8eTMAOTk5PPbYYyQmJuJyuejTpw9Op5OVK1fSp08fzpw543nfuHHj2L59OwAnTpxg0qRJREdHExsby/3338/OnTsrcGVERET8myMknK+nXF/sn4iI1FwBveVNUHg4qVG9K6293ptTS3y9Z8+e7Ny5k44dO5KWlkbPnj3ZtGkTcXFxOJ1Ojh07RkREBGvWrKF///6sWrWKUaNGERRU+t8GsrOohRZlAAAgAElEQVSzGTduHK1atWLixInFXs/MzCQpKYmkpKRirz388MPExcUxffp0AL755hvGjBlDSkoKoaGhZTx7ERERERER/xPQPa0XWvfu3T09mKmpqURHR3P69GlOnz7N7t276dKlCwApKSkMGzaMiIgIUlNLToTB7rUdM2YMERERXhNWgMGDB3Po0CE2btxYqHzPnj00bNiQm2++2VPWvHlzVq1apYRVREREREQCnpLWcrj22ms5dOgQLpeLTz/9lC5dutCtWze2bdvGjh076NWrF4cPHyYzM5OIiAiGDRvG0qVLS2136tSp/Pzzz3z33Xc+6wQHBzN9+nSSkpI4efKkpzwjI4OWLVt6nickJBAbG8uAAQP47LPPzu+ERUREREREqpmS1nIICgoiIiKCzZs306xZM8LCwoiKimLXrl2kpaXRvXt3UlJSyMzMJC4ujuTkZNLS0jhy5EiJ7cbExLBw4UIOHDjA6tWrfdZr1aoVI0eO5Nlnn/WUXX755WRkZHieT5kyhcWLF9OuXTucFZzzKyIiIiIi4i+UtJZTjx49ePXVV+nVqxcAkZGRfPHFFwDUq1eP999/n6VLl5KcnExycjKjR4/mrbfeKrHNa665hpCQEGbPns2sWbM4ePCgz7oxMTH89NNPfPLJJwB06tSJ48eP89FHH3nq/PDDDxw6dAiHw3G+pysiIiIiIlKtlLSWU/fu3UlLS6N3b3sBqLCwMOrXr89vfvMbNmzYQIcOHWjYsKGn/tChQ1m9ejXnzp3jyy+/ZOjQoZ5/O3bsKNR28+bNiY+P57HHHiMzM9Pr8R0OB0lJSWRlZXmez5s3j40bNzJixAhGjBjBI488wqhRo/jNb35TRVdBRERERETkwnC4XK7qjsGr9PR0V/v27YuWUbAsz+kkKDy80o5Z2e1J4Cp6r4mISPWIjF9U6HnarJFet7hpkbCPHq/0KFa+dczWKotNRETOT1paWlpkZGTn0uoF/JY3FXF6//5Cz/P3alXCKiIiUpgzx0l4SHipZSIiIlUloJNWERERqVrhIeHFejDVeykiIheS5rSKiIiIiIiI31LSKiIiIiIiIn5LSauIiIiIiIj4LSWtIiIiIiIi4rcCeiGmnOxcQkKDy/2+/NWCK6s9ERERERERqRoBnbSGhAYzZ8LaSmvv0ecHlvj6yJEjmThxIh07diQrK4tu3brx8MMPExcXB0BMTAyTJ0+mdevW9OnTh/vvv58HHngAgIyMDMaPH8/y5csLtTlp0iT69+9PVFQUOTk5TJgwgUaNGvHMM8/Qt29f1q9fz7p165gzZw5r1qyhXr16AIwbN47hw4fTtWtXTpw4wcyZMzl48CC1atUiJCSERx55hM6dfW95FBsbS2ZmJrVr1yY7O5urrrqKp556ikaNGgGwfv16lixZQlBQEDk5Odx9990MHjyYd999l88++4zExEQAEhIS2L17N2vX2l+Hd955B8uyiIiIKDHmVatWsWrVKoKDg3G5XDzwwAP07NmT3//+9+Tl5XHo0CEaN25Mw4YN6d69O3/84x8BeOaZZ9izZw/vvvtusWvYpk0b7rjjDjp06ACA0+mkTp06/PWvf+WSSy4hNTWVhQsXEhQURG5uLnfeeSd33HFH6TeGiIiIiIhUm4BOWi+0nj17snPnTjp27EhaWho9e/Zk06ZNxMXF4XQ6OXbsGBEREaxZs4b+/fuzatUqRo0aRVBQ6aOws7OzGTduHK1atWLixInFXs/MzCQpKYmkpKRir+UnztOnTwfgm2++YcyYMaSkpBAaGurzmDNmzKBt27YArFmzhoSEBF555RU+/vhj3n77bebPn0/9+vU5d+4cf/rTnwgPD6d79+4kJyd72ti3bx+NGzcmIyODq666ih07djBgwAB++OEHnzGfPn2auXPnsm7dOsLCwvjuu++Ijo5m06ZNvPnmm0DhZL7gNdi1axft2rVj+/btdO3atdg5XX311SxevNjz/Pnnn2fFihXExcWRmJjI6tWradCgAWfOnGHQoEH06NGDJk2a+LxGIiIiIiJSvTSntRy6d+/Ozp07AUhNTSU6OprTp09z+vRpdu/eTZcuXQBISUlh2LBhREREkJqaWmq7WVlZjBkzhoiICK8JK8DgwYM5dOgQGzduLFS+Z88eGjZsyM033+wpa968OatWrSoxYS3qjjvu4PPPP8fpdLJ48WImTpxI/fr1AahVqxZPPPEES5cu5dJLL8XhcPDTTz9hWRZt2rQhKirKc5579+71XAdfMdepU4fc3FyWLVvG119/zWWXXca//vWvUpP79evX061bN4YMGcLSpUtLPSeXy8WxY8do0KABAE2aNGHRokV8+eWX1K1bl/Xr1ythFRERERHxc1WStBpjQo0xbxljthljthhjIowxVxtjPnY/n2eMCbiE+dprr+XQoUO4XC4+/fRTunTpQrdu3di2bRs7duygV69eHD58mMzMTCIiIhg2bFiZkqupU6fy888/89133/msExwczPTp00lKSuLkyZOe8oyMDFq2bOl5npCQQGxsLAMGDOCzzz4r1/k1aNCA//73v3zzzTe0aNGi0GvNmzfn6NGjAHTr1o1du3axefNmevXqRVRUFFu2bOGbb77hyiuvJDw8vMSYg4OD+dvf/saRI0d44IEHuOmmm1ixYkWp8aWkpBAdHU337t354osvvF6vr776itjYWAYOHMgtt9xCy5YtGTJkCADz5s0jMzOT8ePH07NnT1599VVcLle5rpGIiIiIiFxYVZU49gdCLMvqDkwBpgIvAJMty+oFOIBBVXTsKhMUFERERASbN2+mWbNmhIWFERUVxa5du0hLS6N79+6kpKSQmZlJXFwcycnJpKWlceTIkRLbjYmJYeHChRw4cIDVq1f7rNeqVStGjhzJs88+6ym7/PLLycjI8DyfMmUKixcvpl27djidzjKfm8vl4vjx4zRp0oTLLruM//znP4VeP3z4MFdccQXwS4/zxx9/TFRUFNdccw3ffvutJ3EvLebvvvuOc+fOkZCQwIcffsjChQtJTk7Gsiyf8R08eJAvv/yS6dOn8+CDD+JwOFi2bFmxevnDg1NSUvjVr35FkyZNCAkJ4dSpUxw9epT4+HjWrl3LypUr2bJlS7FeYBERERER8S9VlbQeAELcvakNgGwgEsgfK7se+F0VHbtK9ejRg1dffdWTnEVGRvLFF18AUK9ePd5//32WLl1KcnIyycnJjB49mrfeeqvENq+55hpCQkKYPXs2s2bN4uDBgz7rxsTE8NNPP/HJJ58A0KlTJ44fP85HH33kqfPDDz9w6NAhHA5Hmc9rxYoV3HjjjQQFBREbG8vMmTM5c+YMAGfPnmXmzJnce++9AHTp0oXPPvuM7OxsGjduDEDHjh1ZsWJFsaTVW8zHjx9n4sSJnDp1CoArr7ySRo0alTicOSUlhXHjxnmu65tvvsk777xDVlaW1/q1atVi9uzZzJ07l/3795OVlcXYsWM5duwYAM2aNaNp06aEhYWV+RqJiIiIiMiFV1ULMZ0BWgH7gabAACDKsqz8sZingUtKasDpdJKenl6oLDs7m8zMTM/zkODQUlf8LY/srBxycrNLrNOpUycmT57MlClTPLHUqVOHiIgIPvjgAyIiIggPD/e81r9/f+6++24GDhzIgQMHPENVAcaPH09OTg5ZWVlkZmbStGlTxo4dy5gxY1iyZAl5eXlkZmaSlZVFTk6Op82EhASio6NxOp2cO3eOF198kZdffpkFCxYAkJOTQ2xsLNddd12h61VQbm4u8fHx1K5dG4BLL72UJ598kszMTLp168aJEye4//77CQoKIi8vjyFDhnDTTTd52gsKCqJTp06e5127dmXLli1cccUVpcbcsWNHhg8fTmxsLLVq1SI3N5fBgwd73pt/DvnXJTs7m/fee4/ly5d7Xm/UqBHXXHMNa9eu9dQ9d+6c55oB1K1bl7FjxzJ58mTefPNNHn/8cR5++GFCQkLIzc0lKiqKyMhIr9coOzu72P0nInIxat++vdfyC/E90texy0vfz0WgRas21K0dXqz8bKaTrw8fqoaIKkeL1i2oW6tusfKz587y9b+/roaIpCo4qmJOnzHmBcBpWdaTxpjmwAagkWVZTd2vDwJutizrUV9tpKenu4r+sEpPT6+UH2Cn9+8v9NzXvq1y8aqse01EpCbo8UqPQs+3jtl6wY4dGb+o0PO0WSP5esr1xeq1SNhXLE64sLGK+LuinyewP1OBTp/9wJWWlpYWGRnpe59Ot6rqaT2JPSQY4AQQCuw2xvzWsqxNwG2AJhNWsb179zJr1qxi5bfddhsjRoyohohERERERETKp6qS1heBhcaYLUAY8GdgJ7DAGBMGpAOlLxcr56Vjx46F9iwVEREREREJNFWStFqWdQa4y8tLvavieCIiIiIiUjM4s3MJDw0uc7nUfFXV0yoiIiIiIlJu4aHBNXb+rVRMVW15IyIiIiIiInLeArqnNScri5AK7LPpa7XgirYnIiIiIiIiVSOgk9aQsDCmxtxZae09taTktaFGjhzJxIkT6dixI1lZWXTr1o2HH36YuLg4AGJiYpg8eTKtW7emT58+3H///TzwwAMAZGRkMH78eJYvX16ozUmTJtG/f3+ioqLIyclhwoQJNGrUiGeeeYa+ffuyfv161q1bx5w5c1izZg316tUDYNy4cQwfPpyuXbty4sQJZs6cycGDB6lVqxYhISE88sgjdO7se/Xo2NhYEhMTadu2LWDvi3vbbbexYcMGJk2axOeff07Dhg0Be0/XZ599lmuuuYbU1FQWLlxIUFAQubm53Hnnndxxxx1MmDCB77//nv/85z+EhoZy6aWX0q5dO55++mkAXnvtNRYtWsRHH31EeLi9R9grr7xC06ZNueeee7juuuu44YYbAHuP1Ly8PJ5//nmaN2/O3r17eemll3C5XOTl5dG7d29GjRpVrq+tiIiIiIgEpoBOWi+0nj17snPnTjp27EhaWho9e/Zk06ZNxMXF4XQ6OXbsGBEREaxZs4b+/fuzatUqRo0aRVBQ6aOws7OzGTduHK1atWLixInFXs/MzCQpKYmkpKRir+UnztOnTwfgm2++YcyYMaSkpBAaGlqhc42PjycqKgqA1NRU/vrXvzJnzhwSExNZvXo1DRo04MyZMwwaNIgePXrw/PPPA4UT0YLWrl1L//79WbduHUOHDi12vEsuuaTQSsdvv/02f/vb30hISGDKlCnMmDGDtm3bkp2dzfDhw7nxxhu59tprK3RuIhI4AmkxDm8x+WOcIlL1XDlOHCHhZS4XkZIpaS2H7t27M3fuXEaNGkVqairR0dHMnj2b06dP8/nnn9OlSxcAUlJSeOqppzhx4gSpqancdNNNJbablZXFmDFjuO6663j00Ue91hk8eDC7d+9m48aNhdrbs2cPDRs25Oabb/aUNW/enFWrVuFwOCrhrOHUqVPUqVMHgCZNmrBo0SJuueUWrr76atavX09YKUOqt2/fTosWLRg+fDjx8fFek9aijh49SoMGDQD41a9+xdKlSxk6dCjt27dn2bJlpR5TRGqGQFqMw1us/hiniFQ9R0g4X0+5vlh5i4R91RCNSODTQkzlcO2113Lo0CFcLheffvopXbp0oVu3bmzbto0dO3bQq1cvDh8+TGZmJhEREQwbNoylS5eW2u7UqVP5+eef+e6773zWCQ4OZvr06SQlJXHy5ElPeUZGBi1btvQ8T0hIIDY2lgEDBvDZZ59V+FxnzZpFbGwsv//979myZYun93fevHlkZmYyfvx4evbsyauvvorL5SqxrZSUFKKjo2nTpg1hYWHs2bOnWJ1Tp04RGxvLkCFDuOmmm3A6nTz44IMAJCUl0aRJExITE+nevTszZswgKyurwucmIiIiIiKBQ0lrOQQFBREREcHmzZtp1qwZYWFhREVFsWvXLtLS0ujevTspKSlkZmYSFxdHcnIyaWlpHDlypMR2Y2JiWLhwIQcOHGD16tU+67Vq1YqRI0fy7LPPesouv/xyMjIyPM+nTJnC4sWLadeuHU6n02db4eHhZGdne56fPXuWWrVqeZ7Hx8ezePFi3nzzTWbNmsWll17KqVOnOHr0KPHx8axdu5aVK1eyZcsWNm7c6PM4p06dYvPmzSxatIi4uDjOnDnDkiVLitXLHx68YsUKOnfuTGhoKHXr1sXpdPL555/zyCOPsGLFCj744AOOHj3K3//+d5/HFBERERGRmkNJazn16NGDV199lV69egEQGRnJF198AUC9evV4//33Wbp0KcnJySQnJzN69GjeeuutEtu85pprCAkJYfbs2cyaNYuDBw/6rBsTE8NPP/3EJ598AkCnTp04fvw4H330kafODz/8wKFDh0ocHtyhQwf+8Y9/eJ5v3ryZ668vPoyloKysLMaOHcuxY8cAaNasGU2bNi1xqO6aNWsYNmwYCxcuJDk5meXLl7N161ZOnDjhtX5wcDDPPfcc//znP9m0aRMOh4P4+HgOHDgAQKNGjbjyyis1PFhERERE5CIR0HNac7KySl3xt7ztlbblTffu3Zk8eTIzZ84EICwsjPr163PttdeyYcMGOnTo4Fl1F2Do0KEMGjSI6Ohovvzyy0LzOSdNmlSo7ebNmxMfH89jjz1GSkqK1+M7HA6SkpIYOHCg5/m8efN44YUXSE5Ots8jJ4dRo0bxm9/8xud5PPjggyQkJDB06FDCwsJo2LAhzz33XInn3qxZMyZPnsyjjz5KSEgIubm5/Pa3v6Vnz54+35OSkuK5VgC1a9emX79+xVZRLqhWrVpMnTqVJ554grVr1/LSSy+RkJBAbm4uDoeD66+/nmHDhpUYq4iIiIiI1AwBnbRWdE/V0/v3F3qev29rWdq78sorsSyrUNncuXM9/+/Xr1+h1y677DJPr+ju3buLtZe/eFO+QYMGMWjQIAA2bNgAUGzhol/96lekpaV5njdu3Ji//OUvpcZeUL169XjhhRe8vpa/CrE3ffv2pW/fvj5fHzNmTKHna9asKVYnMTGxWNnWrVsLPe/cubOn97hTp068/fbbPo8pIiIiIiI1V0AnrVKyvXv3MmvWrGLlt912GyNGjKiGiERERERERMpHSWsN1rFjx0J7n4qIiIhI9XHmOAn3sk+rr3IRsQVc0upyuSpt/1ERb0rbwkdERESkIsJDwunxSo9i5VvHbPVSW0TyBdTqwbVq1eLHH39UUiFVxuVy8eOPPxba/kdERERERKpPQPW0XnXVVWRkZPDDDz+cVzvnvv220PNaSoKlgFq1anHVVVdVdxgiIiIiIkKAJa2hoaG0bt36vNtJ/cNDhZ7fsDn1vNsUERERERGRyhdQw4NFRERERETk4qKkVURERERERPyWklYRERERERHxW0paRURERERExG8paRURERERv+LMzi1XuTd5Tme5yiuqPDEFEmdO8evkrUzkQgio1YNFREREpOYLDw0mMn5RsfK0WSPL3EZQeDipUb2Llfeu5F0jvMVanjj9VXhIOD1e6VGobOuYrdUUjVzs1NMqIiIiIiIifktJq4iIiIiIiPgtJa0iIiIiIiLit5S0ioiIXER8LRqTl60FViRwaYEgkZpNCzGJiIhcREpa4ObrKdcXK2+RsO9ChCVyXrRokEjNpp5WERERERER8VtKWkVERERERMRvKWkVEZES+ZorpjlkIhXj7bPjj58nffbF37h07120NKdVRERK5G2uGGi+mEhFBcr8S332xd84QsKLzb3XvPuLg3paRURERERExG8paRURERERERG/paRVRETkAtNcQRERkbLTnFYREZELTHMFRUREyk49rSIiIiIiIuK3lLSKiIiIiIiI31LSKiIiIiIiIn5LSauIiNQY3hYy0uJGIiK+ufQ9Uorwx8UCtRCTiIjUGN4WONLiRiIivjlCwvl6yvXFylsk7KuGaMQf+ONigeppFREREREREb+lpFVERERERET8lpJWEREJOJqDJSIigUbrLlSc5rSKiEjA0RwsEREJNFp3oeLU0yoiIiIiIiJ+S0mriIiIiIiI+C0lrSIiIiIXCWd2brGyvGzNqRMR/6Y5rSIiIiIXifDQYCLjFxUqS5s1UnPERcSvqadVRERERERE/JaSVhEREREREfFbSlpFRERERETEbylpFREREREREb+lpFVERERERET8lpJWERERERER8VtKWkVERERERMRvKWkVERERERERv6WkVURERERERPyWklYRERERERHxW0paRURERERExG8paRURERGRgODKcVZZ2zlZWWUqE8nnzM4tV3mgy3N6//x5K/f12anoZyqkQu8SEREREbnAHCHhfD3l+mLlLRL2nXfbIWFhTI25s1DZU0tWnHe7UnOFhwYTGb+oWHnarJHVEE3VCwoPJzWqd7Hy3ptTi5V5+zxBxT9T6mkVERERERERv6WkVURERERERPyWklYRERERERHxW0paRUREqkhVLhojIiJysdBCTCIiIlWkKheNERERuViop1VERERERET8lpJWERERERER8VtKWkVERETOgzM7t1zlIiJSPprTKiIiInIewkODiYxfVKw8bdbIaohGRKTmUU+riIiIiIiI+C0lrSIiIiIiIuK3lLRWM6ePPfx8lYuIiEhg0D69IuLvKuP7VM4FmL+vOa3VLDwknB6v9ChWvnXM1mqIRkRERCqL9ukVEX/n7ftUeb9HhYQGM2fC2kJljz4/8LxjK0g9rSIiIiIiIuK3lLSKiIiIiIiI31LSKiIiIiIiIn5LSWsV0CbjIiJSEXnO4gtieCsTERG5mFTZQkzGmCeBO4AwYC6QCrwBuID/BzxiWVZeVR2/OmmTcRERqYig8HBSo3oXKuu9ObWaohEREfEPVdLTaoz5LdAd6AH0BpoDLwCTLcvqBTiAQVVxbBEREREREak5qmp48C3APmAVsBZ4D4jE7m0FWA/8roqOLSIiIiIiIjVEVQ0Pbgq0BAYArYE1QJBlWS7366eBS0pqwOl0kp6eXumBtW/f3mt5ZR7L1zG8Hac8dUXEv7Vo1Ya6tcOLlZ/NdPL14UPVEFHlqM7vUyUduzwuxPfTyorVmwv1M6o8Auma6j79RaDEWpWfJ/Aef0V/R7zYrqnu01/4itOV48QRUvz3AV+q83f+qv6seVOR862qpPVHYL9lWVmAZYw5hz1EOF994KeSGggPD7+gF/FCHas8x6mOm0hEzo+v+ew19fMcKOcVKHH64o/x+2NMvgRKrIESJwRWrN744+9jgXJNAyVOqL5YHSHhfD3l+mLlLRL2ea0fSNe0MhQ837S0tDK9p6qGB38M3GqMcRhjfgXUBT5yz3UFuA3YUkXHFhERERERkRqiSnpaLct6zxgTBezATowfAf4NLDDGhAHpwIqqOLaIiIiIiIjUHFW25Y1lWY97Ke7tpUxERERERETEq6oaHiwXUE5WVrnKRS5GeU5nmcqqm6+YLkSsrhz/ux4i4n8C5ftpINE1larmzM6t7hDOS5X1tMqFExIWxtSYO4uVP7VEI7BF8gWFh5MaVXiwR+/NqT5qVx9vccKFibW8C0eIyMUpUL6fBhJdU6lq4aHBPheLDATqaRURERERERG/paRVRERERERE/JaSVj9VnfPaRERERGqqnACf2ydyMdKcVj9VnfPaRERERGqqkNBg5kxYW6z80ecHVkM0IlIW6mkVERERERERv6WkVURERERERPyWklYJCL72lvJW7vSx12RuAM0T1n5tFefr6y8iIiLnR2uuSHXRnFYJCOXZWyo8JJwer/QoVr51zNaAmSes/doqrqSvv4iIiFSc1lyR6qKeVhEREREREfFbSlpFRERERETEbylpFREREREREb+lpPUi53Uho3Juuq1Fg0REREREpKpoIaaLnLcFjrwtblQSLRokIiIiIiJVRT2tIiIiIiIi4reUtIqIiIiIiIjfUtIqAc2Vo7mzIiIicvHIycoqV7lITaA5rRLQHCHhfD3l+kJlLRL2VVM0IiIiIlUrJCyMqTF3Fit/asmKaohG5MJQT6uIiIiIiIj4LSWtIiIiIiIi4reUtIpcpHztx+t1714fc4d9lQe6yp4v5GvudWXMyfYW04Wa16Q9mkUkX46Pnym+ykWqmq+fR/o5FZg0p1XkIuVtj17wvk9veEg4PV7pUax865itVRJbdavs+ULe5l5D5cy/9hbrhZrXpD2aRSRfSGgwcyasLVb+6PMDqyEaEe8/o0A/pwKVelpFRERERETEbylpFREREREREb+lpFVERERERET8VkAlrV4XiKnCCf7avFkq4kLfpxeryljE6GKme1JERKT6acGosgmohZi8LRzjbdGYyqLNm6UiLvR9erGqysWNLga6T0VERKqfFowqm4DqaRUREREREZGLS5mSVmPMA0We/6lqwhERERERERH5RYnDg40x9wB3ADcZY/q4i4OB64CXqzi2GseV48QREl7dYVSYM8dJeADH7490TUUkEOU5nQSFF//e5au8OnmLyR/jFBER30qb0/oBcAxoArzqLssDDlZlUDWVtzl4gTT/LjwknB6v9ChWvnXM1mqIpmbQNRWRQBRIc7C8xeqPcYqIiG8lJq2WZZ0ENgGbjDGXArXK8j4RERERERGRylCm5NMY87/A7cBRwAG4gO5VGJeIiIiIiIhImXtMuwJtLMvKq8pgRPxFTlYWIWFhZS6vToEUqxSmOc0XRnnnX3r77OjzJFIx+hl1cQuU76e6T/1fWZPWr7CHBv9chbGI+I1A2qM3kGKVwrzNadZ85spX3vmX3j5T+jyJVIx+Rl3cAuX7qe5T/1fWpLUFcMQY85X7ucuyLA0PFhERERERkSpV1qT1niqNQkRERERERMSLsiatv/dSNuX/t3f/wZbedX3A35vsZiM0pUiB0AJJdciXVB2RpSg/8qNDsEImjbU4ZmiKScRWSxESlP4AABV7SURBVCxoSikQqGXAqZQE1AwiITFgzNASwSHWCLUNCYjU6Q50iFk/YIJh/IFCkBIK7GaT7R/P2XL37rm7N+Gc83yfu6/XTGbvee7Z+7z3yX2+977P8/0+Z5FBAAAAYL3Nlta/nP25LclTkxy3nDiL4wYnAABM1f777s/2HcePHQO6sKnSWlW/svZxa+3m5cRZnHk3OEnc5AQAgP5t33F8rrrspsO2X3rFeSOkgXFt9n1aT1vz8HEZbswEAAAAS7XZ6cFrr7R+Pcm/WUIWAAAAOMRmpwf/w9bao5J8e5K7quoLy421WlNaMzClrAAAwOLs37cv20844ajbtprNTg/+4SSvT7InyXe21n62qq5farIVmtKagXlZe8wJAAAs1vYTTsgbLnzBIdteff2NI6VZnc3eBfhnkuyqqh9M8j1JXrq8SAAAADDYbGl9oKq+kiRVdW+Gda0AAACwVJu9EdOdrbUrktyW5Iwkdy4vEgAAAAw2e6X17Um+mOS5SS5OctXSEsGK7b/v/qXv48D+vUvfxxge2Dv/37XRdo5d+/fte1DbOTrHFGDrWsXvp1Oy2SutVya5qKruaK1dmeS6JGcuLRWs0CpubrVt+8589nXfddj2J772kwvdz6odt3Nnbj3zrMO2n3XbrSOkoWfzbhyRHBs3j1gWxxRg65rSjWJXYbNXWvdX1R1JUlV3JXlgeZEAAABgsNkrrXe31n4uye8neXqSP1teJAAAABhs9krrxUn+Ksnzk3w+ySVLS/QgbdW1glO30Tz8+6zBesiO5bUNe4/hfzvLcyyfU8xnnTBAnzZ1pbWqvp7kLUvO8pBs1bWCU3ekefjWYD00x/Lahp07js+ul7/rkG27/9OLRkrDVnEsn1PMZ50wQJ82e6UVAAAAVk5pBQAAoFtKK3CIY2mduDWNTIHv02OD972G1TCmTtNm7x4MHCPmrRPfqmvErWlkCnyfHhu87zWsxrwx1XjaP1daAQAA6JbSCgAAQLeUVgAAALqltAJMgBtHwOI4nwCmxY2YACbAzXhgcZxPANPiSisAAADdUloBAADoltLKYQ7s90bmAABsjnXiLJs1rRxm2/ad+ezrvuuw7U987SdHSAMAQM+sE2fZXGkFAACgW0orAAAA3VJaAQAA6JbSCgAAQLeUVgAAALqltAIAANAtpRUAAIBuKa0ALIw3mIfV2L9v36a2AWwF28cOAMDW4Q3mYTW2n3BC3nDhCw7Z9urrbxwpDcByudIKAABAt5RWAAAAuqW0Aiux0Vora7AAADiSpa1pba09JsnuJM9Nsj/JdUkOJLk9yUuq6oFl7Rvoz7z1V4k1WAAAHNlSrrS21nYk+ZUkX5ttujLJ5VV1RpJtSc5fxn4BAADYWpY1PfhNSd6W5M9nj3cluXX28c1JzlnSfgEAANhCFj49uLV2UZLPV9UHWmuvnG3eVlUHZh/fm+QRR/s6e/fuzZ49ew7Zdvrppy8y6jdlfba1ppIzmU7WqeRMppN12TkfzPnrmC6eY7p4julD3/ffO/WUnPgtDztk29e/9tV85k/uPuLXckw33vdG+/R9uniO6eI5pou3VY7pRpaxpvWSJAdaa+ckeUqSdyV5zJrPn5TkS0f7Ijt37uzq4K7Xc7a1ppIzmU7WqeRMxs36YPbtmC7eVHIm08k6lZxJn+f+vPcUdUwXv2/HdPGmkjOZTtap5Eymk3UqOZNDs+7evXtTf2fh04Or6syqOquqzk7yiSQvSnJza+3s2VOel+TDi94vAAAAW8/S7h68zmVJrm6tnZBkTxK3CwUAAOCollpaZ1dbDzprmfsCAABg61nW3YMBgGPM/vvuHzsCAFvQqqYHAwBb3PYdx+eqy246bPulV5w3QhoAtgpXWgEAAOiW0goAAEC3lFZg4axrAwBgUaxpBRZu3ro2a9oAAHgoXGkFAACgW0orAAAA3VJaAQAA6JbSCgAAQLeUVgAAALqltAIAANAtpRUAAIBuKa0AAJ3af9/9Y0cAGN32sQMAADDf9h3H56rLbjps+6VXnDdCGoBxuNIKAABAt5RWAAAAuqW0AgAA0C2lFQAAgG4prQAAAHRLaQUAAKBbSisAAADdUloBAADoltIKAABAt5RWAAAAuqW0AgAA0C2lFQAAgG4prQAAAHRLaQUAAKBbSisAAADdUloBAADoltIKAABAt5RWAAAAuqW0AgAA0C2lFQAAgG4prQAAAHRLaQUAAKBbSisAAADdUloBAADoltIKAABAt5RWAAAAuqW0AgAA0C2lFQAAgG4prQAAAHRLaQUAAKBbSisAAADdUloBAADoltIKAABAt5RWAAAAuqW0AgAA0C2lFQAAgG4prQAAAHRLaQUAAKBbSisAAADdUloBAADoltIKAABAt5RWAAAAuqW0AgAA0C2lFQAAgG4prQAAAHRLaQUAAKBbSisAAADdUloBAADoltIKAABAt5RWAAAAuqW0AgAA0C2lFQAAgG4prQAAAHRLaQUAAKBbSisAAADdUloBAADoltIKAABAt5RWAAAAuqW0AgAA0C2lFQAAgG4prQAAAHRLaQUAAKBbSisAAADdUloBAADo1vZFf8HW2o4k1yY5NcnOJK9PckeS65IcSHJ7kpdU1QOL3jcAAABbyzKutF6Y5J6qOiPJ85JcleTKJJfPtm1Lcv4S9gsAAMAWs4zS+p4kr1nzeH+SXUlunT2+Ock5S9gvAAAAW8zCpwdX1VeSpLV2UpIbk1ye5E1VdWD2lHuTPGLR+wUAAGDrWXhpTZLW2hOSvC/JW6vqhtbaG9d8+qQkXzra19i7d2/27NlzyLbTTz99oTm/GeuzrTWVnMl0sk4lZzKdrFPJmUwn61RyJtPJOpWcyXSyTiVnMp2sU8mZTCfrVHIm08k6lZzJdLJOJWcyrazzLONGTI9N8sEkl1bVf59t/nhr7eyq+lCGda63HO3r7Ny5s6uDu17P2daaSs5kOlmnkjOZTtap5Eymk3UqOZPpZJ1KzmQ6WaeSM5lO1qnkTKaTdSo5k+lknUrOZDpZp5IzOTTr7t27N/V3lnGl9VVJHpnkNa21g2tbX5rkF1trJyTZk2HaMAAAABzRMta0vjRDSV3vrEXvCwAAgK1tGXcPBgAAgIVQWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAAEC3lFYAAAC6pbQCAADQLaUVAACAbimtAAAAdEtpBQAAoFvbV7Wj1tpxSd6a5LuT7E3y4qr641XtHwAAgOlZ5ZXWH0xyYlU9I8m/S3LFCvcNAADABK2ytD47ye8kSVV9LMnTVrhvAAAAJmjbgQMHVrKj1to7kvxGVd08e/zZJN9WVfvnPX/37t2fT3L3SsIBAACwaqfs2rXr0Ud70srWtCb5cpKT1jw+bqPCmiSbCQ8AAMDWtsrpwb+X5PlJ0lr7viSfXOG+AQAAmKBVXml9X5LnttY+mmRbkotXuG8AAAAmaGVrWgEAAODBWuX0YAAAAHhQlFYAAAC6tco1raNrrX1vkp+vqrPHzrKR1trxSa5O0pLcn+Tiqrpz3FTztdY+nuT/zB5+pqq6XafcWntlkn+c5IQkb62qa0aOdJjW2kVJLpo9PDHJU5KcXFVfGivTRlprO5K8M8mpGb5Pf7yq/mjUUOvMO99ba29OUlX1ttGCzbFB1hcm+amqesZowdZZm7O19tQkNyX59OzTv1xV/3m8dIdal/UxGcbVRyY5PsmLehlX1+V8d5KTZ586NcnHquqC0cKtM+f//9uS7E3yiSQvraoHRs63I8m1GY7dziSvr6r3zz7X1bk/L2uSzyb5pQxj6t4M36d/OVbGZMOcf5zk7RnuT/K/M4xT94+V8aANsv5pOhunNsj5sXQ4Rm2Q9YXpcJw6wjn1tiT7k3wqyYt7HKcyfJ92NZ4m8ztJhvP+uiQHktye5CWrynrMXGltrf3bJO/IUAZ6dl6SVNWzkrw2yZXjxpmvtXZiklTV2bP/ei6sZyd5ZpJnJTkryRNGDbSBqrru4PFMsjvJv+6xsM48P8n2qnpmktclecPIeQ6x/nxvrT26tXZzhhcuujJvbGqtPSXJj2X44dCFOTmfmuTKNWNAT4V1fdY3Jvn1qjozyeVJnjxWtrXW56yqC2bn/z9J8qUkPz1eukPNOaZvT/Kyqjojw4uXLxwr2xoXJrlnlul5Sa7q+Nw/LGuSX8hQAM9O8t4krxgv3v83L+fPJXnV7PeUh6WfYzsva4/j1LycXY5RmZO143Fq3nH990leV1XPzlAQzx0x30HzcvY4nibzO8mVSS6fZd2W5PxVhTlmSmuSO5P80NghjqaqfjPJv5g9PCXJqK+yHsF3J3lYa+2DrbX/MXsbo179owxvsfS+DK+4/ta4cY6stfa0JN9RVW8fO8sRfCrJ9tbacUn+ZpL7Rs6z3vrz/W8k+dkkvzZKmiM7JGtr7VFJ/mOSl42WaL71x3RXknNba7e11q5prZ20wd8bw/qsz0ry+Nba7yb5Z0k+NEaoOTb6ufQfkvxSVf3FivMcyfqsj6+qj84+/r0kz159pMO8J8lr1jzen37P/XlZL6iqT8web0/y9ZWnOty8nP+0qm5rrZ2Q4YpbL7+nzMva4zg1L2evY9S8rAf1Nk7Ny/rxJN/aWtuW5KT08bvKvJw9jqcbdZJdSW6dbbs5yTmrynPMlNaq+o308c16VFW1v7X2zgzThG4cO88GvprkTRkK4U8k+fXWWq/Tzf92kqcl+eF8I2s3V7DmeFWGHwY9+0qGqS1/lGHqyC+Ommad9ed7VX2mqv7niJE2tDbrbCrONRleub53zFzrzRlD/yDJy2dXBu7K8Ip2F+ZkPTXJX1fVORmmi/VwBWvuz6XZVObnZJh+1Y05We9qrZ01+/i8JA9ffapDVdVXqureWTG5McPVgC7P/Q2y/kWStNaemeTSJG8eM2OyYc77W2unJPnDDD9fa9SQM/OypsNxaoOcp6bPMWpe1i7HqQ2yfjrD7yd7kjw2HbwYsEHO7sbTg+Z0km1VdfCtZ+5N8ohVZTlmSuvUVNWPJjktydWttW6+edf4VJLrq+pAVX0qyT1JHjdypo3ck+QDVbWvqirDq9ePHjnTXK21v5XkyVV1y9hZjuKnMxzT0zJcdX/nwSnjfFN2JXlSkl9O8u4kf7+19pZxI23ofVW1++DHSb5nzDBHcU+S988+vinDi1i9ekGSG3pYI3gUFyd5ZWvtvyb5qyRfGDlPkqS19oQktyT5taq6Yew8RzIva2vtRzKsbTu3qj4/Zr6D5uWsqrur6kkZsnazjGlO1i7HqTk5ux2jNjinuhyn5mT9hSRnVNWTk7wryRVj5jtoTs4ux9OD1naSJN+y5lMnZZgivhJKa2daa/98dtOgZLia+UCGxc+9uSSzk7+19ncyTBHtZYrIeh9J8gOttW2zrA/P8AOiR2cm+d2xQ2zCX+cbN+H6YpIdGW4ewTehqv6gqr5jtl7ogiR3VFVv04QP+kBr7emzj5+TYR12rz6SYR12MpxjfzhilqM5J8OUq96dm+SSqjo3yaOS/LeR86S19tgkH0zyiqq6duw8RzIva2vtwgxXWM+uqrvGzHfQBjnf31p70uwp92b4PWV0G/z/726c2iBnl2PUEc6p7sapDbJ+McmXZx//eYYbXY1qg5zdjafJhp3kf83uFZMMa3I/vKo8vU7nPJa9N8mvttZuy1AEXlZVPaxrWe+aJNe11j6S4Q5il1TV/qP8nVFU1W+11s7MME3ouAx3OuvxhYBkuENbF7+sHMWbk1zbWvtwhjsyv6qq/u/ImVitn8xwo5t9ST6Xb6x76dFlSd7RWvvJ9HWTi3mmMgZ8Oslvt9a+muSWqvrtsQNlWFrxyCSvaa0dXDP2vKr62oiZNrI+6/FJvjPJ3Une21pLklurauzprPOO6asz/Pzfl+EX2RePFW6deVl/JslbOhun5uX80fQ5Rs09p9LnODUv648neXdrbX+SfbPHY5uX84r0N54mczpJhqnWV8/WtO/JCpcxbjtw4MDRnwUAAAAjMD0YAACAbimtAAAAdEtpBQAAoFtKKwAAAN1SWgEAAOiW0goAK9Zau6619gPrtp3cWnvrg/w6J7bWennLEQBYCu/TCgAdqKrPJflXD/KvnZzhfTLfsfhEANAH79MKAAvSWjstyXVJ7kuyP8m1Sc6rqgtmn/9cVZ3cWrsuybcmeXiGF5B/bPb8d1fV97XWzkryhiT3J7kzyb+cPe9Xk5yS4Y3efyrJJUl+JMmbqup1K/pnAsBKmR4MAIvz3CS7k5yToXQ+8gjP/WhVPSfJzyd548GNrbVtSa5O8kNVdVaSP0tyUZKfSPInVfWM2ePvne3jDoUVgK1MaQWAxbkmyReS/E6SSzNcPV1r25qPb5v9+dEkbc32Ryd5XJL/0lr7UJLvT/LE2XN+P0mq6vaqesuiwwNAj5RWAFic85N8eHYF9T0Zpu4+Lklaa6dkmBJ80NNnf56R5PY127+Q5E+TnF9VZ2e4mnpLkj1J/sHsa31ba+2GJA/Ez3IAtjhrWgFgQVpr357k+gxXWB9I8vIkr85ww6Q9SZ5ZVafN1rSemOQxSQ5kWJu6Ld9Y0/r9SV6boZB+OcmLZn9em+TvJjk+ycsylN2PJflAVb1iRf9MAFgppRUAOtBae1KSa6rqzLGzAEBPTCkCgJG11h6f5IYkvzl2FgDojSutAAAAdMuVVgAAALqltAIAANAtpRUAAIBuKa0AAAB0S2kFAACgW0orAAAA3fp/z9AKTLl+jDUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Data provided by each user', fontsize=20)\n",
    "sns.countplot(x='subject',hue='ActivityName', data = train)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We have got almost same number of reading from all the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('No of Datapoints per Activity', fontsize=15)\n",
    "sns.countplot(train.ActivityName)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "> Our data is well balanced (almost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Changing feature names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tBodyAcc_mean_X', 'tBodyAcc_mean_Y', 'tBodyAcc_mean_Z',\n",
       "       'tBodyAcc_std_X', 'tBodyAcc_std_Y', 'tBodyAcc_std_Z', 'tBodyAcc_mad_X',\n",
       "       'tBodyAcc_mad_Y', 'tBodyAcc_mad_Z', 'tBodyAcc_max_X',\n",
       "       ...\n",
       "       'angletBodyAccMeangravity', 'angletBodyAccJerkMeangravityMean',\n",
       "       'angletBodyGyroMeangravityMean', 'angletBodyGyroJerkMeangravityMean',\n",
       "       'angleXgravityMean', 'angleYgravityMean', 'angleZgravityMean',\n",
       "       'subject', 'Activity', 'ActivityName'],\n",
       "      dtype='object', length=564)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = train.columns\n",
    "\n",
    "# Removing '()' from column names\n",
    "columns = columns.str.replace('[()]','')\n",
    "columns = columns.str.replace('[-]', '_')\n",
    "columns = columns.str.replace('[,]','')\n",
    "\n",
    "train.columns = columns\n",
    "test.columns = columns\n",
    "\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save this dataframe in a csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('UCI_HAR_Dataset/csv_files/train.csv', index=False)\n",
    "test.to_csv('UCI_HAR_Dataset/csv_files/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Magnitude of an acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "sns.boxplot(x='ActivityName', y='tBodyAccMag_mean',data=train, showfliers=False, saturation=1)\n",
    "plt.ylabel('Acceleration Magnitude mean')\n",
    "plt.axhline(y=-0.7, xmin=0.1, xmax=0.9,dashes=(5,5), c='g')\n",
    "plt.axhline(y=-0.05, xmin=0.4, dashes=(5,5), c='m')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Observations__:\n",
    "- If tAccMean is < -0.8 then the Activities are either Standing or Sitting or Laying.\n",
    "- If tAccMean is > -0.6 then the Activities are either Walking or WalkingDownstairs or WalkingUpstairs.\n",
    "- If tAccMean > 0.0 then the Activity is WalkingDownstairs.\n",
    "- We can classify 75% the Acitivity labels with some errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Position of GravityAccelerationComponants also matters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='ActivityName', y='angleXgravityMean', data=train)\n",
    "plt.axhline(y=0.08, xmin=0.1, xmax=0.9,c='m',dashes=(5,3))\n",
    "plt.title('Angle between X-axis and Gravity_mean', fontsize=15)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Observations__:\n",
    "* If angleX,gravityMean > 0 then Activity is Laying.\n",
    "* We can classify all datapoints belonging to Laying activity with just a single if else statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFgCAYAAACR2P/oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XmcXfP9x/FXEjHJEEti32n4iFqq9ia2n6WRai2t2oldtGKrXZVaixRRSxHEvrdU0yhK7dvYGR8ZtdUuI0SHyTa/Pz7fyzVmuTN3n3k/H488cu85557zvXfuPZ/v/u3T0tKCiIhId/UtdwJERKS6KZCIiEheFEhERCQvCiQiIpIXBRIREcmLAomIiORlrnInoKcws8WA/wKvufsqBT73JsD9wNLu/t9uvH40cLm7d/vvbWa1wGh3v6i75ygVM1sGeAmY5O47tbH/ImAXYNXufJ45XP9h4CV3P7DQ5+6OXL8/ZrYBcBgwHFgI+AS4FzjN3V8rYvo2B+4BFnf3D9Lfb313v7lY15TCUomkcHYHXgeGmdmG5U5MERwGHFXuROTC3d8GjgZ2NLNR2fvM7EfAgcChxQgiyc+oks8qw8z2AR4EGoGfAysCOwKDgKfMbFgRL/8gsDjwUXo+EdiyiNeTAlOJpHD2BG4Ctgb2Bx4qb3IKrk+5E9BFlwA7AReZ2ffd/X9mNjdwGfB3d7+qWBd298ZinbsYzGwo8CfgDHc/MWvX28DDZvYgcCKwczGu7+4zgA+yNlXbd63XUyApADNbB/g+cBDQDJxgZmPd/dO0vwXYBxgNrAO8BfzR3S/NOseRwMFElcLdxI94DXffpI3r1QCnE9Uz8wDPAke7++OdpPMg4LdELvN24Nfu/nnatyAwDtiG+CE/Dhzm7p6qxk7Jei/bArcCQ7Je/xZRrbdF1mfyGLCou081s/2A3wDLAA3AOe4+MSttq6brb0jkiv+e3tO0tP9N4AJgE2Az4sZzlbv/vq336u4tKZf9AnAScCRRSlgM2LyTz6kfcAJRylwG+B9RxXNgei9/BnYAhrn7h2a2CFGVdr27H5pdtWVm8wIXAlulz/054Bh3/3c7114IODsdP4TIpV+bXtNiZqcCawJPESWruYlMywHu/kE6xw+B84G102c9oaP3C+wHfAWc1s7+nYDP0rnnAmYCvwf2BVpSepYCzgA2AAYC/wFOcffr0t9+HPFd+DKdZwDwIXAIUSV8D1EqOQfYGNg4fe92Bq4HlnD3j9Nr+xK/jzPc/cJO3htm9t/03n4KbAq8B4wFalOaFwP+DeyeyQSY2eopzcOBqcBdxPcx831fnvg7bQLMn97DBe7+x7T/WqAJmEH8TmcSv+uD3P2LztJcbVS1VRijiR/Fw8DNwABgj1bH/IHI9a1J/PAvNrNlAczsYCLHd1za/yYRVNpzNbAR8EviZvEv4H4zW6mD1/Qjgtk2RLXBWsQPFDPrA0wClgB+DIwggt3DZjaEKGn9gfixLE7Ut88ifkSY2YrA0sCPzKx/ut5WwKPpxjuG+CEfD6yaznW+me2ZXr8k8UN+Ib3/XwCrEMEu2ynA34AfANcBJ5vZiPbesLs3EJ/rIWa2BfH5Huzu73fwOUEEnYPSvxWB3dJ7PTbtPwL4lAhsAJcTge3oNs51WjrHFum9vwjcYWYD27n2tcBKwE/S/2cQAfAnWcdsDgwD/o+4SW1EBEvS3+se4B3ib3wi8bl3ZEPib9Xc1k53f8/d/9dq877AKGA7Igj9k/jOrAOsDjwKXJ4C481EpnXrrNdvnbbd2uq8vyIyINcDSwJ3Ap8TwSxjU2Bh4IZO3le2M9M5VwXq0+PDiOq7bYmAcQSAmS1NfB/riO/aL9N7ujXtz/xe5iK+F8PS+caZ2WpZ19wTmEME10PTtX7dhTRXDZVI8pSqS3YCbnT3OcAUM3uGqN46P+vQKzKNh6n0sS+wLvHjOwI4192vTcce1t4NMlVD/JJoKH45bc7cUI8ADuggubu5e306z0HAA+l8yxE3gMGZHBcwxsw2A/Z39zPM7Atgdlau9wHi5ngncWO7h7ghrUPcRLYCbkvnOh442d0zN43XUxA9jqgPHwP8x92PzHqfOwH/NbMN3P2xtPlvWaW435rZr4kf6cMdvOdz0+c1CbjT3a/v4NiMemBPd/9nev6Wmf0TWA3A3b9IueUHzOyq9Dms3c6NeCgwHXjD3T83syOIG+ucdq79d+DezN8J+JOZHZOufVfWcfuknO0rZnYd8dlDBJa+wL7u3pT2L823v4utLQpMyd5gZscRf5+MWe6+QNbzK9z9+XTsokRJ4nx3/yptOwPYC1jR3R8zszuI0sUt6fW7Arenz/Lrk7r7Z2Y2A/jS3T9M57qRCOaZwL078V3oShXiXzO/LzO7jAjMR7t7Xdp2HxFkIILZq+5+TNbnsTPxPVgHeIUo5V2XyZSY2Unp88pkFiBKk4em+4Kb2a7E97XHUSDJ3zbAYL75gUDKwZvZCHfP3OS+7vXi7tPSj2fulINclsiFZXuEyA21tmb6/4nsHyBQk/6159OsmxPA0+n/VYkccz/gvVbnHEDkttpyF9/krjYjcqQ1wCZm5kSQ3NPMFiZylueY2R+yXj8XMFcKxGsCa6Zg1dowvvlsWvcc+oyo2mmXu882s98RgeTY7H2pCuuzrE2z3H0Bd7/DzIab2WmApTSsTJTEMud9yMwuIKpmjsoK6q2dBfwV+MTMHgEmAxPby/0DFwHbmdkBxN9ldeLz65d1zHutqkem8c3nsCpQn4JIRodVnkTVzeBW2y4hAh7A9kRVarb/ZB6k6r1LgL3M7Acp3ZnvaSbdE4G/mtn8RNXpKL5dyurIVcBBqeT7bkrPrjm+NqMh63GmdPV61rYviWpliLSv3d730d2fMrM/EZ051iXe7xppf/bfqSEFkYxpRHVlj6NAkr/R6f97s27CmcbC/fkmt9zWjaMPUUUEuVczzkj/b0B8+bO1d3MCmN3GtTOvmUG0S6zXxuvaq8/9G5FbXoaoajiNaK/ZhKiam+Lur6UbB0RV3QNtnGdWuv4/iXrr1j7OetzeZ9iZzOeUfXPNBJnsYN0CkALPb4AriQB0GlHaWyxzYKqn/wHxuW5hZue4+3em0nb3f5vZUkSV4ZbE53CEmW3o7p59bDrn3cAKRFXJ1cCTRK+mbB19Di189zOZQcceAXY3s7ncfVZKdyPxncDMPmrjNV9/91LV5ONE6fou4rvxEfBE1vH3EAFrO+K+8zFRJdupdON+mShtvZau/Y9cXptlZhvb2isVziAC/mFt7Ps4tXs9mp7fCtxHtFm93erY7n5fq44CSR4sxo78mMhFXtxq9znADmZ2SEfnSEX5t4mb+N+zdq1H21/ETM53UXe/NystFxJVMn9q51JDzGxpd38nPR9O3HReIX5kg1N6GtL5+hHtELcTOdNv3STd/W0ze4lUrww8TzReHk3k8u/Men/vAstlzp3OfyDwg9Qg/TKRw3zL3Wem/csTVRnH8O1SQ0FlpynLIcDx7j4+K70rEVVUGYcCPySq9SYR1XPfGWOTqjwedPfbgdtT28gHRG7cWx2+GlG6W8PdX0ivX4Coesr1BvQcsIuZze/umc9t7U5e8+eU/qP4bskDoiG9I78gSq8bZXLgZpYpbfSBr4P2dUTX4hrgmla59WxtrW0xkfiOvEZUKc1q45hCeZl4T29mrpOqgM8jPqMViZLfgpnP2My+n17bIwNFZxRI8rM78cU5y93fyt5hZmcRQWb3HM5zFnCGmb1KVDmNBtanjRy8uzeY2U3ApWb2K+KHtTfRg6ejvvctwE1mNhbI9CS6zt3fSoHsceDmFPg+JG7gPyV650DcRBe0KHa9lerC7yJybZPcfY6ZPUHk8rYnet5knAr8MV3nPiJI/jG9b4jg92vgKjM7k7jRXAgswHers0rhE2Ckmd0N9CfqzNchcu5YjKk4DTjc3R8ws5OBs8zsn20EphWAnc1sfyLHviXx+T/ZxnUbiRLOjmb2OVGldXpKQ0fVltluIHrmXZPaOZYGftfRC9z91VSVdmkKmBOI3PVyRAeN3Yhea+35mPhbbWdmTxEBNhOEs9M9kfh+9yOCdXumAyuY2bJZv6triM9iJeK3UUzjiY4WV6Tf8UAikzAP0Za0APG739XM/k4ElnPTa3P9O/Uo6rWVnz2Bu1oHEQB3/xeRS98/h/NcRHQ1HJdesxJRr95elcS+RC74SqLb6VbA9u5+XwfXeJ8oXUwG7iDq+w9Mac106X057Xs2pWGku7+SXn8bUWX1At/Ubf+N+OH8K51nFt8MassU/XH3S4j2iSOJEtCpRA+sk9P+D4ic/WJEdUim+/MWHmMMSm03olfQc0SV23ykhtRUrZGpcrokHT+OCHgTU/VUtl8Tn8lNRAlkLLBHVtvZ11JpcR+iUbo+XedhIjisk0vCUw55U+Lm9yRxUzwzh9dN5JuqzWvT+7mF6Nq6rbt3lEm5kSg9Xkz8fX9H9BZ7MzvdqR3pZeD5Vu11rf2J6E7/Sur1lfmO3BsPo7RWLO7+HvF9XJr4DCcTbUJbuvtMd3+UyGgdR/ydLiDacR4kx79TT9NHKySWn5mNBF5093eztk0G3nX3fcqXMpHKYWbPEb3Fxnd6sJSUqrYqw57A8qmqairRx35zNE2ECGa2HdG5ZHmilCYVRoGkMvyaaMj7BzH6+VVg51Q9JtLbnUgMlt3T00wH0OZYl7Zs5e49bbqiiqOqLRGpSmY2mO+Of2nt3cy0LFI8CiQiIpIX9doSEZG8VHUbyXPPPddSU9Mru22LiHRbU1PTJ2uttdbChTpfVQeSmpoahg0r5no7IiI9T11d3XfGvuVDVVsiIpIXBRIREcmLAomIiORFgURERPKiQCIiInkpWa+tNCvqRcRKYs3EUqANbRzzd+CONGOsiIhUuFKWSLYFBrj7BsQUzOPaOOZUOp/yQEREKkgpx5GMIOb1x90fN7NvrdpmZr8gFkXq6hKaIiIVZfLkyUyaNCmnYxsbGwEYPDi3PPSoUaMYOXJkt9NWDKUskczHt5dMnW1mcwGY2arEeswnljA9IiJlN3XqVKZOnVruZOSllCWSz4kp0jP6Zq27vAexrOi/iOU9Z5jZm+4+uaMTNjc3U1/f0UJrIiKlt+yyyzJmzJicjh03Lmr5cz0eqLj7XikDySPEGuA3m9n6wIuZHe5+VOaxmZ0EfNBZEAFNkSIi1a+2thagpPeyurq6gp6vlIHkL8AWZvYo0AfYy8wOBxrc/c4SpkNERAqoZIHE3ecAB7ba/Gobx51UkgTR+xrERCqFfns9S1XP/ltKmcawXL/MIlIY+u1Vvl4dSEaOHJlzzmXs2LEAjB8/vphJEukV9NvrWXp1IBGpVKr6kWqiQCJS5VT1I+WmQCJSgVT1I9VEgUREJAfjx4+noaGh8wO7aMqUKcA3GYJCGjp0aFHO25oCiYhIDhoaGnjp+ecZNHdhb5sts+cA8Fb9ywU97/QZszo/qEAUSEREcjRo7rlYd9EFy52MnDz54aclu5YWthIRkbyoRNJDdaX7KKgLqYh0nwKJAOpCKtKZxsZGps+YVdIqo3xMnzHr6wxisSmQ9FBd6T4K6kIqIt2nQCIikoPBgwcz/cP3q6qxvVQ1DGpsFxGRvCiQiIhIXnpc1ZZGn0qlqsbvJuj7KZ3rcYGkoaGBZ198hTm1ha0b7DM7Pqq61z8o6Hn7NpWmV4WUX0NDA68+9xyLFfi8A9P/0557rsBnhsJ+26Wn6nGBBGBO7WC+WmXrcicjJwNeuavcSZASWgzYhz7lTkbOJtCS87HVWOLqammrGN1/m9MUKTX9CtvSoClSRKTqNDQ08PKL9SxQu0hBz9t3dg0A774+taDnndb0UZeOHzp0aEGvn5EJlMuuuGLBz12sNLemQCJSIo2NjXxI13L55fY+MKcLg9oWqF2ETVfeqXgJKqD7X72xS8cXq52oJ4zhUq8tERHJS8lKJGbWF7gIWANoBvZ194as/YcBmazMJHc/uTvXaWxspG/T1Kppe+jbNJXGxrnLnQwpgcGDB9P37berro1kAU2bI50oZdXWtsAAd9/AzNYHxgHbAJjZCsCuwHpAC/CQmf3F3V8oYfpEJA+NjY1Ma/qoy1VG5TKt6SMGNlZPUK9kpQwkI4DJAO7+uJmtnbXvHWCku88GMLP+wFfducjgwYN549MZVdVrSxMlikg1K2UgmQ/4LOv5bDOby91nuftM4BMz6wOcDTzr7q91dsLm5mbq6+u/ta2pqamQaS6Jpqam77yPcqQBKHs6erJq/G5C7t/PAQMGVF1j+4ABA8r+ne8Jv71SBpLPgUFZz/u6+9cdnc1sAHAFMB04KJcT1tTUMGzYsG9tq62tTZeqHrW1td95H+VIA1D2dPRktbW1vE3he219kf6ft6BnDR8AK+f4/aytreVTvixCKoqnt/726urqCnq+UgaSR4CfAjenNpIXMztSSeQO4F/u/ocSpkmkZIrVp//jNA5hqSKMQ1iA0o1FkOpVykDyF2ALM3sU6APsZWaHAw1AP2BjoMbMtkrHH+vuj3XnQn2bGgvea6vPzMhptfQf2MmRXRNTpBR60gypRBqH0Ht0ZYXSro7cr8TVSUsWSNx9DnBgq82vZj0eUIjrFHv06YrfK/RNfzHl+ER6sSFDhpQ7CXnrcSPblesTKZ9idP/9aub/ABjQf56Cnnda00csSXFu4l1dobTa9bhAIiLlUbzagJiiZcnvLVPQ8y7JENUGFIgCiYgUhGoDei8FEqlKXWnMbEyTDnZl4GclNmiKVCoFEunxpk6N6cc1g4BIcSiQSFXqSmOmqkZEikuBRKQC9bZxCFLdFEhEqlxPGIcg1U2BpIoUa01sqKx1saX3jUOQ6qZAUkUaGhp47aVnWGbe2QU/93wtsS7DV28+VdDzvv1Fv4KeT0QqjwJJlVlm3tmcsPYXnR9YIU59uhhz0opIJdGa7SIikhcFEhERyYsCiYiI5EWBRERE8qJAIiIieVEgERGRvPTq7r+ahkJEJH+9OpB0haahEBFpW68OJNU2DUVjYyMfT+9XVYP83prej4XTeiAiGaoN6FlKGkjMrC9wEbAG0Azs6+4NWfv3Aw4AZgGnuvtdpUyfiFQe1QZUvlKXSLYFBrj7Bma2PjAO2AbAzBYDxgJrAwOAh83sHndvLnEaK9bgwYOp/fz1qpsiZYAWlJJWqq02QDpW6l5bI4DJAO7+OBE0MtYFHnH3Znf/DGgAVi9x+kREpItKXSKZD/gs6/lsM5vL3We1sW86MH9HJ2tubqa+vr7wqaxQTU1NVdlfu6mpqax/p6amJoBe9V0RKaWcAomZDQK2IqqcAHD3q7txvc+BQVnP+6Yg0ta+QcC0jk5WU1PDsGHDupGM6lRbW8tX5U5EN9TW1pb171RbWwvQq74rIh2pq6sr6PlyLZHcAbwHvJOet3Tzeo8APwVuTm0kL2btexI4zcwGADXAMOClbl5HRERKJNdA0tfddyvA9f4CbGFmjwJ9gL3M7HCgwd3vNLPxwENE283x7l6NGXARkV4l10DygpmtBzxHKo24+4yuXszd5wAHttr8atb+y4DLunpeEREpn1wDycZElVRGC7BC4ZMjIiLVJqdA4u5rFDshIiJSnXLttfUz4FdAf6JtY4i7a4yHiIjkPCzhROAkotfWRL7d20pERHqxXAPJVHd/DMDdrwKWKlqKRESkquQaSJrNbCOgv5n9GFi8iGkSEZEqkmuvrTHAysCpwClEVZeUwdtfFGca+c9m9AFg/rm7O9a0bW9/0Y+VCnpGEak0ufbaetfMVgaGAycDrxU1VdKmoUOHFu3c76Q1HxZdbsWCnncliptuESm/XHttnU60iwwDZgDHAjsXMV3ShlwX9snn3OPHjy/aNUSkZ8q1jWSEu+8BfOHuE4Hli5gmERGpIrkGkrnSZIotZtYPmF3ENImISBXJtbH9XKAOWBh4Ij0XERHJubH9FjO7FxgKvOHunxQ3WSIiUi06DCRmdkU723H3vYuTJBERqSadlUjWBmqBa4HMGiIiIiJf67CxPU3MuC2xxO4xwAbA6+5+dwnSJiIiVaDTNhJ3f4kIIqRpUs4ws6Xdff1iJ05ERCpfrgMS5wO2IwYhzkNUdYmIiHTa2L4DETyWAW4HDnT3N0uQLhERqRKdlUhuItZUfx5YDTjdzABw912KmzQREakGnQWSTdP/LeTZY8vMBhJVYosA04E93f3jVsecDYxI6brU3S/L55oiIlJ8nfXa+re7/xs4ClgQeDhrW1eNAV509w2Bq4ETsnea2abAUHffgAgmR5vZgt24joiIlFCuc239BvgRUGdmfzCz7sw1PgKYnB7/A9i81f7HgMwgxxagHzCzG9cREZESynWKlFeBo1LV0/nAS2b2IHCsuz/d+ngz2wc4rNXmD4HP0uPpwPytrvEV8JWZ9SfWhb/U3b/oKF3Nzc3U19fn8hakE01NTQA98vPsye9NpBLk2v13K2A0sUritcChQH9gErBG6+PdfQIwodU5bgcGpaeDgGltXGdB4FbgAXc/o7N01dTUMGzYsFzegnSitrYWoEd+nj35vYl0R11dXUHPl+vsv7sBF7v7A9kbzezkLlzrEWAU8CSwFfBQq3MNBO4Dxrn7dV04b1k9u8mz7e5bbPRiLD7628vbV+rxGzZsGM9feDan4yst/Tpex3d2/JoPrNnuPslProHk0+wgYmZXu/se7n57F651MTDRzB4mVlncJZ3rLKIUMhxYAdjPzPZLr9nL3d/owjVERKTE+rS0tLS708x+RfSuWhBoJLoA9wFedvfNSpLCDtTX17eouqIwevJSuz35vYl0R11dXd1aa621dqHO12GJxN0vBC40s+Pc/fRCXVRERHqOzqZI2drd7wKmmtn+2fvc/dKipkxERKpCZ20kQ9L/ixU7ISIiUp06q9qamB4uSIzreKX4SRIRkWqSa6+th4GzzGwQcCVwk7t/WbxkiYhItchpihR3v9XdtwZ2AkYC7xc1VSIiUjVyHdm+DLAH8AvgGWJAoYiISM5VW7cBlwMbuvv0IqZHerHx48fT0NBQ8PNOmTIF+GY8SaENHTq0aOcWqQa5Ttq4jpktDixoZoOBJdz9seImTXqbhoYGnn35WVigwCdOFbjPvtv+9Bnd9p0Z40R6n1yrtiYAGxDrtdcCrwPrFzFd0lstAHM2mVPuVOSs7wO5rsQg0nPl+isYBnwfuDs9/qpoKRIRkaqSayCZ7u4twDzu/gkwdxHTJCIiVSTXQFJnZr8B3jOzG4nVC0VERHLutTUReA/4kuj6+2TRUiQiIlUl10Aywd1HpMd/K1ZiRESk+uQaSP5nZucCDswBzf5b6SZPnsykSZNyPr6rYy1GjRrFyJEju5U2EelZcg0kj6b/F03/t78allSlIUOGdH6QiEgbcg0k97d6PtPMlnL3/xY6QVIYI0eOVIlBREoi10ByKrEmSR2wJrHm+gAzu8zdzy5W4kREpPLl2v23CVjd3XcG1gDeBlYFfl6shImISHXItUSysLt/BeDuzWa2kLvPMLOc54cws4HAtcAiwHRgT3f/uI3jaok2mWPcfXKu5xcRkfLINZD81cweJsaPrAPcaWZjgJe6cK0xwIvufpKZ7QScABzSxnEXosZ8EZGq0WGJwsz6ALj7KcBBwBPAGHc/HbgV2KcL1xoBZEoY/wA2b+N6vyFKI8934bwiIlJGnZVIHjSzXd39bXd/AXghs6OtaqkMM9sHOKzV5g+Bz9Lj6cD8rV6zGbCiux9gZsNzSXxzczP19fW5HCpVoKmpqdxJ6JampiZ9D6VX6yyQnAXcbWanuvt1uZ7U3ScAE7K3mdntwKD0dBDfXclhH2BZM3sAWBn4oZl94O7PtXedmpoahg0blmuypMLV1tbCp+VORdfV1tbqeyhVpa6urqDn6zCQuPvfUtvI2WY2iphzK7Pvn1281iPAKKKdZSvgoVbX2iXz2MyuAm7sKIiIiEhl6LSx3d0/NbMngSOBZqAP0Rje1UByMTAxBaYZwC4AZnYWcKu7ayJIEZEq1GEgMbPlgSuBj4H13X1qdy/k7k3ADm1sP6qNbaO7ex0RESmtzkokDwFHd6V9REREepfOAsl67v4ugJnNBywL/Mfd/1f0lImISFXocBxJVhD5BfBv4HrgcDM7oQRpExGRKpDrFCeHAesDnxATOG5XtBSJiEhVyXWKlDlpjq0Wd28xM1VtScE1NjbCNOj7QM5TuJXfNGgc2FjuVIiUVa6/2IfM7AZgKTO7BHiqiGkSEZEqklOJxN2PM7ORwDNAvbvfVdxkSW80ePBg3vryLeZsMqfcSclZ3wf6Mnjw4HInQ6SsOhtHsn+rTZ8BS5jZ/lqzXUREoPMSyeLtbNc07yIiAnQ+19bJAGa2UatdWrNdREQArdkuIiJ50prtIiKSl1wDybfWbAcWcvcZXXi9iIj0UKVcs11ERHqgnEoUBVqzXUREeqCcSiRmtjQwEhgQT217d/99UVMmIiJVIdc2jluA+YAPs/6JiIjk3EYy3d01dbyIiHxHroHkJTPbCXiWNKrd3V8rWqpERKRq5BpIfkCMH8moAYYXPjkiIlJtcg0kNwGHA/2BPsDMrl7IzAYC1wKLANOBPd3941bHjAbGAP2AO1JvMRERqWC5NrbvC2wMTAJG073xI2OAF919Q+Bq4FttLmb2vXTMJsC6wNxm1r8b1xERkRLKNZB84u7vA4Pc/QFgSDeuNQKYnB7/A9i81f7NgaeBicT68I+4e5dLPiIiUlq5Vm19ZmbbAi1mdgCwcEcHm9k+xDrv2T4k1jOBqNqav9X+hYCNgB8BA4FHzGwdd5/W3nWam5upr6/P8S1IpWtqaip3ErqlqalJ30Pp1XINJPsCQ4FjgN8QVVDtcvcJwITsbWZ2OzAoPR0EtA4QU4EH3H06MN3MXgFWIqZlaVNNTQ3Dhg3L8S1IpautrYU3irBm+1fp/wGFPS0A06B2yVp9D6Wq1NXVFfR8uS61O53o+gtwRDev9QgwiggMWwEPtbH/V2Y2gGhsXwVo6Oa1pAoNHTq0KOedMmUKACsuuWLhT75k8dItUi1yLZEUwsXAxDT54wyyfD2PAAAgAElEQVRgFwAzOwu41d2fNLMJREDpA5zi7o0lTJ+U2dixY4t63vHjxxfl/CK9XckCibs3ATu0sf2orMfnAeeVKk0iIpI/rSciIiJ5USAREZG8KJCIiEheFEhERCQvCiQiIpIXBRIREcmLAomIiORFgURERPKiQCIiInlRIBERkbwokIiISF4USEREJC8KJCIikhcFEhERyYsCiYiI5EWBRERE8qJAIiIieVEgERGRvCiQiIhIXhRIREQkL3OV6kJmNhC4FlgEmA7s6e4ftzrmj8AIYA5whLs/Uqr0iYhI95SyRDIGeNHdNwSuBk7I3mlmawA/AtYDdgfGlzBtIiLSTaUMJCOAyenxP4DNW+1/F2gCaoD5gJmlS5qIiHRXUaq2zGwf4LBWmz8EPkuPpwPzt9o/i6jSejXt26+z6zQ3N1NfX59fYqXHa2pqAtB3RaRIihJI3H0CMCF7m5ndDgxKTwcB01q9bA/gA+DHaf/DZvaYu7/b3nVqamoYNmxYwdItPVNtbS2AvisiSV1dXUHPV8qqrUeAUenxVsBDrfZ/Cnzh7rOJEkszMG/pkiciIt1Rsl5bwMXARDN7GJgB7AJgZmcBtwLXA8PN7FGgH3Cdu3sJ0yciIt1QskDi7k3ADm1sPyrr6YGlSo+IiBSGBiSKiEheFEhERCQvCiQiIpIXBRIREcmLAomIiORFgURERPKiQCIiInlRIBERkbwokIiISF4USEREJC8KJCIikhcFEhERyYsCiYiI5EWBRERE8qJAIiIieVEgERGRvCiQiIhIXhRIREQkLwokIiKSFwUSERHJy1ylvqCZbQfs4O67tLFvP+AAYBZwqrvfVer0iYhI15S0RGJm5wNntHVdM1sMGAsMB34MnGFmNaVMn4iIdF2pq7YeBca0s29d4BF3b3b3z4AGYPWSpUxERLqlKFVbZrYPcFirzXu5+01mtkk7L5sP+Czr+XRg/iIkT3qAyZMnM2nSpJyOnTJlCgBjx47N+fyjRo1i5MiR3UqbSG9TlEDi7hOACV182efAoKzng4BpHb2gubmZ+vr6Ll5GeoL33nuPpqamnI6dd955AXI+PnN+fbdEclPyxvYOPAmcZmYDgBpgGPBSRy+oqalh2LBhpUibVJhhw4ax9957lzsZIlWprq6uoOcreyAxs8OBBne/08zGAw8RbTfHu/tX5U2diIh0pk9LS0u509Bt9fX1LSqRiIh0TV1dXd1aa621dqHOpwGJIiKSFwUSERHJiwKJiIjkRYFERETyokAiIiJ5KXv333w0NTV9UldX91a50yEiUmWWLeTJqrr7r4iIlJ+qtkREJC8KJCIikhcFEhERyYsCiYiI5EWBRERE8qJAIiIieVEgKTEz61PuNIiIFJLGkRRZChzfAxrdvbHc6cmXmQ0jBrJO6WnrxZjZXsSqnG+7e2FX/qkgZnYgkYn8yN1vLXd6pDKkRQVnuvvsrr5WgaSIzGxJ4Hzixvs8cLq7N5c3Vd2XFiEbSaxg+Tvg3+5e9V8gM1sAuAT4H9AIjAO+cPcvypqwIjCzC4CFgL8RQfN+oKWnZQpKyczmB9YF5rj7feVOT3eY2UbAvsAixKKCdWbWJ9fft6q2isTM1gFuAu50923d/XfAFmb2izInrVvM7FxgPeBn7r4x8CJwrJltWN6U5cfMhgC3Ak+5+z7ufiTxPm83s83SMVX/OzGz/mZ2BdDs7ju7+/XAl8C9wCgzqy1vCquTma0G3AKMAk41swXT9qqpwjaz0cBxRKb3D8ALAJkgkst7qeq5tipR+tD7AFsBZ7n7nWn7hcAKQI2ZzXT3O8qYzC4xs+WAhdx9x/R8BHAuEUwWMrNp7v5iGZOYj2WAN9x9HICZHQr8lMgEnGlmO7j7m2VMX0G4+0wz+wI4EcDMtgP2Bian/z8CHi5fCqtPVo3DWe4+OW37npkNJEp7TeVMXy7MrB+wJnCgu79pZssC48zsE+AV4LZcSiVVn9OqNO7e4u5ziHaRfgBm9n3gv+6+FXA7sEUZk5izVOUDMIAIjqSc67JEMfhQYGmiqquqmFn2MqMDzKxfugE8BvzY3S8FXgbmlCWBBWJmQ81sSCp5bUpkZiBuEqPd/RTgY2CB9s4h7VoYeBe438zWNbPHgGuAG4CtzaxvFZRM+gNrAGPN7DQiY9EfmJ/IDC+Ry0kUSArIzA4zs1PS0w+BTKPV6+5+Rnq8GJGTr2hmthRwvJn9BHgfWNfMhrt7E/AXd38emJv40k0vY1K7zMyWAS5JufJ3iGC4tLt/6e5PuPssM9sZGEJU/1QlM1sUOA/Y2t2nApcBu5hZrYepZjYcGEbcECUHZraJmc3r7s8BKwF/AY4CHnL3HxFVXT9w9zmV2IZoZkua2S1mdgiwInAw8AHwX6JkMgY4lqixyin9amwvoJTLPY1orJ0GXAHsALzn7p+Z2YnAxsDu7v5e+VLaOTNbGNiZuMn+CVgNOAX4OXHzXREYD/zd3c8tVzq7IxXnRwKHA3ulxzsSf7dXgG2IOu/fVHGVHQBm9jPivV0FNBOl4SWAC4ic6GjgDHf/Z5mSWDXMbF5gAtEg/SrxmT5H5N7ncfc30nHHEqWVo4FZlRRMzGxd4HTgEeBzwICD3b3ZzJZw9/dSyfxSosPJmFzOq0CSJzObh2jAnJWejyJyJ3sRjbY/Ib547xJVXfu5+4wyJbdTZjZX1ntZDNiT+KFcRNxwdwDeJKq3/uTud5UpqV2S6rMXdfdnsrbtB2xHBMetgR8RubBa4HB3/6wcac2HmQ0Ctgfudfd307adiAAyAXiLCKBfAYOBce7eUKbkVg0zWwk4E3jS3c9Mvd+ecfcr02c+lqhp2IaoJty70r4/6fu+DfG7nWxmGxDVuCel/ccB2xIZjgfc/bdpe6e9txRI8pD+EBcTXXvvIurU3wJ+DBxA3HSbiKjfx91fKlNSc2JmFwO7EfWktxPvayCwDnHTOQOYj2gzaXH3j8qU1C5J9dT3AxsBVwPzEt19PyVusMsAv3L3FjOrqfIu2qOJkvDrwBNE0J9I5I4/Ai5293fSsTl37+zNzGxF4rewv7tfm7adRmQOL3H3OWa2D1FFONPdj03H9E3tpRXBzF4H7nP3/VP750RgEFE6/TtRFb8gkeF6Ob0mp++IAkk3pYF5U4juk8sQddG/IIqLTxJB5AVgr0ougQCY2ULEzXVu4ga7AJF73Ydo6+kPLA5cTuRmZpYpqV2Wepj1ARqIv9WlxFiRdYiA70Sp8Xx3P7xc6cxX6qo8xN1vNrNjiLEi/yFuFMsSpa3VgH8Au7j752VLbBVJJdkviJvt6+5+spldQ5TO69K+yUCduz+b9bqKCSJmtitRBdcIPEi0lW1AtH1+TtScDAQ+cfets16ncSTFlNpCjgNGEAFjNvC8u28EnEr0gnmXaF9Yob3zVIKUMzke2J8YkHcE8eV6yN1/SORkbwOmAgOrLIisBKxOlLIGAL8CDgLud/exRK+Uk4iS1qQyJTNvqWPEp8CfzGxN4FriprEwESAPAnYiqu/uUhDJjZltSrQnrEBUV69pZv8lfusLAwcSvfxWoVXvpgoKIgsQv4FfEtWZuxHf9yfd/SB3P8bdNyUyU/tlv7YrpVWVSLogE6HNbG6iIXotosF5caLh7eepJwfpmAGV/KM1szFEjvVO4DCiBHUj0SHgCKI955XypbD7UtXDl0Q//72JXPlvgd2JascR7v6/dGzF5B67yswOJnoI7WMxxcsRwP8RJZK9gPeACzLtXtI1ZnYGkVG8giixXwuckj0OrNKrCM3MgD2IDOI4IlNxDDA8dQLql5kWpbu/BZVIcmRmqwKXpi/W9kSd4mtEDvcFImd7dWZkq7vPqPAgMg7YHLjS3V8lirvrEdU99xA/mCtTT5WqGqmbPAvUuvt0on2kETja3S8h3t/9mQOrNYgkQ4hqC9z9SqIr6k1Eld2dwKrE91VyYGZLpB6LGWcRn/EORKnvMOAoM9s8c0ClBREz29rMrrAwt7s70Ya7KJE5vDY9fwLAs+bW6u5vQYEkB6kn1njgIeDfwCHAlsCjwCfAEe5+DXFzGl2mZObEYqqMy4lceou7fwzg7k8DNxONz8OB64gb0SJpf0X9WNrS6gYwm2j8xN1fAP4J9DOzQ9z9KOJmW5XMbCEzWzk9XZRoUAcg9bR5n8ggPER0LvhbyRNZhVJb4c3AFWa2i5mt4e6fAn8EVgZ+RvTMupyo1q44qSZkPaI9bDvgJjNbxN0fIzIZK5vZbu5+DDGguCBUtdWJ1BtjDNFj45m0bX2iXeFkou3gEOADdz+zbAnNQSot7QvUuPupZvYw8Ii7H511zL5EkDylmsZQpIF1xxLtPHcDTwF7eMydlTnmx0RX3/GV3oOuPRbzfp2Vnp4HnAO8TdwkGjIZAzN7mhgfcltZElqlzOx6orr3DuJ3fzpwH9EF/myiN+PtldiBxswWcPdpZrYxEfw245uqzqeJe9aeRLXnBV7A2chVIuncKsADRA+tTH3o40Tvl7PTIKQ7iKJixbKYXPEm4F/ufmra/Atgh1S3DoC7Xw7cUE1BJJlCNH7+m+iRNR7Yy8y+l3XMv4BTqziI9ElVD+OJbtibETnlgUSvorvM7LZU/TpcQSQ3ZrZr6oUJ0Z3/2fQ7eImY5fpBoj20DvhPpQURM5vfzK4kSkwQNSV3EwFjFjEkYQGid9lcRM/Lgi5poRJJO9Io9NlE49R5xEjWG939g7R/EeBYdz+sfKnMTQoUhwO7eUxtQqo7nWExS/Ftad+D5UxnV6V2mw2BF1MVRPa+IcAuRFXdzpmG9WqXaRhNPQePJGYYWJ+4YSwN/JAYTa3qrE6k0t1lxAC8sR5T46xP9NCqA75PlHJ/QDRQH+EVNiOFxTx+VwCT3P3ktK0vcCFRErnO3X+ftm8OPJh+9wXtIKASSfvuIG5SmxNTg6xFVPlkHEdM9tenkhuizewk4NfEqPppadtc6cvU192fInoz3WAxNUI1+QPxd7rdzNY3s6+7YHrMLXUJ0ch+fJnSVxBmdpaZ7ZaetqSbwNPE+3OiZDLI3d9y978oiHTOzBYnShrLEVPhzAJItQ2ziQ4Ku6fP9A5igstKCyJbEW2Z04GnLab+yTSYX0B0Drg4c7y731uMIAIKJN9iZgumxipSzv0coo5xEaJUsomZ7WRmtwEz3H2Mx2y/FVmss5hwcQFiMNrvgYmp4W1WytnOAXD3icAG7l5tExReRfSWu4cI8telgDIvxNTpxNiRqg4kxLxIY8xs7fQ365cyAfcT7313YPmyprCKmNkaRFvHE0SV6Ob2zUzXAH8mxtvMNrMaAI+5qComw2hmSxNjv/YklnTYhBgnlPE+kclYpPVri3G/UtVWkhpiLyKmQphMdOl9jRgBehiRQ9mCKInc4O7nlCmpnbKY6n0X4HN3vzltmxs4AVjV3bdP2/oRq7q1FCOXUmxmtgpR9fgzoq1gEjHp4nTgene/vYzJy4vF7LJfZD3fD9gV2CmrerU/Ue2ygrtXbS+0UkulkZXd/X6LheZ+QnR3fyjl2Ncjerp9P9N5oZKkdr+p7p6pYZibGBu1OHC3u/87bZ8A/Nndnyx2mhRIEjObiwggixM9HnYiptZ4hggidcTNeSl3f6tc6eyMxdThCxLTm/wXuCczqDAFmHOJ4JHTrJ6VxMyWcfe3swdNpbasnxC9504jgv/2wOzUYFp1LCZZPIjIFZ9l3wyEPRVYzd23sRjN/nei901Vvs9SM7OxxJxxn7j7n7K2H0xkRK4iJmKcnUp/T5cnpW1LVc+XEev/rEZ0029M343BRDCZi5iw87FSpq1XV21ZLGZUC5DqSEcTo1ffcvctiG69z6R/g4AlKjyI/JxoOD8BWIoo1o60WPUMj7VEfgcMM7P/K1tCuyF1afyzma3oMUleZnXPu4kR7Ae5+yNETu3PVX5zfZeomviZmZ1DNPhCVE82mNmTxAwEZ1X5+ywZixVK1yGqCb9VhevuFxDTGo0m1heByDhWjNR1/69EoNuBGGg6HeiT2jwbiTEwCwMrlLrttteWSMxsPmL2y9nEzXWau79rZlsSjZi7pIa3TC+I/l7Bs8Km8S4/AU7MdG9NN9/NifVDbs10+cv0Ny9bYrvBzOYn5gJaiWgc/Tz9UOYhlRbdva4aq+gyUseI54ib3bFE4FiSCJaPEmNFniW+r5e5+7/Kk9Lqkkp4q7h7Zpnh4cQKpg3AE6kEMojIOF7gFTb9O3w9Sez+7n5Y+i2cTcwq/j4xwep9KYO1nJdhaejeHEj6Ebm65YgxIBsQU2g8b2bbEoO+NnT3D8uXytykuvJziK5+T6bSxgnEtOHfI0opHwPXVFof+K6wWB/lEGI24iMzASPl0K9JOcuqZWYHAXu6+3ppXMBrRG+7JYkR1SOJ+ZJGu+bO6pSZzePu/0vtSzsRvS+3Ixb6upOYtPNnnjVrb6UxMyPmS5tDBL7HiFULa4nemAcTbaEntnpdSTNUvS6QWKwQ9kGqa9+KyKmMs5gaen3iD3Ua0cD+hMf8RRXPzA4ncrE3Ed2WrwYeJoLlXcAbxNoJTWVLZAFYzOh7GFEKuY3o/vhWNbb5AJjZD4CF3f2e9Pw8YlDlO8Ta39e7+++yjq/aCSZLKX1PfkMM3nyZ+K68Q9yQ/+ju75jZ74F6d7+hfCltn8Wy3RsSbZ1/JaZoWh6Yy90fTsfsSPTKPLKcmcRe1UZiZr8j5pfJrDHeBxhhZtsQVSTHEu0htxEjoKsiiAC4+x+J2V5vIHr2jHP3J4gR+BcC51V7EAFw99eAK4kG9deBO6s4iPQhAv2fzez8tPkpYkTyp0QHgrPSsZlu6QoiHci0C6TvSTPRNXqIu2/v7ocAp6UgMpzoMl5xa9VbzId3BdF1fzsis7RBqh15GljUzBYxsyOIEsmV5a5p6BUlkvTlugFYDBjp7l9l7buXaKD6WaYh3cwWd/f3y5LYPKT3uRgxIvcVYhGnBncv2ORslSC1WY0kxvLcW+70dEdWT6ytibrujYlSVhNxg9uGWNp1tlfB7AmVwsyGeAxGzbSDnk3MRXYt0aPpYqCeWC3zaK+wterTuJVriJUWd03bxgDLufvRqZPJWcRiejXAvu7+YbnbBufq/JDqZjEj7MT09EtgGTObAl8PzLmOyLG8ZWYDUpD5oDypLYjvE+tH9yf6lJ9X5vQUXMqVV/NCVMcBT6W2nTeImWR3IjpGLE8spHQO0b33P+VKZzVJ7YSHAieb2V1EG8gLRMeEM4lq6/uIRZ0GExN3vl6m5LbJYlGyF4DHgQXTeJfdiKB3JHzdu/RwS1McpdeVvbqzR5dIUhD5HrC6u1+a+pFvAhyWVfr4P6J6YahX8PohuUqlkr7A4EocTCWxXgRR992fmNfpD8B0dz8plbYuIUomJ2QPSpS2pTEUhxIljZ8SM/W+SATmx4kSXl+iuvqqrNeV/QacLVVnLeruPzGzM4nuyl8BO7r7F9kDiLNeUxG9FHtsIEljKg4jShd17n5G2n4e0ePhmKzusNt7FY+CluqTeqAdTIwHOJ6YVPNMd38ttYfMUc+s3FhMPLonsRrmMGJevEeJ2Z6XItrTNgVedffflCuduTCzvxNdwE8gMhQvAJdX8tAD6KGBpJ0xFTWZP4aZXUv0v/5dT2iAluplZr8lqlq2IGag1diQHJnZ8DQINTPg8HN3P9bM9iBy87d4hc9obd/M1pBpM5uX6J11HjGP2unEuKKbKrnGpMf12kp1pasTubuXzGwTM3sAuMXMTk6H/YaYfnvBMiVTBAB3P4XoFPEqUQ0rObCYI+seMzsotSUcAaxmse7OX4lqrl0slsjOfl0lTby4DzDBzJb0b+a7+4KYU+1QojH9NmBZogdaxeqpJZLWYyquIrpV3gCMcvcXsxurRKS6WKwbcg3RgP4BsUTC88Cy7n5VCiAbAbdV8qBiM8sMov2tx+qG/d19ZhpDclfqwl/xelyJBNocU3FuGsBzH2meHQURkepiZgub2cGpd+XjxGDD94nf+RZEO9NwgFSl/edM19iyJbodqeEcoh13MeAgM6tNQWQxolPQwKzjK+49ZOuRJRJod0zFFPXJF6lOZrYRkUFchFg6YCNiNuTxFpMaHgrsS4wPubZ8Kc2NfbPa5VLEoOF64DPivf05u4dZpevpgWQzeviYCpGezsxGADOIiVVfS7MAzCRuvDsR1UKPm9k8wCLu/kYZk9uh1t11M12Q05QuP0j/Jmc6CVRK997O9NhAAhpTIVLtUgeZtYl2kEy36D0tJlZdGjiQGDOyn7tPz3pdRdyAU0np+8DAzHxqOb6uosa4dKZHBxIRqV5m9gciE7hf1rYbiW6++6cemucBSwB7eYUtjWCxpO84Yv4+A3YA+mZP0ZSO6+fus9Pjpd39nZInNk89srFdRKpbmnNqIeDo9HzutGs0sICZDXX3mcRU6ntWYBDZhFj7/Xx3P8rdtyHWWN/DYj2RzHF9UzvJPGZ2OTFFTtXp8XNtiUhVmkG0bS5mZp8CM9OEhQOIWXGb4ev58j6vwKqgYcC57v63FBQvJCZa/BSYbma3ENV0c8xsKLG893mVPoCyPSqRiEhFMLNtzOyXZvbLFCBmAJu6e0v6NwuYjxgzMjP7tZUSRMxsSHq4MZB5PB/wqLtvCfwT2MzdZ6UgsiVwAXBoNc9qoBKJiJSdmR1PdOe9A/i5mf2QyKXfaGbNxLohzcBJxNxTFTdDd3oPc4gZhicCO5rZJI+lb69Ih60AvJmOH0rMEbZjJU9/kgs1totIWZnZpcSqf3tnbbuPWEPkHuCXRM+nvsCENLi44qTR9ofwzRQto4hlkscTy+WeToxt29fdp5vZQKC5UkpT+VDVloiUTZozaxNiOn3MbEDatTuxlsjgNFPFvsD+7v5wJY3yzp7LK422v4qYbXgRYs2cqcBFRDBpdvcdUxDp4+5f9oQgAiqRiEiZpZl7ZwK/d/fGzEzdaU2OG939uaxjK2J8CHxdNfUQ0EjM5Xcbsf7JjkTD+k3uXpca2+fJWraiYt5DoahEIiJlkTXf1CFEFdCv0jxazWlG3x/Sqh23Um7AZjbS3RuI9pCXiHmxfgDcTpSw9gEuNLPvpeUrpqXX9bggAiqRiEgZZc03tSRwJbGm+jRi9u5r3P2asiawlbSC5UDgHeAA4C6i2m1JIqjMIrr+bkLMmbVHamzv0RRIRKSkOphvaj3gMqLb7+GVNqbCzBYh2jr2IhbOuoIYrf4BcBBRPfenTBVW1ut6ZCkkmwKJiBRVLvNNZa0QuAHwX3d/p9IGGZrZ94FT3H379HwPopPA/xFjRvYGpqdjetWNVW0kIlI0ab6pW4hqnl+b2dxZPbOyzQXg7o8BTelxRQQRM1s09RRbgRiZngl8VwN3AtcBU4DJwJO9LYiASiQiUiRpvqkzgdPc/W9p26+Jqqub3P2ztC1TtTUPcD5wdaVUa6WR59sDZwNrEqWPC9395axjbgVmuvvO5Ull+Wlku4gUS0+Yb+phYGsigKxC9My6xMzeIaqxHifGvCxTthRWAFVtiUhB9ZT5ptL66U3AOcB6RPXcxcBPgLOIgLgRMMDdPfXo6pVUIhGRgqn2+aZSg/r/ufsFaf30fu7+tpmNA+Yluv72S4MkWw+UrIg2nXLotRFURIriPmB1M9uRmGjxVeAIM1sxrblxPjCUaAshHbN7JQSRpD+wt5ltl563pGBSTwTCjYEN06JaQO/o3tsZBRIRyUtPmG8qM39XKmkcDRxlZmu3StvjwLPAx2lRLdJrenUQAfXaEpE89IT5ptKcXm+6+yVZ2w4AdgG2dfdPzexwYrT6Xu4+tTwprVwKJCLSLWm+qclmNhYYnja/BGwJfAhsSoyv2NXdX8/q5ltJQWQ+IhD2IQLhA8Ct7v5lau9ZE2gAVgd+5e5vlCutlUyBRES6pCfMN2VmKxKrL15qZscAjxLp/jWwNHAM0X7zW6JzwJap8b2iRttXCgUSEclZT5lvKk3FchuwBrATsBIx6PBcoIVo19kCGOHu76XXKIi0Q43tItIVCwNzp0byB4HfA9cAs4HrgUHEVCjfWnyqUoKIma1sZrVpKpbxwMFEN+U1gL8Al7r7L9z9AGA/BZHcKJCISKd6wnxTqc3jMeDsVD03iVgHfiEi7X9097vNLDPv132Z1yqIdExVWyLSoZ4y35SZLQccSQTDd4i2nd2J+cCWIdZAGeHuM8qVxmqlke0i0pmqnW8qNaovAbwIfEy05ZwLrE2kdwgRSH5PVHGp5NENqtoSkXb1gPmmBhCdAA4l5vt6nVgb/kaio8DdRLtPH3e/0N1ntW7fkc6paktEviV7vqn0PLMc7jDgd8C/gFvc/dNWr6uonlkZaRnfHYBfANsBpwGT3P2vaf9wd3+kjEmsepWWexCR8utR8025+7vufh7RK+tUokp/5az9CiJ5UiAREaDnzzfl7uOAq4meWvua2dxlTlKPoaotEel1802Z2UB3/7Lc6egpFEhEerneOt+UBhkWjgKJSC+l+aakUBRIRHopzTclhaJAItLLmNnKwNvu3pRKIrXEOJG7gHmA49z97nTsZpmpQhREpD3qtSXSi2i+KSkGBRKR3uU6YpbeFYBLgOWIKU8WJEokh5jZ3O4+q2wplKqjubZEejjNNyXFphKJSM+n+aakqNTYLtILaL4pKSYFEpFexMyOILr59gdec/czy5wk6QEUSER6GTMbDuxGjBFZRQs5Sb4USER6Kc03JYWiQCLSi2mQoRSCAomIiORF3X9FRCQvCiQiIpIXBRIREcmLAon0KmZ2tJm9b2YDOjhmNTPbKD2+sb0lWc3sGDNb18wGmNm+HZxvtJm9mRaQymy70cw2yeOtiFQMBRLpbXYFbiTW32jPz4FVANx9p/bGWbj7me7+JLAY0G4gSWqJ+a1EehxN2ii9RioBvE7MenstcJWZrQecTywz+y5wMHFBxpAAAAKCSURBVDAamGFmzwA3A6sBzwJruPv/zOxIYiXBNYig9HNgFTM7ERgJ7OfuL5vZVsDWxPK1E4HhZra1u9+VlaZ+wJ+JFQmHAP9w99+a2VXATGBZoCZd56fEJIvbuPvrZnYGsBGRIfyju99S+E9NpHMqkUhvsi9wubs70JyCyKXAXu6+HnAvsChwFXFjfjK9biaxkuDP0/OdgKuzznsa8Iq7/x64DNgzbd8bmJAez07bzzOzIVmvXRp43N1/DIwAxmTte9PdtwTqgeXdfVRKx09TkFre3YcDmwLHm9kC3fxcRPKiQCK9gpktCIwi1tuYDMxPrE2+qLvXA7j7Re7+TDunuBzYw8zWJeaomtrOcTcBPzOzRYCls8/n7lOI0s9FWcc3AuuY2XVE1VdN1r7Ma6cBr6THnxKz+a4GrGVmDwCTibmzlu34UxApDgUS6S12Aya4+5buPhJYD9gS+DKt15FpiN+OWI/jW7+NFAT6AEcSpY7/b+8OVSIKwjAMv8ngJXgDf1bYrkaTYBRkg3G9EINNMIgWm2AyyyKCze5fvACToFjXMKMcRdaFOSro+7SBmWFOmY+Zc85M11v9zHwGxpTAOPlkHPuULazVWh4CD5m5CewB850j3Kf9LXwLjDNzufZ1CtxNqS99G4NE/8U2nYm9TvhnlG2s44i4BBYpV8/eAKOIWPnQxxGwRAmKrntgLiJ2a/kQWKfcRvhOZk4oW16vK48LYC0iroEDynW3CzM8zznwFBFXdbyTzHycoZ3UO49IkXoWEQNgJzO3fnss0k/wqy2pRxExoqw4Nr6qK/0VrkgkSU18RyJJamKQSJKaGCSSpCYGiSSpiUEiSWpikEiSmrwAx1teOWbd8dYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='ActivityName', y='angleYgravityMean', data = train, showfliers=False)\n",
    "plt.title('Angle between Y-axis and Gravity_mean', fontsize=15)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.axhline(y=-0.22, xmin=0.1, xmax=0.8, dashes=(5,3), c='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 564) (2947, 564)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('UCI_HAR_Dataset/csv_files/train.csv')\n",
    "test = pd.read_csv('UCI_HAR_Dataset/csv_files/test.csv')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc_mean_X</th>\n",
       "      <th>tBodyAcc_mean_Y</th>\n",
       "      <th>tBodyAcc_mean_Z</th>\n",
       "      <th>tBodyAcc_std_X</th>\n",
       "      <th>tBodyAcc_std_Y</th>\n",
       "      <th>tBodyAcc_std_Z</th>\n",
       "      <th>tBodyAcc_mad_X</th>\n",
       "      <th>tBodyAcc_mad_Y</th>\n",
       "      <th>tBodyAcc_mad_Z</th>\n",
       "      <th>tBodyAcc_max_X</th>\n",
       "      <th>...</th>\n",
       "      <th>angletBodyAccMeangravity</th>\n",
       "      <th>angletBodyAccJerkMeangravityMean</th>\n",
       "      <th>angletBodyGyroMeangravityMean</th>\n",
       "      <th>angletBodyGyroJerkMeangravityMean</th>\n",
       "      <th>angleXgravityMean</th>\n",
       "      <th>angleYgravityMean</th>\n",
       "      <th>angleZgravityMean</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>ActivityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc_mean_X  tBodyAcc_mean_Y  tBodyAcc_mean_Z  tBodyAcc_std_X  \\\n",
       "0         0.288585        -0.020294        -0.132905       -0.995279   \n",
       "\n",
       "   tBodyAcc_std_Y  tBodyAcc_std_Z  tBodyAcc_mad_X  tBodyAcc_mad_Y  \\\n",
       "0       -0.983111       -0.913526       -0.995112       -0.983185   \n",
       "\n",
       "   tBodyAcc_mad_Z  tBodyAcc_max_X      ...       angletBodyAccMeangravity  \\\n",
       "0       -0.923527       -0.934724      ...                      -0.112754   \n",
       "\n",
       "   angletBodyAccJerkMeangravityMean  angletBodyGyroMeangravityMean  \\\n",
       "0                            0.0304                      -0.464761   \n",
       "\n",
       "   angletBodyGyroJerkMeangravityMean  angleXgravityMean  angleYgravityMean  \\\n",
       "0                          -0.018446          -0.841247           0.179941   \n",
       "\n",
       "   angleZgravityMean  subject  Activity  ActivityName  \n",
       "0          -0.058627        1         5      STANDING  \n",
       "\n",
       "[1 rows x 564 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X_train and y_train from csv files\n",
    "X_train = train.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_train = train.ActivityName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X_test and y_test from test csv file\n",
    "X_test = test.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_test = test.ActivityName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and y_train : ((7352, 561),(7352,))\n",
      "X_test  and y_test  : ((2947, 561),(2947,))\n"
     ]
    }
   ],
   "source": [
    "print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))\n",
    "print('X_test  and y_test  : ({},{})'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's model with our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels that are useful in plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using raw time series data and deep learning methods:\n",
    "Approch 1 - Using LSTM  \n",
    "Approch 2 - Using CNN - CNN are useful to get best features and realtions between sequnce data using convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'\n",
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, y_train, X_test,  y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train, Y_train, X_test,  Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "#n_classes  = 6\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AMIT\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\AMIT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 1.3194 - acc: 0.4376 - val_loss: 1.1805 - val_acc: 0.4496\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.9842 - acc: 0.5749 - val_loss: 0.9447 - val_acc: 0.5857\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.7991 - acc: 0.6470 - val_loss: 0.7865 - val_acc: 0.6132\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.6984 - acc: 0.6661 - val_loss: 0.8261 - val_acc: 0.5901\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.6306 - acc: 0.6876 - val_loss: 0.7671 - val_acc: 0.6434\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.6168 - acc: 0.7084 - val_loss: 0.8407 - val_acc: 0.6590\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.6056 - acc: 0.7361 - val_loss: 0.6495 - val_acc: 0.7248\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.5260 - acc: 0.7719 - val_loss: 0.6340 - val_acc: 0.7265\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.4605 - acc: 0.7900 - val_loss: 0.6768 - val_acc: 0.7296\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.4405 - acc: 0.7999 - val_loss: 0.5573 - val_acc: 0.7530\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.4180 - acc: 0.8013 - val_loss: 0.5859 - val_acc: 0.7201\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.4083 - acc: 0.8198 - val_loss: 0.5773 - val_acc: 0.7625\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.3706 - acc: 0.8560 - val_loss: 0.6319 - val_acc: 0.8504\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.3456 - acc: 0.8832 - val_loss: 0.4920 - val_acc: 0.8717\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.2947 - acc: 0.9135 - val_loss: 0.6581 - val_acc: 0.8554\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.3015 - acc: 0.9159 - val_loss: 0.4791 - val_acc: 0.8833\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.2472 - acc: 0.9317 - val_loss: 0.5137 - val_acc: 0.8785\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.2784 - acc: 0.9271 - val_loss: 0.7416 - val_acc: 0.8364\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.2505 - acc: 0.9306 - val_loss: 0.4745 - val_acc: 0.8894\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.2093 - acc: 0.9344 - val_loss: 0.5829 - val_acc: 0.8775\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.2218 - acc: 0.9370 - val_loss: 0.4609 - val_acc: 0.8931\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1966 - acc: 0.9414 - val_loss: 0.4116 - val_acc: 0.9046\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1827 - acc: 0.9403 - val_loss: 0.4737 - val_acc: 0.8979\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1801 - acc: 0.9393 - val_loss: 0.6009 - val_acc: 0.8860\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1896 - acc: 0.9433 - val_loss: 0.4729 - val_acc: 0.9063\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.2555 - acc: 0.9334 - val_loss: 0.4608 - val_acc: 0.9070\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1791 - acc: 0.9434 - val_loss: 0.4300 - val_acc: 0.9080\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.2444 - acc: 0.9339 - val_loss: 0.4088 - val_acc: 0.9101\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1938 - acc: 0.9393 - val_loss: 0.4978 - val_acc: 0.9050\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1598 - acc: 0.9450 - val_loss: 0.4559 - val_acc: 0.9013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f1ed870710>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 28)                6832      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 174       \n",
      "=================================================================\n",
      "Total params: 12,382\n",
      "Trainable params: 12,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(28,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 109s 15ms/step - loss: 1.3081 - acc: 0.4561 - val_loss: 0.9680 - val_acc: 0.5409\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 107s 15ms/step - loss: 0.8821 - acc: 0.6051 - val_loss: 0.8140 - val_acc: 0.6284\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.7624 - acc: 0.6359 - val_loss: 0.8088 - val_acc: 0.6037\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.7258 - acc: 0.6302 - val_loss: 0.7932 - val_acc: 0.6189\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.7122 - acc: 0.6474 - val_loss: 0.7969 - val_acc: 0.6189\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.6977 - acc: 0.6515 - val_loss: 0.7787 - val_acc: 0.6152\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.6750 - acc: 0.6790 - val_loss: 0.7335 - val_acc: 0.6793\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.6167 - acc: 0.7329 - val_loss: 0.7110 - val_acc: 0.6990\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.5178 - acc: 0.7889 - val_loss: 0.6528 - val_acc: 0.7357\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.4557 - acc: 0.8215 - val_loss: 0.5696 - val_acc: 0.8521\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.4006 - acc: 0.8554 - val_loss: 0.7078 - val_acc: 0.8093\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.3518 - acc: 0.8936 - val_loss: 0.4328 - val_acc: 0.8884\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.2959 - acc: 0.9102 - val_loss: 0.5183 - val_acc: 0.8595\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.2716 - acc: 0.9240 - val_loss: 0.5887 - val_acc: 0.8568\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.2532 - acc: 0.9223 - val_loss: 0.4996 - val_acc: 0.8887\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.2409 - acc: 0.9295 - val_loss: 0.4287 - val_acc: 0.8992\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.2296 - acc: 0.9342 - val_loss: 0.4177 - val_acc: 0.8931\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.2039 - acc: 0.9377 - val_loss: 0.5764 - val_acc: 0.8962\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.2141 - acc: 0.9331 - val_loss: 0.4349 - val_acc: 0.9080\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.2001 - acc: 0.9382 - val_loss: 0.5034 - val_acc: 0.8914\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1917 - acc: 0.9348 - val_loss: 0.4654 - val_acc: 0.9108\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1970 - acc: 0.9362 - val_loss: 0.4669 - val_acc: 0.8989\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1801 - acc: 0.9425 - val_loss: 0.5325 - val_acc: 0.8928\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.1680 - acc: 0.9446 - val_loss: 0.5077 - val_acc: 0.9030\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1835 - acc: 0.9418 - val_loss: 0.5613 - val_acc: 0.9067\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1692 - acc: 0.9449 - val_loss: 0.4361 - val_acc: 0.9148\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1722 - acc: 0.9421 - val_loss: 0.6196 - val_acc: 0.8985\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.1739 - acc: 0.9434 - val_loss: 0.4876 - val_acc: 0.9131\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1833 - acc: 0.9421 - val_loss: 0.6746 - val_acc: 0.8999\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1730 - acc: 0.9431 - val_loss: 0.4763 - val_acc: 0.9084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f13724bc88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above 2 layer LSTM is giving similar score as 1 layer LSTM which we trained above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 28)                6832      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 174       \n",
      "=================================================================\n",
      "Total params: 12,382\n",
      "Trainable params: 12,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(32,recurrent_regularizer=l2(0.003),return_sequences=True,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(28,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 107s 15ms/step - loss: 1.4263 - acc: 0.4241 - val_loss: 1.2625 - val_acc: 0.5175\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 1.2066 - acc: 0.5011 - val_loss: 1.5878 - val_acc: 0.3549\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.9923 - acc: 0.5695 - val_loss: 0.9060 - val_acc: 0.6162\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.9109 - acc: 0.5839 - val_loss: 0.8547 - val_acc: 0.5962\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.7995 - acc: 0.6223 - val_loss: 0.7806 - val_acc: 0.6176\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.8123 - acc: 0.6062 - val_loss: 0.8927 - val_acc: 0.5887\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.7574 - acc: 0.6319 - val_loss: 0.7507 - val_acc: 0.6050\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.7699 - acc: 0.6411 - val_loss: 0.7285 - val_acc: 0.6159\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.7106 - acc: 0.6493 - val_loss: 0.8037 - val_acc: 0.5935\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.7854 - acc: 0.6389 - val_loss: 1.9405 - val_acc: 0.3936\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "History = model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Using Hyperas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(36)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperas.utils import eval_hyperopt_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##gives train and validation data \n",
    "def data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Data directory\n",
    "    DATADIR = 'UCI_HAR_Dataset'\n",
    "    # Raw data signals\n",
    "    # Signals are from Accelerometer and Gyroscope\n",
    "    # The signals are in x,y,z directions\n",
    "    # Sensor signals are filtered to have only body acceleration\n",
    "    # excluding the acceleration due to gravity\n",
    "    # Triaxial acceleration from the accelerometer is total acceleration\n",
    "    SIGNALS = [\n",
    "        \"body_acc_x\",\n",
    "        \"body_acc_y\",\n",
    "        \"body_acc_z\",\n",
    "        \"body_gyro_x\",\n",
    "        \"body_gyro_y\",\n",
    "        \"body_gyro_z\",\n",
    "        \"total_acc_x\",\n",
    "        \"total_acc_y\",\n",
    "        \"total_acc_z\"\n",
    "        ]\n",
    "    # Utility function to read the data from csv file\n",
    "    def _read_csv(filename):\n",
    "        return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "    # Utility function to load the load\n",
    "    def load_signals(subset):\n",
    "        signals_data = []\n",
    "\n",
    "        for signal in SIGNALS:\n",
    "            filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "            signals_data.append( _read_csv(filename).as_matrix()) \n",
    "\n",
    "        # Transpose is used to change the dimensionality of the output,\n",
    "        # aggregating the signals by combination of sample/timestep.\n",
    "        # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "        return np.transpose(signals_data, (1, 2, 0))\n",
    "    \n",
    "    def load_y(subset):\n",
    "        \"\"\"\n",
    "        The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "        that represents a human activity. We return a binary representation of \n",
    "        every sample objective as a 6 bits vector using One Hot Encoding\n",
    "        (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "        \"\"\"\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "        y = _read_csv(filename)[0]\n",
    "        return pd.get_dummies(y).as_matrix()\n",
    "    \n",
    "    X_train, X_val = load_signals('train'), load_signals('test')\n",
    "    Y_train, Y_val = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, Y_train, X_val,  Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_val, Y_val):\n",
    "    # Importing tensorflow\n",
    "    np.random.seed(36)\n",
    "    import tensorflow as tf\n",
    "    tf.set_random_seed(36)\n",
    "    # Initiliazing the sequential model\n",
    "    model = Sequential() \n",
    "    if conditional({{choice(['one', 'two'])}}) == 'two':\n",
    "        # Configuring the parameters\n",
    "        model.add(LSTM({{choice([28,32,38])}},recurrent_regularizer=l2({{uniform(0,0.0002)}}),return_sequences=True,input_shape=(128, 9),name='LSTM2_1'))\n",
    "        # Adding a dropout layer\n",
    "        model.add(Dropout({{uniform(0.35,0.65)}},name='Dropout2_1'))\n",
    "        model.add(LSTM({{choice([26,32,36])}},recurrent_regularizer=l2({{uniform(0,0.001)}}),input_shape=(128, 9),name='LSTM2_2'))\n",
    "        model.add(Dropout({{uniform(0.5,0.7)}},name='Dropout2_2'))\n",
    "        # Adding a dense output layer with sigmoid activation\n",
    "        model.add(Dense(6, activation='sigmoid'))\n",
    "    else:\n",
    "        # Configuring the parameters\n",
    "        model.add(LSTM({{choice([28,32,36])}},recurrent_regularizer=l2({{uniform(0,0.001)}}),input_shape=(128, 9),name='LSTM1_1'))\n",
    "        # Adding a dropout layer\n",
    "        model.add(Dropout({{uniform(0.35,0.55)}},name='Dropout1_1'))\n",
    "        # Adding a dense output layer with sigmoid activation\n",
    "        model.add(Dense(6, activation='sigmoid'))\n",
    "        \n",
    "    adam = keras.optimizers.Adam(lr={{uniform(0.009,0.025)}})\n",
    "    rmsprop = keras.optimizers.RMSprop(lr={{uniform(0.009,0.025)}})\n",
    "   \n",
    "    choiceval = {{choice(['adam', 'rmsprop'])}}\n",
    "    \n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    else:\n",
    "        optim = rmsprop\n",
    "    \n",
    "    print(model.summary())\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
    "    \n",
    "    result = model.fit(X_train, Y_train,\n",
    "              batch_size=16,\n",
    "              nb_epoch=30,\n",
    "              verbose=2,\n",
    "              validation_data=(X_val, Y_val))\n",
    "                       \n",
    "    score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pickle\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.utils import eval_hyperopt_space\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'conditional': hp.choice('conditional', ['one', 'two']),\n",
      "        'LSTM': hp.choice('LSTM', [28,32,38]),\n",
      "        'l2': hp.uniform('l2', 0,0.0002),\n",
      "        'Dropout': hp.uniform('Dropout', 0.35,0.65),\n",
      "        'LSTM_1': hp.choice('LSTM_1', [26,32,36]),\n",
      "        'l2_1': hp.uniform('l2_1', 0,0.001),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0.5,0.7),\n",
      "        'LSTM_2': hp.choice('LSTM_2', [28,32,36]),\n",
      "        'l2_2': hp.uniform('l2_2', 0,0.001),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0.35,0.55),\n",
      "        'lr': hp.uniform('lr', 0.009,0.025),\n",
      "        'lr_1': hp.uniform('lr_1', 0.009,0.025),\n",
      "        'choiceval': hp.choice('choiceval', ['adam', 'rmsprop']),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: \"\"\"\n",
      "   3: Obtain the dataset from multiple files.\n",
      "   4: Returns: X_train, X_test, y_train, y_test\n",
      "   5: \"\"\"\n",
      "   6: # Data directory\n",
      "   7: DATADIR = 'UCI_HAR_Dataset'\n",
      "   8: # Raw data signals\n",
      "   9: # Signals are from Accelerometer and Gyroscope\n",
      "  10: # The signals are in x,y,z directions\n",
      "  11: # Sensor signals are filtered to have only body acceleration\n",
      "  12: # excluding the acceleration due to gravity\n",
      "  13: # Triaxial acceleration from the accelerometer is total acceleration\n",
      "  14: SIGNALS = [\n",
      "  15:     \"body_acc_x\",\n",
      "  16:     \"body_acc_y\",\n",
      "  17:     \"body_acc_z\",\n",
      "  18:     \"body_gyro_x\",\n",
      "  19:     \"body_gyro_y\",\n",
      "  20:     \"body_gyro_z\",\n",
      "  21:     \"total_acc_x\",\n",
      "  22:     \"total_acc_y\",\n",
      "  23:     \"total_acc_z\"\n",
      "  24:     ]\n",
      "  25: # Utility function to read the data from csv file\n",
      "  26: def _read_csv(filename):\n",
      "  27:     return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "  28: \n",
      "  29: # Utility function to load the load\n",
      "  30: def load_signals(subset):\n",
      "  31:     signals_data = []\n",
      "  32: \n",
      "  33:     for signal in SIGNALS:\n",
      "  34:         filename = f'HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
      "  35:         signals_data.append( _read_csv(filename).as_matrix()) \n",
      "  36: \n",
      "  37:     # Transpose is used to change the dimensionality of the output,\n",
      "  38:     # aggregating the signals by combination of sample/timestep.\n",
      "  39:     # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
      "  40:     return np.transpose(signals_data, (1, 2, 0))\n",
      "  41: \n",
      "  42: def load_y(subset):\n",
      "  43:     \"\"\"\n",
      "  44:     The objective that we are trying to predict is a integer, from 1 to 6,\n",
      "  45:     that represents a human activity. We return a binary representation of \n",
      "  46:     every sample objective as a 6 bits vector using One Hot Encoding\n",
      "  47:     (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
      "  48:     \"\"\"\n",
      "  49:     filename = f'HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
      "  50:     y = _read_csv(filename)[0]\n",
      "  51:     return pd.get_dummies(y).as_matrix()\n",
      "  52: \n",
      "  53: X_train, X_val = load_signals('train'), load_signals('test')\n",
      "  54: Y_train, Y_val = load_y('train'), load_y('test')\n",
      "  55: \n",
      "  56: \n",
      "  57: \n",
      "  58: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     # Importing tensorflow\n",
      "   4:     np.random.seed(36)\n",
      "   5:     tf.set_random_seed(36)\n",
      "   6:     # Initiliazing the sequential model\n",
      "   7:     model = Sequential() \n",
      "   8:     if conditional(space['conditional']) == 'two':\n",
      "   9:         # Configuring the parameters\n",
      "  10:         model.add(LSTM(space['LSTM'],recurrent_regularizer=l2(space['l2']),return_sequences=True,input_shape=(128, 9),name='LSTM2_1'))\n",
      "  11:         # Adding a dropout layer\n",
      "  12:         model.add(Dropout(space['Dropout'],name='Dropout2_1'))\n",
      "  13:         model.add(LSTM(space['LSTM_1'],recurrent_regularizer=l2(space['l2_1']),input_shape=(128, 9),name='LSTM2_2'))\n",
      "  14:         model.add(Dropout(space['Dropout_1'],name='Dropout2_2'))\n",
      "  15:         # Adding a dense output layer with sigmoid activation\n",
      "  16:         model.add(Dense(6, activation='sigmoid'))\n",
      "  17:     else:\n",
      "  18:         # Configuring the parameters\n",
      "  19:         model.add(LSTM(space['LSTM_2'],recurrent_regularizer=l2(space['l2_2']),input_shape=(128, 9),name='LSTM1_1'))\n",
      "  20:         # Adding a dropout layer\n",
      "  21:         model.add(Dropout(space['Dropout_2'],name='Dropout1_1'))\n",
      "  22:         # Adding a dense output layer with sigmoid activation\n",
      "  23:         model.add(Dense(6, activation='sigmoid'))\n",
      "  24:         \n",
      "  25:     adam = keras.optimizers.Adam(lr=space['lr'])\n",
      "  26:     rmsprop = keras.optimizers.RMSprop(lr=space['lr_1'])\n",
      "  27:    \n",
      "  28:     choiceval = space['choiceval']\n",
      "  29:     \n",
      "  30:     if choiceval == 'adam':\n",
      "  31:         optim = adam\n",
      "  32:     else:\n",
      "  33:         optim = rmsprop\n",
      "  34:     \n",
      "  35:     print(model.summary())\n",
      "  36:         \n",
      "  37:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
      "  38:     \n",
      "  39:     result = model.fit(X_train, Y_train,\n",
      "  40:               batch_size=16,\n",
      "  41:               nb_epoch=30,\n",
      "  42:               verbose=2,\n",
      "  43:               validation_data=(X_val, Y_val))\n",
      "  44:                        \n",
      "  45:     score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
      "  46:     print('Test accuracy:', acc)\n",
      "  47:     print('-------------------------------------------------------------------------------------')\n",
      "  48:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  49: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM1_1 (LSTM)               (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "Dropout1_1 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 54s - loss: 1.2450 - acc: 0.4542 - val_loss: 1.3427 - val_acc: 0.3712\n",
      "Epoch 2/30\n",
      " - 53s - loss: 0.9058 - acc: 0.5974 - val_loss: 0.7812 - val_acc: 0.6379\n",
      "Epoch 3/30\n",
      " - 52s - loss: 0.7532 - acc: 0.6465 - val_loss: 0.6822 - val_acc: 0.7207\n",
      "Epoch 4/30\n",
      " - 51s - loss: 0.5511 - acc: 0.8190 - val_loss: 0.4388 - val_acc: 0.8626\n",
      "Epoch 5/30\n",
      " - 51s - loss: 0.3685 - acc: 0.9067 - val_loss: 0.7325 - val_acc: 0.8124\n",
      "Epoch 6/30\n",
      " - 52s - loss: 0.3109 - acc: 0.9203 - val_loss: 0.4244 - val_acc: 0.8863\n",
      "Epoch 7/30\n",
      " - 52s - loss: 0.2748 - acc: 0.9271 - val_loss: 0.4503 - val_acc: 0.8948\n",
      "Epoch 8/30\n",
      " - 52s - loss: 0.2566 - acc: 0.9238 - val_loss: 0.5668 - val_acc: 0.8670\n",
      "Epoch 9/30\n",
      " - 51s - loss: 0.2533 - acc: 0.9306 - val_loss: 0.4599 - val_acc: 0.9013\n",
      "Epoch 10/30\n",
      " - 51s - loss: 0.2503 - acc: 0.9287 - val_loss: 0.3217 - val_acc: 0.9009\n",
      "Epoch 11/30\n",
      " - 52s - loss: 0.2251 - acc: 0.9388 - val_loss: 0.3650 - val_acc: 0.9104\n",
      "Epoch 12/30\n",
      " - 51s - loss: 0.2239 - acc: 0.9363 - val_loss: 0.5278 - val_acc: 0.9053\n",
      "Epoch 13/30\n",
      " - 51s - loss: 0.2239 - acc: 0.9324 - val_loss: 0.4011 - val_acc: 0.8924\n",
      "Epoch 14/30\n",
      " - 52s - loss: 0.2066 - acc: 0.9385 - val_loss: 0.5576 - val_acc: 0.8999\n",
      "Epoch 15/30\n",
      " - 52s - loss: 0.2208 - acc: 0.9370 - val_loss: 0.6006 - val_acc: 0.8833\n",
      "Epoch 16/30\n",
      " - 52s - loss: 0.2124 - acc: 0.9392 - val_loss: 0.6876 - val_acc: 0.8666\n",
      "Epoch 17/30\n",
      " - 52s - loss: 0.2021 - acc: 0.9399 - val_loss: 0.4828 - val_acc: 0.9023\n",
      "Epoch 18/30\n",
      " - 52s - loss: 0.2058 - acc: 0.9372 - val_loss: 0.5229 - val_acc: 0.9077\n",
      "Epoch 19/30\n",
      " - 53s - loss: 0.2071 - acc: 0.9392 - val_loss: 0.5419 - val_acc: 0.8904\n",
      "Epoch 20/30\n",
      " - 53s - loss: 0.2081 - acc: 0.9378 - val_loss: 0.7437 - val_acc: 0.8843\n",
      "Epoch 21/30\n",
      " - 52s - loss: 0.2032 - acc: 0.9407 - val_loss: 0.8337 - val_acc: 0.8911\n",
      "Epoch 22/30\n",
      " - 52s - loss: 0.2136 - acc: 0.9404 - val_loss: 0.6945 - val_acc: 0.8897\n",
      "Epoch 23/30\n",
      " - 53s - loss: 0.1895 - acc: 0.9388 - val_loss: 0.5063 - val_acc: 0.8999\n",
      "Epoch 24/30\n",
      " - 53s - loss: 0.1968 - acc: 0.9468 - val_loss: 0.4665 - val_acc: 0.9074\n",
      "Epoch 25/30\n",
      " - 52s - loss: 0.1866 - acc: 0.9450 - val_loss: 0.7473 - val_acc: 0.8856\n",
      "Epoch 26/30\n",
      " - 52s - loss: 0.1845 - acc: 0.9412 - val_loss: 0.6272 - val_acc: 0.8901\n",
      "Epoch 27/30\n",
      " - 52s - loss: 0.2020 - acc: 0.9426 - val_loss: 0.5100 - val_acc: 0.8975\n",
      "Epoch 28/30\n",
      " - 52s - loss: 0.1866 - acc: 0.9406 - val_loss: 0.6803 - val_acc: 0.8887\n",
      "Epoch 29/30\n",
      " - 52s - loss: 0.1897 - acc: 0.9434 - val_loss: 0.6320 - val_acc: 0.8982\n",
      "Epoch 30/30\n",
      " - 52s - loss: 0.1871 - acc: 0.9486 - val_loss: 0.6176 - val_acc: 0.9002\n",
      "Test accuracy: 0.9002375296912114\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM2_1 (LSTM)               (None, 128, 28)           4256      \n",
      "_________________________________________________________________\n",
      "Dropout2_1 (Dropout)         (None, 128, 28)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2_2 (LSTM)               (None, 32)                7808      \n",
      "_________________________________________________________________\n",
      "Dropout2_2 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 12,262\n",
      "Trainable params: 12,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 116s - loss: 1.3509 - acc: 0.4094 - val_loss: 1.2985 - val_acc: 0.4211\n",
      "Epoch 2/30\n",
      " - 114s - loss: 1.1227 - acc: 0.5048 - val_loss: 0.9203 - val_acc: 0.5840\n",
      "Epoch 3/30\n",
      " - 114s - loss: 0.9163 - acc: 0.5909 - val_loss: 0.7878 - val_acc: 0.5979\n",
      "Epoch 4/30\n",
      " - 113s - loss: 0.7372 - acc: 0.6355 - val_loss: 0.8733 - val_acc: 0.6576\n",
      "Epoch 5/30\n",
      " - 113s - loss: 0.7606 - acc: 0.6559 - val_loss: 0.7596 - val_acc: 0.6627\n",
      "Epoch 6/30\n",
      " - 113s - loss: 0.6631 - acc: 0.7126 - val_loss: 0.6731 - val_acc: 0.7272\n",
      "Epoch 7/30\n",
      " - 112s - loss: 0.6001 - acc: 0.7648 - val_loss: 0.6734 - val_acc: 0.7401\n",
      "Epoch 8/30\n",
      " - 112s - loss: 0.5491 - acc: 0.8194 - val_loss: 0.7685 - val_acc: 0.7767\n",
      "Epoch 9/30\n",
      " - 113s - loss: 0.4469 - acc: 0.8749 - val_loss: 0.6154 - val_acc: 0.8039\n",
      "Epoch 10/30\n",
      " - 113s - loss: 0.3422 - acc: 0.9060 - val_loss: 0.4643 - val_acc: 0.8728\n",
      "Epoch 11/30\n",
      " - 113s - loss: 0.3277 - acc: 0.9120 - val_loss: 0.5444 - val_acc: 0.8935\n",
      "Epoch 12/30\n",
      " - 113s - loss: 0.2989 - acc: 0.9165 - val_loss: 0.5426 - val_acc: 0.8873\n",
      "Epoch 13/30\n",
      " - 113s - loss: 0.3066 - acc: 0.9183 - val_loss: 0.5929 - val_acc: 0.8890\n",
      "Epoch 14/30\n",
      " - 113s - loss: 0.2790 - acc: 0.9238 - val_loss: 0.8567 - val_acc: 0.8605\n",
      "Epoch 15/30\n",
      " - 113s - loss: 0.2381 - acc: 0.9308 - val_loss: 0.4199 - val_acc: 0.8795\n",
      "Epoch 16/30\n",
      " - 113s - loss: 0.2765 - acc: 0.9237 - val_loss: 0.4038 - val_acc: 0.9009\n",
      "Epoch 17/30\n",
      " - 113s - loss: 0.2222 - acc: 0.9347 - val_loss: 0.9794 - val_acc: 0.8558\n",
      "Epoch 18/30\n",
      " - 113s - loss: 0.2855 - acc: 0.9245 - val_loss: 0.5541 - val_acc: 0.8721\n",
      "Epoch 19/30\n",
      " - 113s - loss: 0.2214 - acc: 0.9329 - val_loss: 0.6838 - val_acc: 0.8890\n",
      "Epoch 20/30\n",
      " - 113s - loss: 0.2382 - acc: 0.9294 - val_loss: 0.6224 - val_acc: 0.8975\n",
      "Epoch 21/30\n",
      " - 113s - loss: 0.2227 - acc: 0.9377 - val_loss: 0.9649 - val_acc: 0.8761\n",
      "Epoch 22/30\n",
      " - 113s - loss: 0.2391 - acc: 0.9344 - val_loss: 0.7248 - val_acc: 0.8945\n",
      "Epoch 23/30\n",
      " - 112s - loss: 0.2880 - acc: 0.9316 - val_loss: 0.6072 - val_acc: 0.8928\n",
      "Epoch 24/30\n",
      " - 113s - loss: 0.2283 - acc: 0.9309 - val_loss: 0.5543 - val_acc: 0.8958\n",
      "Epoch 25/30\n",
      " - 113s - loss: 0.2152 - acc: 0.9378 - val_loss: 0.7930 - val_acc: 0.8558\n",
      "Epoch 26/30\n",
      " - 113s - loss: 0.2582 - acc: 0.9338 - val_loss: 0.6463 - val_acc: 0.8836\n",
      "Epoch 27/30\n",
      " - 113s - loss: 0.2352 - acc: 0.9317 - val_loss: 0.5760 - val_acc: 0.8884\n",
      "Epoch 28/30\n",
      " - 113s - loss: 0.2256 - acc: 0.9378 - val_loss: 0.7432 - val_acc: 0.8755\n",
      "Epoch 29/30\n",
      " - 114s - loss: 0.2372 - acc: 0.9453 - val_loss: 0.6815 - val_acc: 0.8948\n",
      "Epoch 30/30\n",
      " - 113s - loss: 0.2550 - acc: 0.9340 - val_loss: 0.6620 - val_acc: 0.8721\n",
      "Test accuracy: 0.8720732948761453\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM2_1 (LSTM)               (None, 128, 38)           7296      \n",
      "_________________________________________________________________\n",
      "Dropout2_1 (Dropout)         (None, 128, 38)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2_2 (LSTM)               (None, 36)                10800     \n",
      "_________________________________________________________________\n",
      "Dropout2_2 (Dropout)         (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 222       \n",
      "=================================================================\n",
      "Total params: 18,318\n",
      "Trainable params: 18,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 119s - loss: 1.1983 - acc: 0.4893 - val_loss: 0.8035 - val_acc: 0.6149\n",
      "Epoch 2/30\n",
      " - 116s - loss: 0.7894 - acc: 0.6400 - val_loss: 0.8551 - val_acc: 0.6111\n",
      "Epoch 3/30\n",
      " - 116s - loss: 0.7522 - acc: 0.6668 - val_loss: 0.9096 - val_acc: 0.6844\n",
      "Epoch 4/30\n",
      " - 116s - loss: 0.5412 - acc: 0.7935 - val_loss: 0.8693 - val_acc: 0.8110\n",
      "Epoch 5/30\n",
      " - 116s - loss: 0.4574 - acc: 0.8808 - val_loss: 0.6524 - val_acc: 0.8880\n",
      "Epoch 6/30\n",
      " - 116s - loss: 0.3585 - acc: 0.9127 - val_loss: 0.6781 - val_acc: 0.8758\n",
      "Epoch 7/30\n",
      " - 116s - loss: 0.3066 - acc: 0.9203 - val_loss: 0.7484 - val_acc: 0.8890\n",
      "Epoch 8/30\n",
      " - 117s - loss: 0.2817 - acc: 0.9278 - val_loss: 0.8017 - val_acc: 0.8690\n",
      "Epoch 9/30\n",
      " - 116s - loss: 0.2543 - acc: 0.9283 - val_loss: 1.2660 - val_acc: 0.8320\n",
      "Epoch 10/30\n",
      " - 116s - loss: 0.2435 - acc: 0.9365 - val_loss: 0.8145 - val_acc: 0.8646\n",
      "Epoch 11/30\n",
      " - 116s - loss: 0.2767 - acc: 0.9317 - val_loss: 0.5959 - val_acc: 0.8979\n",
      "Epoch 12/30\n",
      " - 116s - loss: 0.2265 - acc: 0.9373 - val_loss: 0.6543 - val_acc: 0.8935\n",
      "Epoch 13/30\n",
      " - 116s - loss: 0.2253 - acc: 0.9363 - val_loss: 0.5145 - val_acc: 0.9216\n",
      "Epoch 14/30\n",
      " - 116s - loss: 0.2458 - acc: 0.9310 - val_loss: 0.4773 - val_acc: 0.9175\n",
      "Epoch 15/30\n",
      " - 116s - loss: 0.2122 - acc: 0.9389 - val_loss: 0.6626 - val_acc: 0.8958\n",
      "Epoch 16/30\n",
      " - 116s - loss: 0.2367 - acc: 0.9393 - val_loss: 0.6204 - val_acc: 0.8965\n",
      "Epoch 17/30\n",
      " - 116s - loss: 0.2317 - acc: 0.9414 - val_loss: 0.9979 - val_acc: 0.8772\n",
      "Epoch 18/30\n",
      " - 116s - loss: 0.2406 - acc: 0.9350 - val_loss: 0.9485 - val_acc: 0.8744\n",
      "Epoch 19/30\n",
      " - 116s - loss: 0.2186 - acc: 0.9408 - val_loss: 0.7989 - val_acc: 0.8870\n",
      "Epoch 20/30\n",
      " - 116s - loss: 0.2050 - acc: 0.9427 - val_loss: 0.8482 - val_acc: 0.8738\n",
      "Epoch 21/30\n",
      " - 117s - loss: 0.1984 - acc: 0.9415 - val_loss: 0.6845 - val_acc: 0.8945\n",
      "Epoch 22/30\n",
      " - 116s - loss: 0.1928 - acc: 0.9445 - val_loss: 0.5078 - val_acc: 0.9192\n",
      "Epoch 23/30\n",
      " - 116s - loss: 0.2071 - acc: 0.9427 - val_loss: 0.6209 - val_acc: 0.9172\n",
      "Epoch 24/30\n",
      " - 116s - loss: 0.2433 - acc: 0.9381 - val_loss: 0.6083 - val_acc: 0.9091\n",
      "Epoch 25/30\n",
      " - 117s - loss: 0.2048 - acc: 0.9429 - val_loss: 0.6255 - val_acc: 0.8772\n",
      "Epoch 26/30\n",
      " - 116s - loss: 0.1990 - acc: 0.9397 - val_loss: 0.9037 - val_acc: 0.8809\n",
      "Epoch 27/30\n",
      " - 116s - loss: 0.1816 - acc: 0.9426 - val_loss: 0.8393 - val_acc: 0.8748\n",
      "Epoch 28/30\n",
      " - 116s - loss: 0.2225 - acc: 0.9412 - val_loss: 0.6894 - val_acc: 0.9070\n",
      "Epoch 29/30\n",
      " - 116s - loss: 0.2070 - acc: 0.9449 - val_loss: 0.7186 - val_acc: 0.9063\n",
      "Epoch 30/30\n",
      " - 116s - loss: 0.2195 - acc: 0.9421 - val_loss: 0.8332 - val_acc: 0.8972\n",
      "Test accuracy: 0.8971835765184933\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM2_1 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "Dropout2_1 (Dropout)         (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2_2 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "Dropout2_2 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 13,894\n",
      "Trainable params: 13,894\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 115s - loss: 1.4372 - acc: 0.3659 - val_loss: 1.4671 - val_acc: 0.3539\n",
      "Epoch 2/30\n",
      " - 113s - loss: 1.3271 - acc: 0.4178 - val_loss: 1.1843 - val_acc: 0.4785\n",
      "Epoch 3/30\n",
      " - 112s - loss: 1.1944 - acc: 0.5075 - val_loss: 1.0682 - val_acc: 0.5185\n",
      "Epoch 4/30\n",
      " - 112s - loss: 0.9614 - acc: 0.5405 - val_loss: 0.9636 - val_acc: 0.5450\n",
      "Epoch 5/30\n",
      " - 112s - loss: 0.8921 - acc: 0.5649 - val_loss: 1.0393 - val_acc: 0.5697\n",
      "Epoch 6/30\n",
      " - 112s - loss: 0.9083 - acc: 0.5941 - val_loss: 1.0248 - val_acc: 0.5938\n",
      "Epoch 7/30\n",
      " - 112s - loss: 0.8562 - acc: 0.6053 - val_loss: 0.8309 - val_acc: 0.6081\n",
      "Epoch 8/30\n",
      " - 112s - loss: 0.7939 - acc: 0.6302 - val_loss: 0.7886 - val_acc: 0.6210\n",
      "Epoch 9/30\n",
      " - 112s - loss: 0.7313 - acc: 0.6542 - val_loss: 0.7931 - val_acc: 0.6356\n",
      "Epoch 10/30\n",
      " - 112s - loss: 0.7418 - acc: 0.6492 - val_loss: 0.7654 - val_acc: 0.6305\n",
      "Epoch 11/30\n",
      " - 112s - loss: 0.7019 - acc: 0.6542 - val_loss: 0.7826 - val_acc: 0.6261\n",
      "Epoch 12/30\n",
      " - 112s - loss: 0.6793 - acc: 0.6644 - val_loss: 0.7845 - val_acc: 0.6244\n",
      "Epoch 13/30\n",
      " - 112s - loss: 0.6800 - acc: 0.6647 - val_loss: 0.7932 - val_acc: 0.6200\n",
      "Epoch 14/30\n",
      " - 112s - loss: 0.6687 - acc: 0.6666 - val_loss: 0.7532 - val_acc: 0.6295\n",
      "Epoch 15/30\n",
      " - 112s - loss: 0.7405 - acc: 0.6615 - val_loss: 0.7667 - val_acc: 0.6261\n",
      "Epoch 16/30\n",
      " - 112s - loss: 0.6780 - acc: 0.6643 - val_loss: 0.7667 - val_acc: 0.6172\n",
      "Epoch 17/30\n",
      " - 112s - loss: 0.6512 - acc: 0.6696 - val_loss: 0.7582 - val_acc: 0.6295\n",
      "Epoch 18/30\n",
      " - 112s - loss: 0.6180 - acc: 0.6904 - val_loss: 0.6705 - val_acc: 0.6423\n",
      "Epoch 19/30\n",
      " - 112s - loss: 0.5738 - acc: 0.7399 - val_loss: 0.8903 - val_acc: 0.6834\n",
      "Epoch 20/30\n",
      " - 112s - loss: 0.5144 - acc: 0.7964 - val_loss: 0.7585 - val_acc: 0.7564\n",
      "Epoch 21/30\n",
      " - 112s - loss: 0.5651 - acc: 0.7982 - val_loss: 0.6209 - val_acc: 0.7893\n",
      "Epoch 22/30\n",
      " - 112s - loss: 0.4844 - acc: 0.8009 - val_loss: 0.6228 - val_acc: 0.8249\n",
      "Epoch 23/30\n",
      " - 111s - loss: 0.4312 - acc: 0.8070 - val_loss: 0.5516 - val_acc: 0.7516\n",
      "Epoch 24/30\n",
      " - 112s - loss: 0.4394 - acc: 0.8192 - val_loss: 0.6016 - val_acc: 0.7845\n",
      "Epoch 25/30\n",
      " - 112s - loss: 0.4126 - acc: 0.8383 - val_loss: 0.6123 - val_acc: 0.8205\n",
      "Epoch 26/30\n",
      " - 112s - loss: 0.4230 - acc: 0.8743 - val_loss: 0.4831 - val_acc: 0.8734\n",
      "Epoch 27/30\n",
      " - 112s - loss: 0.3373 - acc: 0.9131 - val_loss: 0.5120 - val_acc: 0.8870\n",
      "Epoch 28/30\n",
      " - 112s - loss: 0.2753 - acc: 0.9346 - val_loss: 0.5130 - val_acc: 0.8724\n",
      "Epoch 29/30\n",
      " - 112s - loss: 0.2642 - acc: 0.9325 - val_loss: 0.3661 - val_acc: 0.8985\n",
      "Epoch 30/30\n",
      " - 112s - loss: 0.2854 - acc: 0.9282 - val_loss: 0.4492 - val_acc: 0.8958\n",
      "Test accuracy: 0.8958262639972854\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM2_1 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "Dropout2_1 (Dropout)         (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2_2 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "Dropout2_2 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 13,894\n",
      "Trainable params: 13,894\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 116s - loss: 1.5210 - acc: 0.3177 - val_loss: 1.8157 - val_acc: 0.1805\n",
      "Epoch 2/30\n",
      " - 113s - loss: 1.7460 - acc: 0.2628 - val_loss: 1.4418 - val_acc: 0.3529\n",
      "Epoch 3/30\n",
      " - 113s - loss: 1.4133 - acc: 0.3596 - val_loss: 1.3828 - val_acc: 0.3617\n",
      "Epoch 4/30\n",
      " - 113s - loss: 1.3750 - acc: 0.3727 - val_loss: 1.4695 - val_acc: 0.3536\n",
      "Epoch 5/30\n",
      " - 113s - loss: 1.3640 - acc: 0.3776 - val_loss: 1.4747 - val_acc: 0.3536\n",
      "Epoch 6/30\n",
      " - 113s - loss: 1.3579 - acc: 0.3674 - val_loss: 1.3544 - val_acc: 0.3624\n",
      "Epoch 7/30\n",
      " - 113s - loss: 1.3526 - acc: 0.3740 - val_loss: 1.4759 - val_acc: 0.3536\n",
      "Epoch 8/30\n",
      " - 113s - loss: 1.3457 - acc: 0.3681 - val_loss: 1.2573 - val_acc: 0.4133\n",
      "Epoch 9/30\n",
      " - 112s - loss: 1.4167 - acc: 0.3753 - val_loss: 1.3990 - val_acc: 0.3536\n",
      "Epoch 10/30\n",
      " - 112s - loss: 1.3734 - acc: 0.3826 - val_loss: 1.3683 - val_acc: 0.3685\n",
      "Epoch 11/30\n",
      " - 114s - loss: 1.3230 - acc: 0.4319 - val_loss: 1.3894 - val_acc: 0.3756\n",
      "Epoch 12/30\n",
      " - 112s - loss: 1.3716 - acc: 0.3898 - val_loss: 1.4371 - val_acc: 0.3512\n",
      "Epoch 13/30\n",
      " - 113s - loss: 1.3323 - acc: 0.4132 - val_loss: 1.2813 - val_acc: 0.4011\n",
      "Epoch 14/30\n",
      " - 113s - loss: 1.1793 - acc: 0.4763 - val_loss: 1.2701 - val_acc: 0.4435\n",
      "Epoch 15/30\n",
      " - 112s - loss: 1.0988 - acc: 0.4761 - val_loss: 1.0824 - val_acc: 0.4130\n",
      "Epoch 16/30\n",
      " - 113s - loss: 0.9046 - acc: 0.5589 - val_loss: 1.1002 - val_acc: 0.5395\n",
      "Epoch 17/30\n",
      " - 113s - loss: 0.8583 - acc: 0.5683 - val_loss: 0.9662 - val_acc: 0.5161\n",
      "Epoch 18/30\n",
      " - 113s - loss: 0.7778 - acc: 0.6159 - val_loss: 0.9013 - val_acc: 0.5836\n",
      "Epoch 19/30\n",
      " - 113s - loss: 0.8041 - acc: 0.6264 - val_loss: 0.8678 - val_acc: 0.6149\n",
      "Epoch 20/30\n",
      " - 113s - loss: 0.7989 - acc: 0.6192 - val_loss: 0.9060 - val_acc: 0.5769\n",
      "Epoch 21/30\n",
      " - 114s - loss: 0.7531 - acc: 0.6269 - val_loss: 0.8337 - val_acc: 0.5772\n",
      "Epoch 22/30\n",
      " - 112s - loss: 0.7393 - acc: 0.6353 - val_loss: 0.8051 - val_acc: 0.5853\n",
      "Epoch 23/30\n",
      " - 113s - loss: 0.8261 - acc: 0.5998 - val_loss: 1.2974 - val_acc: 0.3695\n",
      "Epoch 24/30\n",
      " - 113s - loss: 1.1817 - acc: 0.4483 - val_loss: 0.9910 - val_acc: 0.5555\n",
      "Epoch 25/30\n",
      " - 113s - loss: 0.7748 - acc: 0.6117 - val_loss: 0.7969 - val_acc: 0.6023\n",
      "Epoch 26/30\n",
      " - 113s - loss: 0.8745 - acc: 0.5828 - val_loss: 0.9096 - val_acc: 0.5599\n",
      "Epoch 27/30\n",
      " - 113s - loss: 0.9154 - acc: 0.5937 - val_loss: 0.8608 - val_acc: 0.5738\n",
      "Epoch 28/30\n",
      " - 113s - loss: 0.9566 - acc: 0.5649 - val_loss: 1.0465 - val_acc: 0.5209\n",
      "Epoch 29/30\n",
      " - 113s - loss: 0.9162 - acc: 0.5412 - val_loss: 0.8763 - val_acc: 0.5344\n",
      "Epoch 30/30\n",
      " - 113s - loss: 0.9363 - acc: 0.5345 - val_loss: 0.9800 - val_acc: 0.4856\n",
      "Test accuracy: 0.4855785544621649\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM2_1 (LSTM)               (None, 128, 28)           4256      \n",
      "_________________________________________________________________\n",
      "Dropout2_1 (Dropout)         (None, 128, 28)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2_2 (LSTM)               (None, 32)                7808      \n",
      "_________________________________________________________________\n",
      "Dropout2_2 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 12,262\n",
      "Trainable params: 12,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 114s - loss: 1.2473 - acc: 0.4480 - val_loss: 0.8644 - val_acc: 0.6189\n",
      "Epoch 2/30\n",
      " - 112s - loss: 0.9461 - acc: 0.5958 - val_loss: 0.9319 - val_acc: 0.5304\n",
      "Epoch 3/30\n",
      " - 112s - loss: 0.8364 - acc: 0.6109 - val_loss: 0.8742 - val_acc: 0.6532\n",
      "Epoch 4/30\n",
      " - 112s - loss: 0.7885 - acc: 0.6352 - val_loss: 0.7957 - val_acc: 0.6054\n",
      "Epoch 5/30\n",
      " - 112s - loss: 0.7112 - acc: 0.6623 - val_loss: 0.8570 - val_acc: 0.7038\n",
      "Epoch 6/30\n",
      " - 112s - loss: 0.5906 - acc: 0.7859 - val_loss: 0.7603 - val_acc: 0.8297\n",
      "Epoch 7/30\n",
      " - 112s - loss: 0.4219 - acc: 0.8789 - val_loss: 0.7585 - val_acc: 0.8470\n",
      "Epoch 8/30\n",
      " - 111s - loss: 0.3792 - acc: 0.9044 - val_loss: 0.7414 - val_acc: 0.8765\n",
      "Epoch 9/30\n",
      " - 112s - loss: 0.3187 - acc: 0.9166 - val_loss: 0.6164 - val_acc: 0.9057\n",
      "Epoch 10/30\n",
      " - 112s - loss: 0.2635 - acc: 0.9264 - val_loss: 0.6408 - val_acc: 0.8812\n",
      "Epoch 11/30\n",
      " - 112s - loss: 0.3462 - acc: 0.9204 - val_loss: 0.8713 - val_acc: 0.8602\n",
      "Epoch 12/30\n",
      " - 112s - loss: 0.2796 - acc: 0.9270 - val_loss: 1.0391 - val_acc: 0.8629\n",
      "Epoch 13/30\n",
      " - 112s - loss: 0.3115 - acc: 0.9234 - val_loss: 0.8092 - val_acc: 0.8548\n",
      "Epoch 14/30\n",
      " - 112s - loss: 0.2593 - acc: 0.9331 - val_loss: 0.9853 - val_acc: 0.8826\n",
      "Epoch 15/30\n",
      " - 111s - loss: 0.2985 - acc: 0.9310 - val_loss: 0.7689 - val_acc: 0.8901\n",
      "Epoch 16/30\n",
      " - 112s - loss: 0.3149 - acc: 0.9268 - val_loss: 0.7485 - val_acc: 0.9040\n",
      "Epoch 17/30\n",
      " - 111s - loss: 0.2692 - acc: 0.9327 - val_loss: 0.9946 - val_acc: 0.8887\n",
      "Epoch 18/30\n",
      " - 112s - loss: 0.2224 - acc: 0.9412 - val_loss: 0.8671 - val_acc: 0.9040\n",
      "Epoch 19/30\n",
      " - 112s - loss: 0.2948 - acc: 0.9355 - val_loss: 0.9961 - val_acc: 0.8911\n",
      "Epoch 20/30\n",
      " - 112s - loss: 0.3114 - acc: 0.9335 - val_loss: 0.8864 - val_acc: 0.8907\n",
      "Epoch 21/30\n",
      " - 112s - loss: 0.2119 - acc: 0.9395 - val_loss: 0.9013 - val_acc: 0.8951\n",
      "Epoch 22/30\n",
      " - 112s - loss: 0.1955 - acc: 0.9472 - val_loss: 1.2858 - val_acc: 0.8863\n",
      "Epoch 23/30\n",
      " - 112s - loss: 0.2033 - acc: 0.9476 - val_loss: 1.1028 - val_acc: 0.8853\n",
      "Epoch 24/30\n",
      " - 112s - loss: 0.2260 - acc: 0.9448 - val_loss: 0.7571 - val_acc: 0.9169\n",
      "Epoch 25/30\n",
      " - 111s - loss: 0.2121 - acc: 0.9489 - val_loss: 0.9081 - val_acc: 0.8979\n",
      "Epoch 26/30\n",
      " - 111s - loss: 0.2351 - acc: 0.9480 - val_loss: 0.6938 - val_acc: 0.9053\n",
      "Epoch 27/30\n",
      " - 112s - loss: 0.1817 - acc: 0.9489 - val_loss: 0.8636 - val_acc: 0.9118\n",
      "Epoch 28/30\n",
      " - 112s - loss: 0.2097 - acc: 0.9480 - val_loss: 0.7828 - val_acc: 0.9019\n",
      "Epoch 29/30\n",
      " - 112s - loss: 0.2703 - acc: 0.9436 - val_loss: 0.7614 - val_acc: 0.9060\n",
      "Epoch 30/30\n",
      " - 112s - loss: 0.2324 - acc: 0.9459 - val_loss: 0.8418 - val_acc: 0.8914\n",
      "Test accuracy: 0.8914149983033594\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM2_1 (LSTM)               (None, 128, 38)           7296      \n",
      "_________________________________________________________________\n",
      "Dropout2_1 (Dropout)         (None, 128, 38)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2_2 (LSTM)               (None, 32)                9088      \n",
      "_________________________________________________________________\n",
      "Dropout2_2 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 16,582\n",
      "Trainable params: 16,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 117s - loss: 1.5296 - acc: 0.3341 - val_loss: 1.4561 - val_acc: 0.4876\n",
      "Epoch 2/30\n",
      " - 115s - loss: 1.2383 - acc: 0.4608 - val_loss: 0.9390 - val_acc: 0.5667\n",
      "Epoch 3/30\n",
      " - 115s - loss: 0.9184 - acc: 0.5537 - val_loss: 0.9031 - val_acc: 0.5721\n",
      "Epoch 4/30\n",
      " - 115s - loss: 1.2038 - acc: 0.4587 - val_loss: 1.4212 - val_acc: 0.3556\n",
      "Epoch 5/30\n",
      " - 115s - loss: 1.1103 - acc: 0.4985 - val_loss: 0.9811 - val_acc: 0.5687\n",
      "Epoch 6/30\n",
      " - 115s - loss: 0.9085 - acc: 0.5677 - val_loss: 1.0072 - val_acc: 0.5389\n",
      "Epoch 7/30\n",
      " - 115s - loss: 0.8435 - acc: 0.5822 - val_loss: 0.9197 - val_acc: 0.5819\n",
      "Epoch 8/30\n",
      " - 115s - loss: 0.8009 - acc: 0.6193 - val_loss: 0.8783 - val_acc: 0.5979\n",
      "Epoch 9/30\n",
      " - 115s - loss: 0.8192 - acc: 0.6200 - val_loss: 0.9072 - val_acc: 0.6026\n",
      "Epoch 10/30\n",
      " - 115s - loss: 0.7571 - acc: 0.6187 - val_loss: 0.8579 - val_acc: 0.6162\n",
      "Epoch 11/30\n",
      " - 115s - loss: 0.7762 - acc: 0.6315 - val_loss: 0.8407 - val_acc: 0.6254\n",
      "Epoch 12/30\n",
      " - 115s - loss: 1.0781 - acc: 0.5133 - val_loss: 1.2932 - val_acc: 0.4147\n",
      "Epoch 13/30\n",
      " - 115s - loss: 1.2008 - acc: 0.4531 - val_loss: 1.0318 - val_acc: 0.5684\n",
      "Epoch 14/30\n",
      " - 115s - loss: 0.8106 - acc: 0.6344 - val_loss: 0.7879 - val_acc: 0.6203\n",
      "Epoch 15/30\n",
      " - 114s - loss: 0.7129 - acc: 0.6447 - val_loss: 0.7458 - val_acc: 0.6274\n",
      "Epoch 16/30\n",
      " - 115s - loss: 0.6834 - acc: 0.6595 - val_loss: 0.7537 - val_acc: 0.6247\n",
      "Epoch 17/30\n",
      " - 115s - loss: 0.6826 - acc: 0.6499 - val_loss: 0.7547 - val_acc: 0.5908\n",
      "Epoch 18/30\n",
      " - 115s - loss: 0.7327 - acc: 0.6394 - val_loss: 0.8384 - val_acc: 0.6183\n",
      "Epoch 19/30\n",
      " - 115s - loss: 0.6892 - acc: 0.6489 - val_loss: 0.7795 - val_acc: 0.6196\n",
      "Epoch 20/30\n",
      " - 115s - loss: 0.7285 - acc: 0.6459 - val_loss: 0.8308 - val_acc: 0.6050\n",
      "Epoch 21/30\n",
      " - 115s - loss: 0.7120 - acc: 0.6402 - val_loss: 0.8046 - val_acc: 0.6067\n",
      "Epoch 22/30\n",
      " - 115s - loss: 0.6636 - acc: 0.6532 - val_loss: 0.7412 - val_acc: 0.6216\n",
      "Epoch 23/30\n",
      " - 114s - loss: 0.7886 - acc: 0.6255 - val_loss: 1.1953 - val_acc: 0.4910\n",
      "Epoch 24/30\n",
      " - 115s - loss: 1.0712 - acc: 0.4948 - val_loss: 0.7798 - val_acc: 0.6162\n",
      "Epoch 25/30\n",
      " - 115s - loss: 0.7376 - acc: 0.6514 - val_loss: 0.7224 - val_acc: 0.6274\n",
      "Epoch 26/30\n",
      " - 115s - loss: 0.7513 - acc: 0.6495 - val_loss: 0.7578 - val_acc: 0.6244\n",
      "Epoch 27/30\n",
      " - 115s - loss: 0.6702 - acc: 0.6591 - val_loss: 0.7168 - val_acc: 0.6800\n",
      "Epoch 28/30\n",
      " - 115s - loss: 0.6637 - acc: 0.6695 - val_loss: 0.7188 - val_acc: 0.6688\n",
      "Epoch 29/30\n",
      " - 115s - loss: 0.7230 - acc: 0.6480 - val_loss: 0.7956 - val_acc: 0.6512\n",
      "Epoch 30/30\n",
      " - 115s - loss: 0.7597 - acc: 0.6450 - val_loss: 0.7395 - val_acc: 0.6736\n",
      "Test accuracy: 0.673566338649474\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM2_1 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "Dropout2_1 (Dropout)         (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2_2 (LSTM)               (None, 26)                6136      \n",
      "_________________________________________________________________\n",
      "Dropout2_2 (Dropout)         (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 162       \n",
      "=================================================================\n",
      "Total params: 11,674\n",
      "Trainable params: 11,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 116s - loss: 1.3997 - acc: 0.3817 - val_loss: 1.4977 - val_acc: 0.3139\n",
      "Epoch 2/30\n",
      " - 113s - loss: 1.1907 - acc: 0.4922 - val_loss: 1.0425 - val_acc: 0.4971\n",
      "Epoch 3/30\n",
      " - 113s - loss: 0.8832 - acc: 0.5906 - val_loss: 0.8801 - val_acc: 0.6077\n",
      "Epoch 4/30\n",
      " - 113s - loss: 0.8497 - acc: 0.6089 - val_loss: 1.0227 - val_acc: 0.5395\n",
      "Epoch 5/30\n",
      " - 113s - loss: 0.8742 - acc: 0.6083 - val_loss: 0.8807 - val_acc: 0.6016\n",
      "Epoch 6/30\n",
      " - 114s - loss: 0.8527 - acc: 0.6085 - val_loss: 0.9190 - val_acc: 0.5646\n",
      "Epoch 7/30\n",
      " - 113s - loss: 0.9217 - acc: 0.5895 - val_loss: 0.9211 - val_acc: 0.5925\n",
      "Epoch 8/30\n",
      " - 114s - loss: 0.8325 - acc: 0.6280 - val_loss: 0.8287 - val_acc: 0.6050\n",
      "Epoch 9/30\n",
      " - 113s - loss: 0.7780 - acc: 0.6338 - val_loss: 0.8622 - val_acc: 0.6101\n",
      "Epoch 10/30\n",
      " - 113s - loss: 1.4237 - acc: 0.4249 - val_loss: 1.4747 - val_acc: 0.5029\n",
      "Epoch 11/30\n",
      " - 113s - loss: 1.2080 - acc: 0.4835 - val_loss: 1.0813 - val_acc: 0.5633\n",
      "Epoch 12/30\n",
      " - 114s - loss: 0.8836 - acc: 0.5924 - val_loss: 0.9811 - val_acc: 0.5959\n",
      "Epoch 13/30\n",
      " - 114s - loss: 1.0894 - acc: 0.5231 - val_loss: 1.1186 - val_acc: 0.5151\n",
      "Epoch 14/30\n",
      " - 113s - loss: 0.9932 - acc: 0.5367 - val_loss: 1.0401 - val_acc: 0.5053\n",
      "Epoch 15/30\n",
      " - 113s - loss: 0.9519 - acc: 0.5646 - val_loss: 1.0127 - val_acc: 0.5097\n",
      "Epoch 16/30\n",
      " - 114s - loss: 0.9355 - acc: 0.6186 - val_loss: 0.9665 - val_acc: 0.5847\n",
      "Epoch 17/30\n",
      " - 113s - loss: 0.8531 - acc: 0.6378 - val_loss: 0.8733 - val_acc: 0.6088\n",
      "Epoch 18/30\n",
      " - 114s - loss: 0.8238 - acc: 0.6472 - val_loss: 0.8909 - val_acc: 0.6006\n",
      "Epoch 19/30\n",
      " - 113s - loss: 0.7985 - acc: 0.6564 - val_loss: 0.9155 - val_acc: 0.5422\n",
      "Epoch 20/30\n",
      " - 114s - loss: 0.8029 - acc: 0.6555 - val_loss: 0.9345 - val_acc: 0.6094\n",
      "Epoch 21/30\n",
      " - 113s - loss: 0.7954 - acc: 0.6575 - val_loss: 0.9065 - val_acc: 0.6410\n",
      "Epoch 22/30\n",
      " - 113s - loss: 0.7906 - acc: 0.6700 - val_loss: 0.9385 - val_acc: 0.5443\n",
      "Epoch 23/30\n",
      " - 113s - loss: 0.7928 - acc: 0.6568 - val_loss: 0.9592 - val_acc: 0.5592\n",
      "Epoch 24/30\n",
      " - 114s - loss: 0.7944 - acc: 0.6620 - val_loss: 0.9956 - val_acc: 0.5304\n",
      "Epoch 25/30\n",
      " - 114s - loss: 0.7747 - acc: 0.6609 - val_loss: 1.0209 - val_acc: 0.5249\n",
      "Epoch 26/30\n",
      " - 114s - loss: 0.7727 - acc: 0.6680 - val_loss: 0.9124 - val_acc: 0.6376\n",
      "Epoch 27/30\n",
      " - 113s - loss: 0.7619 - acc: 0.6710 - val_loss: 0.9372 - val_acc: 0.5236\n",
      "Epoch 28/30\n",
      " - 113s - loss: 0.7483 - acc: 0.6744 - val_loss: 0.9400 - val_acc: 0.6135\n",
      "Epoch 29/30\n",
      " - 113s - loss: 0.7346 - acc: 0.6794 - val_loss: 0.9644 - val_acc: 0.6328\n",
      "Epoch 30/30\n",
      " - 114s - loss: 0.7393 - acc: 0.6857 - val_loss: 0.9658 - val_acc: 0.5962\n",
      "Test accuracy: 0.5961995249507304\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM1_1 (LSTM)               (None, 28)                4256      \n",
      "_________________________________________________________________\n",
      "Dropout1_1 (Dropout)         (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 174       \n",
      "=================================================================\n",
      "Total params: 4,430\n",
      "Trainable params: 4,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 56s - loss: 1.1159 - acc: 0.4990 - val_loss: 0.8833 - val_acc: 0.6060\n",
      "Epoch 2/30\n",
      " - 53s - loss: 0.7621 - acc: 0.6319 - val_loss: 0.8008 - val_acc: 0.5955\n",
      "Epoch 3/30\n",
      " - 54s - loss: 0.7072 - acc: 0.6363 - val_loss: 0.6816 - val_acc: 0.6064\n",
      "Epoch 4/30\n",
      " - 54s - loss: 0.6291 - acc: 0.6567 - val_loss: 0.7050 - val_acc: 0.6247\n",
      "Epoch 5/30\n",
      " - 54s - loss: 0.5655 - acc: 0.7236 - val_loss: 0.5158 - val_acc: 0.7564\n",
      "Epoch 6/30\n",
      " - 53s - loss: 0.4537 - acc: 0.8071 - val_loss: 0.6697 - val_acc: 0.7581\n",
      "Epoch 7/30\n",
      " - 54s - loss: 0.3525 - acc: 0.8992 - val_loss: 0.6083 - val_acc: 0.8588\n",
      "Epoch 8/30\n",
      " - 53s - loss: 0.2895 - acc: 0.9185 - val_loss: 0.4039 - val_acc: 0.8863\n",
      "Epoch 9/30\n",
      " - 54s - loss: 0.2687 - acc: 0.9267 - val_loss: 0.4397 - val_acc: 0.8948\n",
      "Epoch 10/30\n",
      " - 54s - loss: 0.2544 - acc: 0.9321 - val_loss: 0.5715 - val_acc: 0.8649\n",
      "Epoch 11/30\n",
      " - 53s - loss: 0.2165 - acc: 0.9378 - val_loss: 0.4928 - val_acc: 0.8660\n",
      "Epoch 12/30\n",
      " - 53s - loss: 0.2228 - acc: 0.9365 - val_loss: 0.3271 - val_acc: 0.9101\n",
      "Epoch 13/30\n",
      " - 54s - loss: 0.2147 - acc: 0.9392 - val_loss: 0.4956 - val_acc: 0.8918\n",
      "Epoch 14/30\n",
      " - 54s - loss: 0.2089 - acc: 0.9384 - val_loss: 0.3574 - val_acc: 0.9135\n",
      "Epoch 15/30\n",
      " - 54s - loss: 0.2050 - acc: 0.9361 - val_loss: 0.4138 - val_acc: 0.9182\n",
      "Epoch 16/30\n",
      " - 53s - loss: 0.2098 - acc: 0.9377 - val_loss: 0.3259 - val_acc: 0.9135\n",
      "Epoch 17/30\n",
      " - 53s - loss: 0.1989 - acc: 0.9385 - val_loss: 0.4665 - val_acc: 0.9009\n",
      "Epoch 18/30\n",
      " - 53s - loss: 0.2019 - acc: 0.9392 - val_loss: 0.8034 - val_acc: 0.8588\n",
      "Epoch 19/30\n",
      " - 54s - loss: 0.1824 - acc: 0.9468 - val_loss: 0.3951 - val_acc: 0.8945\n",
      "Epoch 20/30\n",
      " - 54s - loss: 0.1787 - acc: 0.9419 - val_loss: 0.3930 - val_acc: 0.9026\n",
      "Epoch 21/30\n",
      " - 54s - loss: 0.1685 - acc: 0.9471 - val_loss: 0.6037 - val_acc: 0.8951\n",
      "Epoch 22/30\n",
      " - 54s - loss: 0.1908 - acc: 0.9455 - val_loss: 1.0361 - val_acc: 0.8259\n",
      "Epoch 23/30\n",
      " - 53s - loss: 0.1743 - acc: 0.9464 - val_loss: 0.5038 - val_acc: 0.9111\n",
      "Epoch 24/30\n",
      " - 53s - loss: 0.1644 - acc: 0.9504 - val_loss: 0.5073 - val_acc: 0.9046\n",
      "Epoch 25/30\n",
      " - 54s - loss: 0.1617 - acc: 0.9497 - val_loss: 0.6129 - val_acc: 0.8846\n",
      "Epoch 26/30\n",
      " - 54s - loss: 0.1754 - acc: 0.9480 - val_loss: 0.6234 - val_acc: 0.8989\n",
      "Epoch 27/30\n",
      " - 54s - loss: 0.1600 - acc: 0.9514 - val_loss: 0.6284 - val_acc: 0.8948\n",
      "Epoch 28/30\n",
      " - 53s - loss: 0.1748 - acc: 0.9476 - val_loss: 0.5432 - val_acc: 0.9006\n",
      "Epoch 29/30\n",
      " - 54s - loss: 0.1575 - acc: 0.9518 - val_loss: 0.6938 - val_acc: 0.8802\n",
      "Epoch 30/30\n",
      " - 54s - loss: 0.1635 - acc: 0.9502 - val_loss: 0.5709 - val_acc: 0.9080\n",
      "Test accuracy: 0.9080420766881574\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM1_1 (LSTM)               (None, 28)                4256      \n",
      "_________________________________________________________________\n",
      "Dropout1_1 (Dropout)         (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 174       \n",
      "=================================================================\n",
      "Total params: 4,430\n",
      "Trainable params: 4,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 57s - loss: 1.1384 - acc: 0.4871 - val_loss: 0.9078 - val_acc: 0.5752\n",
      "Epoch 2/30\n",
      " - 55s - loss: 0.7859 - acc: 0.6450 - val_loss: 0.6904 - val_acc: 0.7234\n",
      "Epoch 3/30\n",
      " - 55s - loss: 0.5756 - acc: 0.7835 - val_loss: 0.6575 - val_acc: 0.7743\n",
      "Epoch 4/30\n",
      " - 54s - loss: 0.4032 - acc: 0.8697 - val_loss: 0.5826 - val_acc: 0.8124\n",
      "Epoch 5/30\n",
      " - 54s - loss: 0.3922 - acc: 0.8872 - val_loss: 0.5953 - val_acc: 0.8276\n",
      "Epoch 6/30\n",
      " - 55s - loss: 0.3531 - acc: 0.8987 - val_loss: 0.5288 - val_acc: 0.8751\n",
      "Epoch 7/30\n",
      " - 55s - loss: 0.2814 - acc: 0.9208 - val_loss: 0.7520 - val_acc: 0.8493\n",
      "Epoch 8/30\n",
      " - 54s - loss: 0.2437 - acc: 0.9300 - val_loss: 0.5382 - val_acc: 0.8707\n",
      "Epoch 9/30\n",
      " - 55s - loss: 0.2432 - acc: 0.9294 - val_loss: 0.8665 - val_acc: 0.8649\n",
      "Epoch 10/30\n",
      " - 54s - loss: 0.2525 - acc: 0.9332 - val_loss: 0.6180 - val_acc: 0.8823\n",
      "Epoch 11/30\n",
      " - 55s - loss: 0.2438 - acc: 0.9350 - val_loss: 0.8062 - val_acc: 0.8812\n",
      "Epoch 12/30\n",
      " - 54s - loss: 0.2181 - acc: 0.9359 - val_loss: 0.5735 - val_acc: 0.8867\n",
      "Epoch 13/30\n",
      " - 55s - loss: 0.2097 - acc: 0.9363 - val_loss: 0.8048 - val_acc: 0.8711\n",
      "Epoch 14/30\n",
      " - 55s - loss: 0.1825 - acc: 0.9422 - val_loss: 0.5308 - val_acc: 0.8884\n",
      "Epoch 15/30\n",
      " - 55s - loss: 0.2044 - acc: 0.9389 - val_loss: 0.8616 - val_acc: 0.8592\n",
      "Epoch 16/30\n",
      " - 54s - loss: 0.1932 - acc: 0.9407 - val_loss: 0.8238 - val_acc: 0.8850\n",
      "Epoch 17/30\n",
      " - 55s - loss: 0.2073 - acc: 0.9350 - val_loss: 1.0110 - val_acc: 0.8575\n",
      "Epoch 18/30\n",
      " - 55s - loss: 0.2428 - acc: 0.9370 - val_loss: 0.8547 - val_acc: 0.8826\n",
      "Epoch 19/30\n",
      " - 55s - loss: 0.1989 - acc: 0.9404 - val_loss: 0.8010 - val_acc: 0.8856\n",
      "Epoch 20/30\n",
      " - 54s - loss: 0.2050 - acc: 0.9404 - val_loss: 0.6379 - val_acc: 0.8812\n",
      "Epoch 21/30\n",
      " - 55s - loss: 0.1937 - acc: 0.9393 - val_loss: 0.6550 - val_acc: 0.9040\n",
      "Epoch 22/30\n",
      " - 54s - loss: 0.1771 - acc: 0.9426 - val_loss: 0.5317 - val_acc: 0.8968\n",
      "Epoch 23/30\n",
      " - 55s - loss: 0.1857 - acc: 0.9430 - val_loss: 0.7792 - val_acc: 0.8775\n",
      "Epoch 24/30\n",
      " - 54s - loss: 0.1789 - acc: 0.9453 - val_loss: 0.6949 - val_acc: 0.8870\n",
      "Epoch 25/30\n",
      " - 55s - loss: 0.1665 - acc: 0.9430 - val_loss: 0.7166 - val_acc: 0.8694\n",
      "Epoch 26/30\n",
      " - 54s - loss: 0.1960 - acc: 0.9437 - val_loss: 0.8243 - val_acc: 0.8799\n",
      "Epoch 27/30\n",
      " - 55s - loss: 0.2010 - acc: 0.9426 - val_loss: 0.6781 - val_acc: 0.8951\n",
      "Epoch 28/30\n",
      " - 55s - loss: 0.1664 - acc: 0.9476 - val_loss: 0.8844 - val_acc: 0.8839\n",
      "Epoch 29/30\n",
      " - 55s - loss: 0.1778 - acc: 0.9468 - val_loss: 0.7395 - val_acc: 0.8744\n",
      "Epoch 30/30\n",
      " - 54s - loss: 0.1610 - acc: 0.9471 - val_loss: 0.8714 - val_acc: 0.8585\n",
      "Test accuracy: 0.8585001696640652\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM1_1 (LSTM)               (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "Dropout1_1 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 56s - loss: 1.1627 - acc: 0.4997 - val_loss: 1.0767 - val_acc: 0.5395\n",
      "Epoch 2/30\n",
      " - 54s - loss: 0.7603 - acc: 0.6753 - val_loss: 0.6746 - val_acc: 0.7024\n",
      "Epoch 3/30\n",
      " - 54s - loss: 0.5395 - acc: 0.8118 - val_loss: 0.4673 - val_acc: 0.8293\n",
      "Epoch 4/30\n",
      " - 54s - loss: 0.3655 - acc: 0.8972 - val_loss: 0.4531 - val_acc: 0.8521\n",
      "Epoch 5/30\n",
      " - 54s - loss: 0.3289 - acc: 0.9109 - val_loss: 0.3577 - val_acc: 0.8833\n",
      "Epoch 6/30\n",
      " - 54s - loss: 0.2702 - acc: 0.9276 - val_loss: 0.5242 - val_acc: 0.8687\n",
      "Epoch 7/30\n",
      " - 54s - loss: 0.2520 - acc: 0.9314 - val_loss: 0.3830 - val_acc: 0.8965\n",
      "Epoch 8/30\n",
      " - 54s - loss: 0.2218 - acc: 0.9348 - val_loss: 0.4224 - val_acc: 0.9030\n",
      "Epoch 9/30\n",
      " - 54s - loss: 0.2194 - acc: 0.9385 - val_loss: 0.4662 - val_acc: 0.8826\n",
      "Epoch 10/30\n",
      " - 55s - loss: 0.2095 - acc: 0.9384 - val_loss: 0.4849 - val_acc: 0.8880\n",
      "Epoch 11/30\n",
      " - 55s - loss: 0.2168 - acc: 0.9392 - val_loss: 0.3884 - val_acc: 0.9016\n",
      "Epoch 12/30\n",
      " - 55s - loss: 0.2031 - acc: 0.9387 - val_loss: 0.4717 - val_acc: 0.8836\n",
      "Epoch 13/30\n",
      " - 55s - loss: 0.1956 - acc: 0.9429 - val_loss: 0.3812 - val_acc: 0.8955\n",
      "Epoch 14/30\n",
      " - 55s - loss: 0.1765 - acc: 0.9472 - val_loss: 0.5949 - val_acc: 0.8958\n",
      "Epoch 15/30\n",
      " - 54s - loss: 0.1944 - acc: 0.9436 - val_loss: 0.4595 - val_acc: 0.9026\n",
      "Epoch 16/30\n",
      " - 54s - loss: 0.1752 - acc: 0.9484 - val_loss: 0.4092 - val_acc: 0.9046\n",
      "Epoch 17/30\n",
      " - 55s - loss: 0.1727 - acc: 0.9453 - val_loss: 0.3518 - val_acc: 0.8965\n",
      "Epoch 18/30\n",
      " - 54s - loss: 0.1679 - acc: 0.9438 - val_loss: 0.4842 - val_acc: 0.8989\n",
      "Epoch 19/30\n",
      " - 54s - loss: 0.1715 - acc: 0.9479 - val_loss: 0.4790 - val_acc: 0.8911\n",
      "Epoch 20/30\n",
      " - 55s - loss: 0.1777 - acc: 0.9463 - val_loss: 0.6256 - val_acc: 0.8748\n",
      "Epoch 21/30\n",
      " - 54s - loss: 0.1576 - acc: 0.9491 - val_loss: 0.4094 - val_acc: 0.9094\n",
      "Epoch 22/30\n",
      " - 54s - loss: 0.1655 - acc: 0.9472 - val_loss: 0.4630 - val_acc: 0.9019\n",
      "Epoch 23/30\n",
      " - 54s - loss: 0.1548 - acc: 0.9486 - val_loss: 0.4075 - val_acc: 0.9009\n",
      "Epoch 24/30\n",
      " - 55s - loss: 0.1537 - acc: 0.9498 - val_loss: 0.5320 - val_acc: 0.8904\n",
      "Epoch 25/30\n",
      " - 55s - loss: 0.1508 - acc: 0.9512 - val_loss: 0.6119 - val_acc: 0.9050\n",
      "Epoch 26/30\n",
      " - 54s - loss: 0.1562 - acc: 0.9470 - val_loss: 0.4720 - val_acc: 0.8975\n",
      "Epoch 27/30\n",
      " - 54s - loss: 0.1473 - acc: 0.9499 - val_loss: 0.8082 - val_acc: 0.8809\n",
      "Epoch 28/30\n",
      " - 54s - loss: 0.1444 - acc: 0.9524 - val_loss: 0.6733 - val_acc: 0.8897\n",
      "Epoch 29/30\n",
      " - 55s - loss: 0.1508 - acc: 0.9510 - val_loss: 0.5657 - val_acc: 0.9030\n",
      "Epoch 30/30\n",
      " - 54s - loss: 0.1428 - acc: 0.9512 - val_loss: 0.4780 - val_acc: 0.9172\n",
      "Test accuracy: 0.9172039362063115\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM1_1 (LSTM)               (None, 36)                6624      \n",
      "_________________________________________________________________\n",
      "Dropout1_1 (Dropout)         (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 222       \n",
      "=================================================================\n",
      "Total params: 6,846\n",
      "Trainable params: 6,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 57s - loss: 1.1751 - acc: 0.5121 - val_loss: 0.8565 - val_acc: 0.6386\n",
      "Epoch 2/30\n",
      " - 55s - loss: 1.3933 - acc: 0.5654 - val_loss: 1.4125 - val_acc: 0.5898\n",
      "Epoch 3/30\n",
      " - 55s - loss: 1.0599 - acc: 0.6488 - val_loss: 0.9485 - val_acc: 0.6189\n",
      "Epoch 4/30\n",
      " - 55s - loss: 0.8547 - acc: 0.6576 - val_loss: 0.9183 - val_acc: 0.6685\n",
      "Epoch 5/30\n",
      " - 55s - loss: 0.6698 - acc: 0.7356 - val_loss: 0.8007 - val_acc: 0.7509\n",
      "Epoch 6/30\n",
      " - 55s - loss: 0.5329 - acc: 0.8184 - val_loss: 0.6638 - val_acc: 0.8334\n",
      "Epoch 7/30\n",
      " - 55s - loss: 0.4624 - acc: 0.8626 - val_loss: 1.1916 - val_acc: 0.6030\n",
      "Epoch 8/30\n",
      " - 55s - loss: 0.6670 - acc: 0.7958 - val_loss: 0.7028 - val_acc: 0.8476\n",
      "Epoch 9/30\n",
      " - 55s - loss: 0.3917 - acc: 0.9041 - val_loss: 0.6530 - val_acc: 0.8636\n",
      "Epoch 10/30\n",
      " - 55s - loss: 0.3107 - acc: 0.9161 - val_loss: 0.5861 - val_acc: 0.8775\n",
      "Epoch 11/30\n",
      " - 55s - loss: 0.3224 - acc: 0.9132 - val_loss: 0.5838 - val_acc: 0.8673\n",
      "Epoch 12/30\n",
      " - 55s - loss: 0.2968 - acc: 0.9217 - val_loss: 0.5438 - val_acc: 0.8697\n",
      "Epoch 13/30\n",
      " - 55s - loss: 0.2591 - acc: 0.9280 - val_loss: 0.6289 - val_acc: 0.8772\n",
      "Epoch 14/30\n",
      " - 55s - loss: 0.2558 - acc: 0.9309 - val_loss: 0.5403 - val_acc: 0.8680\n",
      "Epoch 15/30\n",
      " - 55s - loss: 0.2329 - acc: 0.9329 - val_loss: 0.6780 - val_acc: 0.8578\n",
      "Epoch 16/30\n",
      " - 55s - loss: 0.2715 - acc: 0.9312 - val_loss: 0.5799 - val_acc: 0.8775\n",
      "Epoch 17/30\n",
      " - 55s - loss: 0.3103 - acc: 0.9173 - val_loss: 0.4122 - val_acc: 0.8880\n",
      "Epoch 18/30\n",
      " - 55s - loss: 0.2286 - acc: 0.9362 - val_loss: 0.6918 - val_acc: 0.8510\n",
      "Epoch 19/30\n",
      " - 55s - loss: 0.2378 - acc: 0.9336 - val_loss: 0.5272 - val_acc: 0.8877\n",
      "Epoch 20/30\n",
      " - 55s - loss: 0.2437 - acc: 0.9339 - val_loss: 0.4316 - val_acc: 0.8846\n",
      "Epoch 21/30\n",
      " - 55s - loss: 0.2078 - acc: 0.9377 - val_loss: 0.5531 - val_acc: 0.8799\n",
      "Epoch 22/30\n",
      " - 55s - loss: 0.2344 - acc: 0.9328 - val_loss: 0.4419 - val_acc: 0.8890\n",
      "Epoch 23/30\n",
      " - 55s - loss: 0.2114 - acc: 0.9385 - val_loss: 0.4200 - val_acc: 0.8806\n",
      "Epoch 24/30\n",
      " - 55s - loss: 0.1937 - acc: 0.9419 - val_loss: 0.4129 - val_acc: 0.8935\n",
      "Epoch 25/30\n",
      " - 55s - loss: 0.2091 - acc: 0.9392 - val_loss: 0.5488 - val_acc: 0.8646\n",
      "Epoch 26/30\n",
      " - 55s - loss: 0.2399 - acc: 0.9347 - val_loss: 0.4561 - val_acc: 0.8935\n",
      "Epoch 27/30\n",
      " - 55s - loss: 0.2055 - acc: 0.9387 - val_loss: 0.4420 - val_acc: 0.8985\n",
      "Epoch 28/30\n",
      " - 55s - loss: 0.2788 - acc: 0.9283 - val_loss: 0.4602 - val_acc: 0.8897\n",
      "Epoch 29/30\n",
      " - 55s - loss: 0.2292 - acc: 0.9381 - val_loss: 0.4052 - val_acc: 0.8958\n",
      "Epoch 30/30\n",
      " - 55s - loss: 0.2152 - acc: 0.9388 - val_loss: 0.4672 - val_acc: 0.8894\n",
      "Test accuracy: 0.8893790295215473\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM2_1 (LSTM)               (None, 128, 38)           7296      \n",
      "_________________________________________________________________\n",
      "Dropout2_1 (Dropout)         (None, 128, 38)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2_2 (LSTM)               (None, 32)                9088      \n",
      "_________________________________________________________________\n",
      "Dropout2_2 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 16,582\n",
      "Trainable params: 16,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 119s - loss: 1.3962 - acc: 0.3897 - val_loss: 1.1641 - val_acc: 0.4649\n",
      "Epoch 2/30\n",
      " - 116s - loss: 0.9053 - acc: 0.6020 - val_loss: 0.7868 - val_acc: 0.5853\n",
      "Epoch 3/30\n",
      " - 116s - loss: 0.7861 - acc: 0.6479 - val_loss: 0.7485 - val_acc: 0.6240\n",
      "Epoch 4/30\n",
      " - 116s - loss: 0.7637 - acc: 0.6405 - val_loss: 0.8719 - val_acc: 0.6162\n",
      "Epoch 5/30\n",
      " - 116s - loss: 0.6971 - acc: 0.6980 - val_loss: 1.0038 - val_acc: 0.6345\n",
      "Epoch 6/30\n",
      " - 115s - loss: 0.5672 - acc: 0.8048 - val_loss: 0.7988 - val_acc: 0.8280\n",
      "Epoch 7/30\n",
      " - 116s - loss: 0.4332 - acc: 0.8856 - val_loss: 0.7549 - val_acc: 0.8307\n",
      "Epoch 8/30\n",
      " - 116s - loss: 0.3788 - acc: 0.9042 - val_loss: 0.6115 - val_acc: 0.8795\n",
      "Epoch 9/30\n",
      " - 115s - loss: 0.3367 - acc: 0.9138 - val_loss: 0.7760 - val_acc: 0.8663\n",
      "Epoch 10/30\n",
      " - 116s - loss: 0.3072 - acc: 0.9139 - val_loss: 0.5898 - val_acc: 0.9094\n",
      "Epoch 11/30\n",
      " - 115s - loss: 0.2979 - acc: 0.9217 - val_loss: 0.7345 - val_acc: 0.8897\n",
      "Epoch 12/30\n",
      " - 115s - loss: 0.2988 - acc: 0.9212 - val_loss: 0.5408 - val_acc: 0.8914\n",
      "Epoch 13/30\n",
      " - 116s - loss: 0.2695 - acc: 0.9267 - val_loss: 0.7084 - val_acc: 0.8904\n",
      "Epoch 14/30\n",
      " - 115s - loss: 0.2583 - acc: 0.9285 - val_loss: 0.7715 - val_acc: 0.8894\n",
      "Epoch 15/30\n",
      " - 115s - loss: 0.2734 - acc: 0.9267 - val_loss: 0.9041 - val_acc: 0.8982\n",
      "Epoch 16/30\n",
      " - 116s - loss: 0.2625 - acc: 0.9294 - val_loss: 0.7045 - val_acc: 0.8979\n",
      "Epoch 17/30\n",
      " - 116s - loss: 0.2606 - acc: 0.9289 - val_loss: 0.6480 - val_acc: 0.9006\n",
      "Epoch 18/30\n",
      " - 116s - loss: 0.2542 - acc: 0.9314 - val_loss: 0.7842 - val_acc: 0.8819\n",
      "Epoch 19/30\n",
      " - 115s - loss: 0.2445 - acc: 0.9313 - val_loss: 0.8210 - val_acc: 0.8928\n",
      "Epoch 20/30\n",
      " - 115s - loss: 0.2520 - acc: 0.9321 - val_loss: 0.6904 - val_acc: 0.9050\n",
      "Epoch 21/30\n",
      " - 115s - loss: 0.2544 - acc: 0.9317 - val_loss: 0.7692 - val_acc: 0.8911\n",
      "Epoch 22/30\n",
      " - 116s - loss: 0.2450 - acc: 0.9310 - val_loss: 0.6523 - val_acc: 0.9057\n",
      "Epoch 23/30\n",
      " - 115s - loss: 0.2483 - acc: 0.9329 - val_loss: 0.6386 - val_acc: 0.9040\n",
      "Epoch 24/30\n",
      " - 116s - loss: 0.2394 - acc: 0.9372 - val_loss: 0.6962 - val_acc: 0.8945\n",
      "Epoch 25/30\n",
      " - 115s - loss: 0.2238 - acc: 0.9336 - val_loss: 0.7469 - val_acc: 0.8901\n",
      "Epoch 26/30\n",
      " - 115s - loss: nan - acc: 0.7690 - val_loss: nan - val_acc: 0.1683\n",
      "Epoch 27/30\n",
      " - 116s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683\n",
      "Epoch 28/30\n",
      " - 115s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683\n",
      "Epoch 29/30\n",
      " - 116s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683\n",
      "Epoch 30/30\n",
      " - 116s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683\n",
      "Test accuracy: 0.168306752629793\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM1_1 (LSTM)               (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "Dropout1_1 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 56s - loss: 1.1571 - acc: 0.5097 - val_loss: 1.0674 - val_acc: 0.5833\n",
      "Epoch 2/30\n",
      " - 54s - loss: 1.1179 - acc: 0.5733 - val_loss: 0.9277 - val_acc: 0.5874\n",
      "Epoch 3/30\n",
      " - 54s - loss: 0.8314 - acc: 0.6604 - val_loss: 0.8207 - val_acc: 0.6417\n",
      "Epoch 4/30\n",
      " - 54s - loss: 0.7140 - acc: 0.7183 - val_loss: 0.6658 - val_acc: 0.7710\n",
      "Epoch 5/30\n",
      " - 54s - loss: 0.5664 - acc: 0.8232 - val_loss: 0.6426 - val_acc: 0.8083\n",
      "Epoch 6/30\n",
      " - 54s - loss: 0.3956 - acc: 0.8815 - val_loss: 0.6067 - val_acc: 0.8517\n",
      "Epoch 7/30\n",
      " - 54s - loss: 0.4281 - acc: 0.8859 - val_loss: 0.5300 - val_acc: 0.8799\n",
      "Epoch 8/30\n",
      " - 54s - loss: 0.3570 - acc: 0.9131 - val_loss: 0.5881 - val_acc: 0.8812\n",
      "Epoch 9/30\n",
      " - 54s - loss: 0.3461 - acc: 0.9195 - val_loss: 0.4996 - val_acc: 0.8792\n",
      "Epoch 10/30\n",
      " - 54s - loss: 0.2919 - acc: 0.9267 - val_loss: 0.5529 - val_acc: 0.8768\n",
      "Epoch 11/30\n",
      " - 54s - loss: 0.3594 - acc: 0.9144 - val_loss: 0.5464 - val_acc: 0.8707\n",
      "Epoch 12/30\n",
      " - 54s - loss: 0.3306 - acc: 0.9276 - val_loss: 0.7686 - val_acc: 0.8405\n",
      "Epoch 13/30\n",
      " - 54s - loss: 0.3139 - acc: 0.9253 - val_loss: 0.5115 - val_acc: 0.8721\n",
      "Epoch 14/30\n",
      " - 54s - loss: 0.2549 - acc: 0.9329 - val_loss: 0.4201 - val_acc: 0.8860\n",
      "Epoch 15/30\n",
      " - 54s - loss: 0.2187 - acc: 0.9415 - val_loss: 0.3677 - val_acc: 0.9033\n",
      "Epoch 16/30\n",
      " - 54s - loss: 0.2296 - acc: 0.9346 - val_loss: 0.3998 - val_acc: 0.8951\n",
      "Epoch 17/30\n",
      " - 54s - loss: 0.2213 - acc: 0.9363 - val_loss: 0.4440 - val_acc: 0.8972\n",
      "Epoch 18/30\n",
      " - 54s - loss: 0.2298 - acc: 0.9343 - val_loss: 0.5169 - val_acc: 0.8806\n",
      "Epoch 19/30\n",
      " - 54s - loss: 0.2469 - acc: 0.9358 - val_loss: 0.4917 - val_acc: 0.8992\n",
      "Epoch 20/30\n",
      " - 54s - loss: 0.1910 - acc: 0.9400 - val_loss: 0.3785 - val_acc: 0.9046\n",
      "Epoch 21/30\n",
      " - 54s - loss: 0.1775 - acc: 0.9472 - val_loss: 0.4941 - val_acc: 0.9016\n",
      "Epoch 22/30\n",
      " - 54s - loss: 0.2179 - acc: 0.9376 - val_loss: 0.5053 - val_acc: 0.8972\n",
      "Epoch 23/30\n",
      " - 54s - loss: 0.2553 - acc: 0.9328 - val_loss: 0.4692 - val_acc: 0.8884\n",
      "Epoch 24/30\n",
      " - 54s - loss: 0.1926 - acc: 0.9421 - val_loss: 0.3857 - val_acc: 0.8965\n",
      "Epoch 25/30\n",
      " - 54s - loss: 0.1970 - acc: 0.9395 - val_loss: 0.4568 - val_acc: 0.8962\n",
      "Epoch 26/30\n",
      " - 54s - loss: 0.2238 - acc: 0.9354 - val_loss: 0.5431 - val_acc: 0.8945\n",
      "Epoch 27/30\n",
      " - 54s - loss: 0.1852 - acc: 0.9427 - val_loss: 0.5686 - val_acc: 0.9063\n",
      "Epoch 28/30\n",
      " - 54s - loss: 0.2364 - acc: 0.9343 - val_loss: 0.4388 - val_acc: 0.9006\n",
      "Epoch 29/30\n",
      " - 54s - loss: 0.2425 - acc: 0.9324 - val_loss: 0.4072 - val_acc: 0.9118\n",
      "Epoch 30/30\n",
      " - 54s - loss: 0.1823 - acc: 0.9457 - val_loss: 0.3116 - val_acc: 0.9199\n",
      "Test accuracy: 0.9199185612487275\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM2_1 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "Dropout2_1 (Dropout)         (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "LSTM2_2 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "Dropout2_2 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 13,894\n",
      "Trainable params: 13,894\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 116s - loss: 1.4041 - acc: 0.3607 - val_loss: 1.4238 - val_acc: 0.3448\n",
      "Epoch 2/30\n",
      " - 112s - loss: 1.3603 - acc: 0.3855 - val_loss: 1.4379 - val_acc: 0.4038\n",
      "Epoch 3/30\n",
      " - 112s - loss: 1.3052 - acc: 0.4049 - val_loss: 1.0620 - val_acc: 0.3882\n",
      "Epoch 4/30\n",
      " - 113s - loss: 1.2095 - acc: 0.4909 - val_loss: 1.0250 - val_acc: 0.5083\n",
      "Epoch 5/30\n",
      " - 113s - loss: 0.9901 - acc: 0.5301 - val_loss: 0.8279 - val_acc: 0.6159\n",
      "Epoch 6/30\n",
      " - 112s - loss: 0.8973 - acc: 0.5941 - val_loss: 0.8105 - val_acc: 0.6220\n",
      "Epoch 7/30\n",
      " - 112s - loss: 0.7839 - acc: 0.6291 - val_loss: 0.7552 - val_acc: 0.6176\n",
      "Epoch 8/30\n",
      " - 112s - loss: 0.7660 - acc: 0.6219 - val_loss: 0.8569 - val_acc: 0.5948\n",
      "Epoch 9/30\n",
      " - 112s - loss: 0.7627 - acc: 0.6240 - val_loss: 0.7599 - val_acc: 0.6220\n",
      "Epoch 10/30\n",
      " - 113s - loss: 0.7986 - acc: 0.6296 - val_loss: 0.8444 - val_acc: 0.6172\n",
      "Epoch 11/30\n",
      " - 112s - loss: 0.7062 - acc: 0.6669 - val_loss: 0.8629 - val_acc: 0.6223\n",
      "Epoch 12/30\n",
      " - 112s - loss: 0.6929 - acc: 0.6608 - val_loss: 0.8061 - val_acc: 0.6240\n",
      "Epoch 13/30\n",
      " - 112s - loss: 0.6894 - acc: 0.6632 - val_loss: 0.8014 - val_acc: 0.6264\n",
      "Epoch 14/30\n",
      " - 112s - loss: 0.7562 - acc: 0.6458 - val_loss: 0.8395 - val_acc: 0.6200\n",
      "Epoch 15/30\n",
      " - 112s - loss: 0.7116 - acc: 0.6639 - val_loss: 0.8772 - val_acc: 0.6206\n",
      "Epoch 16/30\n",
      " - 112s - loss: 0.7058 - acc: 0.6564 - val_loss: 0.7293 - val_acc: 0.6213\n",
      "Epoch 17/30\n",
      " - 112s - loss: 0.6849 - acc: 0.6560 - val_loss: 0.7797 - val_acc: 0.6342\n",
      "Epoch 18/30\n",
      " - 112s - loss: 0.6793 - acc: 0.6612 - val_loss: 0.7296 - val_acc: 0.6359\n",
      "Epoch 19/30\n",
      " - 112s - loss: 0.7748 - acc: 0.6462 - val_loss: 0.7778 - val_acc: 0.6210\n",
      "Epoch 20/30\n",
      " - 112s - loss: 0.6893 - acc: 0.6576 - val_loss: 0.7779 - val_acc: 0.6240\n",
      "Epoch 21/30\n",
      " - 112s - loss: 0.6725 - acc: 0.6560 - val_loss: 0.7446 - val_acc: 0.6186\n",
      "Epoch 22/30\n",
      " - 112s - loss: 0.6960 - acc: 0.6564 - val_loss: 0.7433 - val_acc: 0.6301\n",
      "Epoch 23/30\n",
      " - 112s - loss: 0.6884 - acc: 0.6557 - val_loss: 0.7521 - val_acc: 0.6240\n",
      "Epoch 24/30\n",
      " - 112s - loss: 0.6909 - acc: 0.6613 - val_loss: 0.7613 - val_acc: 0.6267\n",
      "Epoch 25/30\n",
      " - 112s - loss: 0.6607 - acc: 0.6676 - val_loss: 0.8038 - val_acc: 0.6172\n",
      "Epoch 26/30\n",
      " - 112s - loss: 0.6454 - acc: 0.6693 - val_loss: 0.8014 - val_acc: 0.6200\n",
      "Epoch 27/30\n",
      " - 112s - loss: 0.6491 - acc: 0.6624 - val_loss: 0.7241 - val_acc: 0.6261\n",
      "Epoch 28/30\n",
      " - 112s - loss: 0.6288 - acc: 0.6723 - val_loss: 0.7202 - val_acc: 0.6318\n",
      "Epoch 29/30\n",
      " - 113s - loss: 0.6441 - acc: 0.6695 - val_loss: 0.7551 - val_acc: 0.6257\n",
      "Epoch 30/30\n",
      " - 112s - loss: 0.6480 - acc: 0.6634 - val_loss: 0.7780 - val_acc: 0.6210\n",
      "Test accuracy: 0.6209704784526637\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = data()\n",
    "trials = Trials()\n",
    "best_run, best_model, space = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=15,\n",
    "                                      trials=trials,notebook_name = 'Human Activity Detection',\n",
    "                                     return_space = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 parameters\n",
      "{'Dropout': [0.36598023572757926], 'Dropout_1': [0.6047146037530785], 'Dropout_2': [0.5188826519950874], 'LSTM': [0], 'LSTM_1': [1], 'LSTM_2': [1], 'choiceval': [1], 'conditional': [0], 'l2': [0.00016900597529479822], 'l2_1': [0.0006108763092812357], 'l2_2': [0.0007371698374615214], 'lr': [0.01942874904782045], 'lr_1': [0.015993860150909475]}\n",
      "\n",
      "{'Dropout': 0.36598023572757926, 'Dropout_1': 0.6047146037530785, 'Dropout_2': 0.5188826519950874, 'LSTM': 28, 'LSTM_1': 32, 'LSTM_2': 32, 'choiceval': 'rmsprop', 'conditional': 'one', 'l2': 0.00016900597529479822, 'l2_1': 0.0006108763092812357, 'l2_2': 0.0007371698374615214, 'lr': 0.01942874904782045, 'lr_1': 0.015993860150909475}\n",
      "------------------------------------------------\n",
      "Model 2 parameters\n",
      "{'Dropout': [0.604072168386432], 'Dropout_1': [0.5642077861572957], 'Dropout_2': [0.4689742513688654], 'LSTM': [0], 'LSTM_1': [1], 'LSTM_2': [0], 'choiceval': [1], 'conditional': [1], 'l2': [2.221286943616341e-06], 'l2_1': [0.0009770005173795487], 'l2_2': [0.0008366666847115819], 'lr': [0.023605271151689124], 'lr_1': [0.015140941766877332]}\n",
      "\n",
      "{'Dropout': 0.604072168386432, 'Dropout_1': 0.5642077861572957, 'Dropout_2': 0.4689742513688654, 'LSTM': 28, 'LSTM_1': 32, 'LSTM_2': 28, 'choiceval': 'rmsprop', 'conditional': 'two', 'l2': 2.221286943616341e-06, 'l2_1': 0.0009770005173795487, 'l2_2': 0.0008366666847115819, 'lr': 0.023605271151689124, 'lr_1': 0.015140941766877332}\n",
      "------------------------------------------------\n",
      "Model 3 parameters\n",
      "{'Dropout': [0.649118836907314], 'Dropout_1': [0.6408661828169875], 'Dropout_2': [0.5025116318997556], 'LSTM': [2], 'LSTM_1': [2], 'LSTM_2': [1], 'choiceval': [1], 'conditional': [1], 'l2': [0.00011247630115130428], 'l2_1': [0.0003949936266626689], 'l2_2': [0.0009758185183456943], 'lr': [0.013618600574440736], 'lr_1': [0.014402022095061829]}\n",
      "\n",
      "{'Dropout': 0.649118836907314, 'Dropout_1': 0.6408661828169875, 'Dropout_2': 0.5025116318997556, 'LSTM': 38, 'LSTM_1': 36, 'LSTM_2': 32, 'choiceval': 'rmsprop', 'conditional': 'two', 'l2': 0.00011247630115130428, 'l2_1': 0.0003949936266626689, 'l2_2': 0.0009758185183456943, 'lr': 0.013618600574440736, 'lr_1': 0.014402022095061829}\n",
      "------------------------------------------------\n",
      "Model 4 parameters\n",
      "{'Dropout': [0.5709919477993022], 'Dropout_1': [0.6574295784428639], 'Dropout_2': [0.39377498664819843], 'LSTM': [1], 'LSTM_1': [1], 'LSTM_2': [2], 'choiceval': [0], 'conditional': [1], 'l2': [0.00019824027740992625], 'l2_1': [0.0007646166765488501], 'l2_2': [0.00041266207281071243], 'lr': [0.01675112837971219], 'lr_1': [0.009417276849790152]}\n",
      "\n",
      "{'Dropout': 0.5709919477993022, 'Dropout_1': 0.6574295784428639, 'Dropout_2': 0.39377498664819843, 'LSTM': 32, 'LSTM_1': 32, 'LSTM_2': 36, 'choiceval': 'adam', 'conditional': 'two', 'l2': 0.00019824027740992625, 'l2_1': 0.0007646166765488501, 'l2_2': 0.00041266207281071243, 'lr': 0.01675112837971219, 'lr_1': 0.009417276849790152}\n",
      "------------------------------------------------\n",
      "Model 5 parameters\n",
      "{'Dropout': [0.48051787644406624], 'Dropout_1': [0.5744163772727372], 'Dropout_2': [0.5086629864785656], 'LSTM': [1], 'LSTM_1': [1], 'LSTM_2': [0], 'choiceval': [0], 'conditional': [1], 'l2': [2.749908849077252e-05], 'l2_1': [0.000587606728324542], 'l2_2': [0.0003746350041674067], 'lr': [0.01834130504525777], 'lr_1': [0.0229410270349058]}\n",
      "\n",
      "{'Dropout': 0.48051787644406624, 'Dropout_1': 0.5744163772727372, 'Dropout_2': 0.5086629864785656, 'LSTM': 32, 'LSTM_1': 32, 'LSTM_2': 28, 'choiceval': 'adam', 'conditional': 'two', 'l2': 2.749908849077252e-05, 'l2_1': 0.000587606728324542, 'l2_2': 0.0003746350041674067, 'lr': 0.01834130504525777, 'lr_1': 0.0229410270349058}\n",
      "------------------------------------------------\n",
      "Model 6 parameters\n",
      "{'Dropout': [0.5813560517914963], 'Dropout_1': [0.6046109124722276], 'Dropout_2': [0.5355832635290444], 'LSTM': [0], 'LSTM_1': [1], 'LSTM_2': [2], 'choiceval': [1], 'conditional': [1], 'l2': [1.612769130873457e-05], 'l2_1': [0.0009772817488940724], 'l2_2': [0.0006883693507416478], 'lr': [0.017446396677831936], 'lr_1': [0.015805655140931824]}\n",
      "\n",
      "{'Dropout': 0.5813560517914963, 'Dropout_1': 0.6046109124722276, 'Dropout_2': 0.5355832635290444, 'LSTM': 28, 'LSTM_1': 32, 'LSTM_2': 36, 'choiceval': 'rmsprop', 'conditional': 'two', 'l2': 1.612769130873457e-05, 'l2_1': 0.0009772817488940724, 'l2_2': 0.0006883693507416478, 'lr': 0.017446396677831936, 'lr_1': 0.015805655140931824}\n",
      "------------------------------------------------\n",
      "Model 7 parameters\n",
      "{'Dropout': [0.5293597400197904], 'Dropout_1': [0.5958807193410454], 'Dropout_2': [0.42617520692074906], 'LSTM': [2], 'LSTM_1': [1], 'LSTM_2': [2], 'choiceval': [0], 'conditional': [1], 'l2': [4.567626225804864e-05], 'l2_1': [0.0005422412690636627], 'l2_2': [0.00033351393608141357], 'lr': [0.01068491666284852], 'lr_1': [0.01643494651558678]}\n",
      "\n",
      "{'Dropout': 0.5293597400197904, 'Dropout_1': 0.5958807193410454, 'Dropout_2': 0.42617520692074906, 'LSTM': 38, 'LSTM_1': 32, 'LSTM_2': 36, 'choiceval': 'adam', 'conditional': 'two', 'l2': 4.567626225804864e-05, 'l2_1': 0.0005422412690636627, 'l2_2': 0.00033351393608141357, 'lr': 0.01068491666284852, 'lr_1': 0.01643494651558678}\n",
      "------------------------------------------------\n",
      "Model 8 parameters\n",
      "{'Dropout': [0.5950749367948185], 'Dropout_1': [0.5997621117444732], 'Dropout_2': [0.4999621572265873], 'LSTM': [1], 'LSTM_1': [0], 'LSTM_2': [1], 'choiceval': [0], 'conditional': [1], 'l2': [5.865420439323175e-05], 'l2_1': [0.0007302305870589934], 'l2_2': [0.000258985915829989], 'lr': [0.010314137826059229], 'lr_1': [0.009310543992889801]}\n",
      "\n",
      "{'Dropout': 0.5950749367948185, 'Dropout_1': 0.5997621117444732, 'Dropout_2': 0.4999621572265873, 'LSTM': 32, 'LSTM_1': 26, 'LSTM_2': 32, 'choiceval': 'adam', 'conditional': 'two', 'l2': 5.865420439323175e-05, 'l2_1': 0.0007302305870589934, 'l2_2': 0.000258985915829989, 'lr': 0.010314137826059229, 'lr_1': 0.009310543992889801}\n",
      "------------------------------------------------\n",
      "Model 9 parameters\n",
      "{'Dropout': [0.45037579382108217], 'Dropout_1': [0.6781762554752515], 'Dropout_2': [0.4794831735512747], 'LSTM': [1], 'LSTM_1': [1], 'LSTM_2': [0], 'choiceval': [1], 'conditional': [0], 'l2': [5.201497156118029e-05], 'l2_1': [0.0006257491042113806], 'l2_2': [0.0004437546321946204], 'lr': [0.023536039320918772], 'lr_1': [0.012611516495429879]}\n",
      "\n",
      "{'Dropout': 0.45037579382108217, 'Dropout_1': 0.6781762554752515, 'Dropout_2': 0.4794831735512747, 'LSTM': 32, 'LSTM_1': 32, 'LSTM_2': 28, 'choiceval': 'rmsprop', 'conditional': 'one', 'l2': 5.201497156118029e-05, 'l2_1': 0.0006257491042113806, 'l2_2': 0.0004437546321946204, 'lr': 0.023536039320918772, 'lr_1': 0.012611516495429879}\n",
      "------------------------------------------------\n",
      "Model 10 parameters\n",
      "{'Dropout': [0.45714950357785966], 'Dropout_1': [0.6894085538291769], 'Dropout_2': [0.45216713875784914], 'LSTM': [0], 'LSTM_1': [1], 'LSTM_2': [0], 'choiceval': [1], 'conditional': [0], 'l2': [7.681307310729229e-05], 'l2_1': [0.0004143619965361732], 'l2_2': [9.225974322037534e-05], 'lr': [0.01235075833910319], 'lr_1': [0.018058999803996133]}\n",
      "\n",
      "{'Dropout': 0.45714950357785966, 'Dropout_1': 0.6894085538291769, 'Dropout_2': 0.45216713875784914, 'LSTM': 28, 'LSTM_1': 32, 'LSTM_2': 28, 'choiceval': 'rmsprop', 'conditional': 'one', 'l2': 7.681307310729229e-05, 'l2_1': 0.0004143619965361732, 'l2_2': 9.225974322037534e-05, 'lr': 0.01235075833910319, 'lr_1': 0.018058999803996133}\n",
      "------------------------------------------------\n",
      "Model 11 parameters\n",
      "{'Dropout': [0.5808002757682877], 'Dropout_1': [0.660514929179723], 'Dropout_2': [0.4733734305745834], 'LSTM': [1], 'LSTM_1': [0], 'LSTM_2': [1], 'choiceval': [1], 'conditional': [0], 'l2': [0.0001195365208222095], 'l2_1': [0.0001849314123467004], 'l2_2': [0.0005106207029550342], 'lr': [0.013696392786995321], 'lr_1': [0.009420957669947726]}\n",
      "\n",
      "{'Dropout': 0.5808002757682877, 'Dropout_1': 0.660514929179723, 'Dropout_2': 0.4733734305745834, 'LSTM': 32, 'LSTM_1': 26, 'LSTM_2': 32, 'choiceval': 'rmsprop', 'conditional': 'one', 'l2': 0.0001195365208222095, 'l2_1': 0.0001849314123467004, 'l2_2': 0.0005106207029550342, 'lr': 0.013696392786995321, 'lr_1': 0.009420957669947726}\n",
      "------------------------------------------------\n",
      "Model 12 parameters\n",
      "{'Dropout': [0.5666044972741778], 'Dropout_1': [0.5837804766498599], 'Dropout_2': [0.38708976069745693], 'LSTM': [1], 'LSTM_1': [2], 'LSTM_2': [2], 'choiceval': [0], 'conditional': [0], 'l2': [6.379888690521487e-05], 'l2_1': [0.00013256157391301627], 'l2_2': [0.0009457487322332761], 'lr': [0.021003723896153827], 'lr_1': [0.014111778261744532]}\n",
      "\n",
      "{'Dropout': 0.5666044972741778, 'Dropout_1': 0.5837804766498599, 'Dropout_2': 0.38708976069745693, 'LSTM': 32, 'LSTM_1': 36, 'LSTM_2': 36, 'choiceval': 'adam', 'conditional': 'one', 'l2': 6.379888690521487e-05, 'l2_1': 0.00013256157391301627, 'l2_2': 0.0009457487322332761, 'lr': 0.021003723896153827, 'lr_1': 0.014111778261744532}\n",
      "------------------------------------------------\n",
      "Model 13 parameters\n",
      "{'Dropout': [0.47945603666694214], 'Dropout_1': [0.6410658485741121], 'Dropout_2': [0.431428962525653], 'LSTM': [2], 'LSTM_1': [1], 'LSTM_2': [2], 'choiceval': [1], 'conditional': [1], 'l2': [0.00018573736431464218], 'l2_1': [0.0009992918522039433], 'l2_2': [0.000376241262719619], 'lr': [0.02028522715636994], 'lr_1': [0.02075108210315991]}\n",
      "\n",
      "{'Dropout': 0.47945603666694214, 'Dropout_1': 0.6410658485741121, 'Dropout_2': 0.431428962525653, 'LSTM': 38, 'LSTM_1': 32, 'LSTM_2': 36, 'choiceval': 'rmsprop', 'conditional': 'two', 'l2': 0.00018573736431464218, 'l2_1': 0.0009992918522039433, 'l2_2': 0.000376241262719619, 'lr': 0.02028522715636994, 'lr_1': 0.02075108210315991}\n",
      "------------------------------------------------\n",
      "Model 14 parameters\n",
      "{'Dropout': [0.3802031741395868], 'Dropout_1': [0.6903389204823146], 'Dropout_2': [0.3654341425327902], 'LSTM': [2], 'LSTM_1': [2], 'LSTM_2': [1], 'choiceval': [0], 'conditional': [0], 'l2': [0.00015208023802140732], 'l2_1': [0.000643128044948208], 'l2_2': [0.0007102309264917989], 'lr': [0.016347608866364167], 'lr_1': [0.024543333891182614]}\n",
      "\n",
      "{'Dropout': 0.3802031741395868, 'Dropout_1': 0.6903389204823146, 'Dropout_2': 0.3654341425327902, 'LSTM': 38, 'LSTM_1': 36, 'LSTM_2': 32, 'choiceval': 'adam', 'conditional': 'one', 'l2': 0.00015208023802140732, 'l2_1': 0.000643128044948208, 'l2_2': 0.0007102309264917989, 'lr': 0.016347608866364167, 'lr_1': 0.024543333891182614}\n",
      "------------------------------------------------\n",
      "Model 15 parameters\n",
      "{'Dropout': [0.578227610775208], 'Dropout_1': [0.6959943282933752], 'Dropout_2': [0.4519332465495095], 'LSTM': [1], 'LSTM_1': [1], 'LSTM_2': [1], 'choiceval': [0], 'conditional': [1], 'l2': [9.909767403125834e-05], 'l2_1': [0.0004671776323322324], 'l2_2': [0.0008869747685138522], 'lr': [0.010099240007717829], 'lr_1': [0.024293576282946767]}\n",
      "\n",
      "{'Dropout': 0.578227610775208, 'Dropout_1': 0.6959943282933752, 'Dropout_2': 0.4519332465495095, 'LSTM': 32, 'LSTM_1': 32, 'LSTM_2': 32, 'choiceval': 'adam', 'conditional': 'two', 'l2': 9.909767403125834e-05, 'l2_1': 0.0004671776323322324, 'l2_2': 0.0008869747685138522, 'lr': 0.010099240007717829, 'lr_1': 0.024293576282946767}\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "total_trials = dict()\n",
    "for t, trial in enumerate(trials):\n",
    "        vals = trial.get('misc').get('vals')\n",
    "        print('Model',t+1,'parameters')\n",
    "        print(vals)\n",
    "        print()\n",
    "        z = eval_hyperopt_space(space, vals)\n",
    "        total_trials['M'+str(t+1)] = z\n",
    "        print(z)\n",
    "        print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dropout': 0.3802031741395868,\n",
       " 'Dropout_1': 0.6903389204823146,\n",
       " 'Dropout_2': 0.3654341425327902,\n",
       " 'LSTM': 2,\n",
       " 'LSTM_1': 2,\n",
       " 'LSTM_2': 1,\n",
       " 'choiceval': 0,\n",
       " 'conditional': 0,\n",
       " 'l2': 0.00015208023802140732,\n",
       " 'l2_1': 0.000643128044948208,\n",
       " 'l2_2': 0.0007102309264917989,\n",
       " 'lr': 0.016347608866364167,\n",
       " 'lr_1': 0.024543333891182614}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dropout': 0.3802031741395868,\n",
       " 'Dropout_1': 0.6903389204823146,\n",
       " 'Dropout_2': 0.3654341425327902,\n",
       " 'LSTM': 38,\n",
       " 'LSTM_1': 36,\n",
       " 'LSTM_2': 32,\n",
       " 'choiceval': 'adam',\n",
       " 'conditional': 'one',\n",
       " 'l2': 0.00015208023802140732,\n",
       " 'l2_1': 0.000643128044948208,\n",
       " 'l2_2': 0.0007102309264917989,\n",
       " 'lr': 0.016347608866364167,\n",
       " 'lr_1': 0.024543333891182614}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEST MODEL PARAMS\n",
    "total_trials['M14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.recurrent.LSTM at 0x146c379d2ac8>,\n",
       " <keras.layers.core.Dropout at 0x146c379d2cc0>,\n",
       " <keras.layers.core.Dense at 0x146c379d2a90>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#layes of best model\n",
    "best_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_accuracy 0.94560663764961915\n",
      "validation accuracy 0.9199185612487275\n"
     ]
    }
   ],
   "source": [
    "_,val_acc = best_model.evaluate(X_val, Y_val, verbose=0)\n",
    "_,train_acc = best_model.evaluate(X_train, Y_train, verbose=0)\n",
    "print('Train_accuracy',val_acc)\n",
    "print('validation accuracy',val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix_rnn(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    #return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "    return metrics.confusion_matrix(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[537   0   0   0   0   0]\n",
      " [  1 412  75   0   0   3]\n",
      " [  0  88 444   0   0   0]\n",
      " [  0   0   0 464  10  22]\n",
      " [  0   0   0  15 390  15]\n",
      " [  0   4   0   2   1 464]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix_rnn(Y_val, best_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAIxCAYAAABaRiKwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzs3Xl8FfX1//HXgQhoEQgqkgVlEZFE\nkN26grsSUBFwV9Aq/rQqKloXtFqtW1nc6tfWtopatAKKQkABF9yVzQoCLqBBkgAKKLjUIOH8/riT\neLMnmrvk3vfTx314Zz6fmTmf3Ks5OfOZGXN3RERERBqyRrEOQEREROTXUkIjIiIiDZ4SGhEREWnw\nlNCIiIhIg6eERkRERBo8JTQiIiLS4CmhERERkagys0fM7Esz+7CKdjOz+81slZktNbNeNe1TCY2I\niIhE2yTg+GraTwA6B69RwEM17VAJjYiIiESVu78ObK6my0nA4x7yLtDKzNKq26cSGhEREYk3GcDa\nsOX8YF2VUiIajoiIiMQd272Zs21H5A7w7U/LgR/D1jzs7g/XYQ9Wybpqn9WkhEZERCTZbNsBB7aJ\n3P5fKvjR3fv8ij3kA+3CljOBwuo20CknERGRZGQWudevNwM4N7ja6bfAFndfV90GqtCIiIhIVJnZ\nU8AAYHczywduBnYCcPe/AbOBgcAq4AfgvJr2qYRGREQk2RgxPUfj7mfU0O7A7+uyT51yEhERkQZP\nFRoREZFkVD9zXeKGEhoREZFklFj5jE45iYiISMOnCo2IiEjSqbfLq+OGKjQiIiLS4KlCIyIikmxi\nfNl2JCTYcERERCQZqUIjIiKSjDSHRkRERCS+qEIjIiKSjBKrQKOERkREJOkY0CixMhqdchIREZEG\nTxUaERGRZJRYBRpVaERERKThU4VGREQkGemybREREZH4ogqNiIhIMkqsAo0qNCIiItLwqUIjIiKS\nbBLwPjRKaERERJJRYuUzOuUkIiIiDZ8qNCIiIknHdNm2iIiISLxRhUZERCTZJOCkYFVoREREpMFT\nhUZERCQZJVaBRhUaERERafhUoREREUlGuspJREREJL6oQiMiIpKMEqtAo4RGREQk6eiybREREZH4\nowqNiIhIMkqsAo0qNCIiItLwqUIjIiKSjHTZtoiIiEh8UYVGREQkGSVYSSPBhiMiIiLJSAmNiPwq\nZnaLmf07eL+XmX1nZo3r+Rh5ZnZ0fe6zFse82Mw2BOPZ7Vfs5zsz61ifscWKmS03swGxjkPqgVlk\nXzGghEYkzgW/zDeY2W/C1l1gZvNjGFal3P0Ld2/u7sWxjuXXMLOdgInAscF4Nv3SfQXbf1Z/0dU/\nM5tkZn+uqZ+7Z7v7/CiEJNFgEXzFgBIakYYhBRj9a3diIfrvvmZ7As2A5bEOJB6YmeZbStzT/9hE\nGoZxwNVm1qqyRjM72MwWmtmW4N8Hh7XNN7Pbzewt4AegY7Duz2b2dnBKZKaZ7WZmk81sa7CP9mH7\nuM/M1gZti83ssCriaG9mbmYpZnZQsO+S149mlhf0a2Rm15nZajPbZGZTzKx12H7OMbM1QdvY6n4w\nZrazmU0I+m8xszfNbOeg7cTgNMk3wZi7hm2XZ2ZXm9nSYLunzayZme0LfBx0+8bMXgkfV7mf6wXB\n+33M7LVgPxvN7Omwfm5m+wTvW5rZ42b2VRDvjSUJppmNDGIfb2Zfm9nnZnZCNePOM7Nrgvi/N7N/\nmdmeZvaCmX1rZi+ZWWpY/6lmtj6I8XUzyw7WjwLOAv5Q8l0I2/+1ZrYU+D74TEtP/ZnZbDObELb/\np83skeo+K4kzOuUkIjGwCJgPXF2+IUgEZgH3A7sROlUyy8rO+zgHGAXsCqwJ1p0erM8AOgHvAI8C\nrYGVwM1h2y8EegRtTwJTzaxZdQG7+zvB6ZbmQCrwLvBU0Hw5cDLQH0gHvgYeDMaTBTwUxJYejCmz\nmkONB3oDBwfx/QHYESQmTwFXAHsAs4GZZtYkbNtTgeOBDkB3YKS7fwJkB+2t3P3I6sYZuA2YG4wz\nE3igin4PAC2BjsHYzwXOC2s/kFAytTvwF+BfZtX+dhgKHAPsCwwGXgBuCLZvROjnXOIFoDPQBlgC\nTAZw94eD938JPq/BYducAeQQ+jlsL3fs84FzzOxIMzsL6Es9VBFFfiklNCINxx+By8xsj3Lrc4BP\n3f0Jd9/u7k8BHxH6BVdikrsvD9p/CtY96u6r3X0LoV92q939peAX11SgZ8nG7v5vd98UbD8BaAp0\nqUPs9wPfAyXVlouAse6e7+5FwC3AsKACMgzIdffXg7abgB2V7TSobpwPjHb3Ancvdve3g+1OA2a5\n+7xgzOOBnQklPqVxuXuhu28GZhJK2n6Jn4C9gXR3/9Hd36wk1sZBTNe7+7fungdMIJS4lVjj7v8I\n5iA9BqQROv1VlQfcfYO7FwBvAO+5+/vB+KdT9jN8JDhuyc/7ADNrWcO47nf3te7+v/IN7r4e+H9B\nnPcB57r7tzXsT+JJowi+YkAJjUgD4e4fArnAdeWa0vm56lJiDaHKS4m1lexyQ9j7/1Wy3LxkwczG\nmNnK4HTFN4SqDLvXJm4zuwgYAJzp7iWJyd7A9OBU0DeEKkLFhH55p4fH6+7fA1VNyt2d0FyX1ZW0\nlfm5BMdeS9mfy/qw9z8QNuY6+gOhqZALglNc51cRaxPKflblP6fSeNz9h+BtdTHV6jM0s8Zmdldw\nim8rkBcWU3Uq+96EywUaAx9XlsSJRJMSGpGG5WbgQsr+EiwklCCE2wsoCFv2X3rAYL7MtYROz6S6\neytgC7W4liHY9jbgpKASVGItcIK7twp7NQsqDeuAdmH72IXQaafKbAR+JHTKrLwyP5fg1E07yv5c\nauv74N+7hK1rW/LG3de7+4Xunk6o+vR/JfNmysVaUskpUf5zipQzgZOAowklo+2D9SWfYVXfj5q+\nN7cTSkbTzOyMXxmjRJOhOTQiEjvuvgp4mrJzI2YD+5rZmcHEzdOALEJ/PdeHXYHtwFdAipn9EWhR\n00Zm1i6I9dxgXkq4vwG3m9neQd89zOykoG0aMMjMDg3mu9xKFf+vCqoujwATzSw9qEQcZGZNgSlA\njpkdZaHLsMcARcDbdRp96DhfEUo8zg6OcT5hSZSZDTezknk+XxNKBIrL7aM4iOl2M9s1GPtVwL/r\nGs8vsCuhsW8ilJTdUa59A6F5PbVmZocTmv9zbvB6wMwyqt9KJHKU0Ig0PLcCpfekCe6RMojQL+xN\nhE5/DHL3jfV0vDmE5th8QugUyY/UfCoC4ChCVYxp9vOVTiWXQd8HzADmmtm3hCYMHxiMZznwe0KT\nj9cRShDyqznO1cAyQhOXNwN3A43c/WPgbEITcTcSmlM02N231XLc5V0IXEPoZ5xN2cSoL/CemX0X\njGu0u39eyT4uI1Tt+Qx4MxhjNK4MepzQZ1cArCD08w73LyArOAX4XE07M7MWwT4vDeYuvRns49Ea\nJjFLPEmw+9CY+y+uRIuIiEgDZG12dk6t7ExtPXlw+WJ37xO5A1SkCo2IiIg0eLr7o4iISDJKsLOD\nqtCIiIhIg6cKjYiISLKJ4eTdSFGFRkRERBo8VWikXlmTRk6zxP5a9dp3/1iHICJJZE3eF2zcuLGe\n6ylGJK+wj8X104n9m0eir1kKHNgm1lFE1Fsv6g7vIhI9hxx4aKxDaBCU0IiIiCQhVWhERESkwUuw\nq7Y1KVhEREQaPlVoREREkowBjSJYoimuuUu9U4VGREREGjxVaERERJKNRXZScCyoQiMiIiINnio0\nIiIiSUgVGhEREZE4owqNiIhI0onsow9iQQmNiIhIEkqwfEannERERKThU4VGREQkyRiaFCwiIiIS\nd1ShERERSTa6sZ6IiIhI/FGFRkREJAkZqtCIiIiIxBVVaERERJKQ5tCIRMm/xoxnw5T/suzhl6rs\nc98lt/LppDf54O/z6LnP/qXrzz1mGJ9MeoNPJr3BuccMi0a4v8jcF+fSPasH2V26Me7u8RXai4qK\nOPuMc8nu0o3DDurPmrw1pW3j7hpHdpdudM/qwbw586IZdp1ojBqjxhifzCL3igUlNBK3Js2dyvE3\nnF1l+wn9jqRzRgc6jzyUUfdey0OX3wlA6q6tuPmcKznwssH0u3QQN59zJa2at4xW2LVWXFzMFZdf\nxfO503l/2WKmPj2VlStWlukz6ZHHSE1txfKPl3HZFZcy9vqbAFi5YiVTp0xjydJFzJj1HKMvu5Li\n4uJYDKNaGmOIxqgxSuQpoZG49cay99j87TdVtp900LE8/tI0AN5buYRWzVvQtnUbjuvTn3mL3+Dr\nb7/hm++2MG/xGxzfd0CUoq69hQsW0alTRzp07ECTJk0YfuowcmfklumTOyOXs845C4BThg5h/ivz\ncXdyZ+Qy/NRhNG3alPYd2tOpU0cWLlgUg1FUT2MM0Rg1xnhjGI0scq9YUEIjDVbG7m1Z+2Vh6XL+\nxnVk7N6WjN3asvarcut3axuLEKtVWFhIZrvM0uWMzAwKCtdV2SclJYUWLVuwadMmCgrXVdi2sLCQ\neKMxVuyjMWqMEhlKaBoIM/uumrYPzOypsOVRZvZ02HILM1ttZh3MbJKZDQvWzzezRWH9+pjZ/LDl\nfkGfT81siZnNMrNu9T64X6iyCW3uXvl6PBoh1Yl7xZjKx15Jl1CfWmwbDzTGkj4Vt9MY40syjLE8\nM4vYKxaU0DRwZtaV0Od4uJn9Jlj9DyDTzI4Olm8FHnH3zyvZRRszO6GS/e4JTAFucPfO7t4LuBPo\nVO+D+IXyv1pHuzbppcuZu6dRuGkD+RvX0W6PiuvjTUZGBvlr80uXC/ILSE9rW65Pemmf7du3s3XL\nVlq3bl1mfcm2aWlp0Qm8DjTGkj4aY/i2GqNEghKahu9M4AlgLnAigIf+1LgYuNfM+gBHAeOq2H4c\ncGMl6y8FHnP3t0tWuPub7v5cPcb+q8x4Zy7nHh26gunArr3Y8v23rN/8JXMWvcaxvQ+nVfOWtGre\nkmN7H86cRa/FONqK+vTtzapVq8n7PI9t27Yxdco0cgbnlOmTMziHyU9MBuDZZ6bT/4j+mBk5g3OY\nOmUaRUVF5H2ex6pVq+nbr08shlEtjTFEY9QY444lXoVG96Fp+E4DjgG6EEpCngJw96VmNgd4GTjZ\n3bdVsf07wBAzOwL4Nmx9NvBYbQIws1HAKACaNf4FQ6jckzf8lQHdD2L3lq1Z++RCbn58AjulhL6y\nf8/9N7MXvMLAA49k1WNv8kPRj5w3/ioAvv72G26bfB8L/zoLgFsn38vX1UwujpWUlBTuuW8Cgwee\nRHFxMSNGnktWdha33nwbvfr0YtDgHEaeP4LzR1xAdpdupKam8sSToY8kKzuLocOG0rNbb1JSUrj3\n/ok0blx/P/v6ojFqjBqjRItVdt5Q4o+Zfefuzcut6wvc6+6HmFljYA3Qzd2/Dto7ArnunhW2zaRg\n3bRgvszVQAtgLHAtMN7dB5jZs4QqNM8H270X9Jvr7qOrjLNFE+fANvU27nj0vxc/iXUIIpJEDjnw\nUBYvWlKvZY+U9Obe6oLu9bnLMjbd9s5id6+yTGVmxwP3AY2Bf7r7XeXa9yL0R3WroM917j67umPq\nlFPDdgawn5nlAasJJRxDw9p3BK9qufsrQDPgt2GrlwO9wvocCNwExN8NXUREpMEI/gB/EDgByALO\nMLOsct1uBKa4e0/gdOD/atqvEpoGyswaAcOB7u7e3t3bAycRSnJ+iduBP4QtPwiMNLODw9bt8gv3\nLSIiccSI6RyafsAqd/8smA7xH0K/v8I5oT/SIfSHdI3XwWsOTcOxi5nlhy1PBArcvSBs3etAlpml\nuXvZGyjUwN1nm9lXYcvrzew04G4zywC+BDYSumJKREQauAhP3t3dwm4LAjzs7g8H7zOAtWFt+cCB\n5ba/BZhrZpcBvwGOpgZKaBoId6+smjaxXJ9iIC1sOQ/Yv1yfkWHvB5Rr611u+V2g/y8MWUREktfG\naubQVJZJlZ/QewYwyd0nmNlBwBNmtr+7VzmNQgmNiIhI0ond5dWEKjLtwpYzqXhK6XfA8QDu/o6Z\nNQN2J3S2oFKaQyMiIiLRtBDobKG71zchNOl3Rrk+XxC6h1rJDWSbAV9RDVVoREREko3F7vEM7r7d\nzC4F5hC6JPsRd19uZrcCi9x9BjAG+IeZXUnodNRIr+E+M0poREREJKqCe8rMLrfuj2HvVwCH1GWf\nSmhERESSUAN4fmadaA6NiIiINHiq0IiIiCSZkhvrJRIlNCIiIkko0RIanXISERGRBk8VGhERkSTU\nSBUaERERkfiiCo2IiEiyMV22LSIiIhJ3VKERERFJMhbbh1NGhCo0IiIi0uCpQiMiIpKEjMSq0Cih\nERERSUI65SQiIiISZ1ShERERSUKq0IiIiIjEGVVoREREklCCFWhUoREREZGGTxUaqVe99t2ft158\nM9ZhRNRu1x8e6xAi7sObJsc6hIhL26VdrEOQeuLusQ4hoiIxPDPNoRERERGJO6rQiIiIJJ3Ee/SB\nEhoREZEklGgJjU45iYiISIOnCo2IiEgSSrACjSo0IiIi0vCpQiMiIpKENIdGREREJM6oQiMiIpJk\ndGM9ERERkTikCo2IiEgSSrQKjRIaERGRJJRg+YxOOYmIiEjDpwqNiIhI0km8ZzmpQiMiIiINnio0\nIiIiSUgVGhEREZE4owqNiIhIktGN9URERETikCo0IiIiSSjBCjRKaERERJKRTjmJRMncF+fSPasH\n2V26Me7u8RXai4qKOPuMc8nu0o3DDurPmrw1pW3j7hpHdpdudM/qwbw586IZdp0cs+9BvH/NMyz9\nw3TGDBhRoT2z1Z7MvuhvvD16Mu9d+RTH7XdIhfYNt73O6MPPjlbIdfbavDc4qtfxHHHAsTw08eEK\n7QveWsjgw06hc2o2s597sUzbPq2yyDnkZHIOOZkLT7s4WiHXWTJ8V5NijHPmcUB2T/bfrzvj/zKh\nQntRURHnnHku++/XncMPHlA6xk2bNnH80SewR6s9ufLyq6IdtgSU0EhcKi4u5orLr+L53Om8v2wx\nU5+eysoVK8v0mfTIY6SmtmL5x8u47IpLGXv9TQCsXLGSqVOmsWTpImbMeo7Rl11JcXFxLIZRrUbW\niIlDrmXIvy6n94ThDO9xHPu16VCmz7VH/Y5nP5jHwfedxYjJN3DPydeWab978Bjmfvx2NMOuk+Li\nYm4ecyuPPvMP5izMZea0WXz60aoyfdIz0/jLQ3dy4vBBFbZvtnMzZr31HLPeeo5/PP1QtMKuk2T4\nribLGK+8/Cqem/ksS5YuYup/Kh9jq1at+PCjpVw2+vfceENojM2aNeOPt9zEHXffHovQf7nQzODI\nvGJACY3EpYULFtGpU0c6dOxAkyZNGH7qMHJn5Jbpkzsjl7POOQuAU4YOYf4r83F3cmfkMvzUYTRt\n2pT2HdrTqVNHFi5YFINRVK9Pu2w+27iWvM0F/FS8nWkfzGVQdv8yfdyhRbPmQOjf67Z+Vdo2KLs/\neZvzWbnhs6jGXRcfLFrK3h33Yq8O7WjSpAmDhg5k3qyXy/TJ3DuTrvt3oVGjhln+TobvajKMcVG5\nMQ47bRi5M2eV6TNr5izODsY4JGyMv/nNbzj40INp1qxZLEKXgBIaiUuFhYVktsssXc7IzKCgcF2V\nfVJSUmjRsgWbNm2ioHBdhW0LCwujE3gdpLdsQ/6WDaXLBVu+JK1FmzJ97pj3d07veQKf3DCLZ8+/\njzHPjwNgl52acdWAEdwx7x9Rjbmu1q/bQFpmWulyWnpbNhRuqGaLsop+LOLE/kM55cjTmJv7UiRC\n/NWS4buaLGPMyAyLMyODwoLCin3KjLElmzZtimqc9Sf06INIvWJBk4LjmJmNBc4EioEdwEXA3cDV\nwINAU6A1sDNQEGyWBqyrZP3JwHygj7tvNDMHJrr7mOBYVwPN3f2WYPls4A9AY2A7sBC42t2/idyI\nf+buFdaV/4+kki6hPrXYNh5UFpFTNvbhPY7n34tncv/rk+m3Vzf+efqt9J14GjceexF/feNJvt/2\nv+gE+0tV9RnV0psrXmHPtD354vO1nDV4BF2y9mXvjnvVY4C/XjJ8VzXG2veR2FFCE6fM7CBgENDL\n3YvMbHegSUm7ux8Y9BtJKEm5tNz2FdaX+w+vCDjFzO50943ltj0euBI4wd0LzKwxMALYE4hKQpOR\nkUH+2vzS5YL8AtLT2pbrk07+2nwyMzPYvn07W7dspXXr1qXrw7dNS0sj3hRs+ZLMlnuWLme0bMP6\nsFNKAOf2PZGT/3U5AAu+WEazlCbsvksr+uy1Pyd3O4o/D7ycljvvyg7fwY/bt/H3t6dEdQw1aZu+\nJ+vyf/5Lfl3hetqktalmi7L2TAv9fPbq0I7fHtqP5UtXxF1Ckwzf1WQZY0F+WJwFBaSlp1XsU2aM\nW2jdunW0Q60fsZvqEjE65RS/0oCN7l4E4O4b3b0+67TbgYcJJS7ljSVUjSkIjl3s7o+4+8f1ePxq\n9enbm1WrVpP3eR7btm1j6pRp5AzOKdMnZ3AOk5+YDMCzz0yn/xH9MTNyBucwdco0ioqKyPs8j1Wr\nVtO3X59ohV5ri/NX0Gn3duydms5OjVMYdsCxzFrxepk++d+s54h9+gLQpU17mu3UlK++/5pjH7qQ\nrLtOJOuuE3nwzacY/8qjcZfMAHTv3Y28z9awNi+fbdu2kfvMbI4eeGSttt3y9RaKirYBsHnT1yx6\n930677dPJMP9RZLhu5oMY+xdbozTnp5GzqCBZfoMHDSQfwdjnB42RokPqtDEr7nAH83sE+Al4Gl3\nf62ej/EgsNTM/lJufTawpLY7MbNRwCiAdnu1q5fAUlJSuOe+CQweeBLFxcWMGHkuWdlZ3HrzbfTq\n04tBg3MYef4Izh9xAdldupGamsoTTz4GQFZ2FkOHDaVnt96kpKRw7/0Tady4cb3EVZ+KdxQz5vlx\nPH/BAzRu1JjHF85g5YbPuPHYi1iSv5LZK17n+tx7+euwG7n0sDNxnIueviXWYddJSkoKt4y7iRFD\nfseO4h0MP2co+3btzD1/vp9uvfbn6IFH8sHiZVx81qVs+WYrL7/wKvfd8VfmLMhl1SerGTv6Zho1\nasSOHTv4f1ddGJcJTTJ8V5NljBPvm8CJOSdTXFzMuSPPCY3xltvo1fvnMf5u5AXsv193UlNTeXzy\npNLt99sni2+3fsu2bduYOSOXmbOfp2tW15iNpyZG4p0us8rOCUp8CE71HAYcQWj+zHXASELVk0VB\nn5HU/pRTHj/PofnO3Zub2a3AT8D/CObQmNlmoIO7bzGzbsATwK7ADe7+dHUx9+7Ty996781fP/g4\nttv1h8c6hIj78KbJsQ4h4tJ2qZ/kW2Iv0X+PHXLgYSxZvKRes4/ftE/1/W48oj53WcaSC6cvdveo\nluJUoYlj7l5MaCLvfDNbRmgeS327l1A15tGwdcuBXsCr7r4M6GFmfyU0yVhERBJAolVoNIcmTplZ\nFzPrHLaqB7Cmqv6/lLtvBqYAvwtbfScw3swyw9YpmRERSSC6bFuipTnwgJm1IjSBdxWheSrTInCs\nCUDpqSl3n21mewAvBKe9vgE+BOZE4NgiIiK/mhKaOOXui4GDK2kaUK7fJGBSJdtXWO/u7cPeNw97\nvwHYpVzfx4DH6ha1iIg0FAl2xkmnnERERKThU4VGREQk2cRwrkukqEIjIiIiDZ4qNCIiIkkmEW+s\npwqNiIiINHiq0IiIiCShRKvQKKERERFJQomW0OiUk4iIiDR4qtCIiIgkG9ON9URERETijio0IiIi\nSUhzaERERETijCo0IiIiScbQow9ERERE4o4qNCIiIkko0So0SmhERESSUILlMzrlJCIiIg2fKjQi\nIiLJxhLvlJMqNCIiItLgqUIjIiKSjFShEREREYkvqtCIiIgkoUSbQ6OERqSOPrjx8ViHEHHd/nxW\nrEOIuI13vB7rEKSeJNov5vISfHj1RgmNiIhIkjGgUYIlSkpoREREko6e5SQiIiISd1ShERERSTYG\njVShEREREYkvqtCIiIgkGSPxrg5ThUZEREQaPCU0IiIiSahRBF81MbPjzexjM1tlZtdV0edUM1th\nZsvN7Mma9qlTTiIiIhI1ZtYYeBA4BsgHFprZDHdfEdanM3A9cIi7f21mbWrarxIaERGRJBTDq5z6\nAavc/TMAM/sPcBKwIqzPhcCD7v41gLt/WdNOldCIiIgkmRhPCs4A1oYt5wMHluuzL4CZvQU0Bm5x\n9xer26kSGhEREalvu5vZorDlh9394eB9ZZmUl1tOAToDA4BM4A0z29/dv6nqgEpoREREko5F+pTT\nRnfvU0VbPtAubDkTKKykz7vu/hPwuZl9TCjBWVjVAXWVk4iIiETTQqCzmXUwsybA6cCMcn2eA44A\nMLPdCZ2C+qy6napCIyIikmwsdnNo3H27mV0KzCE0P+YRd19uZrcCi9x9RtB2rJmtAIqBa9x9U3X7\nVUIjIiIiUeXus4HZ5db9Mey9A1cFr1pRQiMiIpJkjMSbc5Jo4xEREZEkpAqNiIhIEorhjfUiQgmN\niIhIEtLTtkVERETijBIaiVtzX5xL96weZHfpxri7x1doLyoq4uwzziW7SzcOO6g/a/LWlLaNu2sc\n2V260T2rB/PmzItm2HXy+ktvcGzvHI7qcTx/n/iPCu0L3lrESYcNY7/W3XnhuTml6999/T0GH3pK\n6Su7TU/m5b4czdBr7eh9D2LJ1c/wwTXTuWrAiArtma32ZPaov/HW5ZN594qnOLbLIQD0zszm7dGT\neXv0ZN4Z/SSDswdEOfLaS4bvqsaYGGMsYYROOUXqFQtKaCQuFRcXc8XlV/F87nTeX7aYqU9PZeWK\nlWX6THrkMVJTW7H842VcdsWljL3+JgBWrljJ1CnTWLJ0ETNmPcfoy66kuLg4FsOoVnFxMbeMuZ1/\nTvsbLyyYQe4zs/n0o1Vl+qRnpnH3Q7czeHhOmfW/PfxAZr75LDPffJYnZjzCzjs349AjD45m+LXS\nyBox8eRrOeWRy+kzcTjDDziO/dp0KNPn2iN/x7NL53HI/Wcx8skbuOfkawFYsWEVhz1wLgffdxYn\nP3IZ959yA40bNY7FMKqVLN/gn14KAAAgAElEQVRVjbHhjzHRKaGRuLRwwSI6depIh44daNKkCcNP\nHUbujNwyfXJn5HLWOWcBcMrQIcx/ZT7uTu6MXIafOoymTZvSvkN7OnXqyMIFiyo5SmwtXbyMvTu2\nY68O7WjSpAk5pwzk5VmvlumTuXcG++3fBWtU9V88Lz4/l8OPOYydd9k50iHXWZ922Xy2aS15mwv4\nqXg70z6YS05W/zJ9HNi1aXMAWjRrzrpvvwLgfz8VUbwj9EuhWUpTQreliD/J8F3VGEMa+hjLswi+\nYkEJjcSlwsJCMttlli5nZGZQULiuyj4pKSm0aNmCTZs2UVC4rsK2hYXlHxMSe+sLN5CWkVa63DZj\nTzas21Dn/cx65gUGDRtYn6HVm/SWbcj/5ucxFWz5kvSWbcr0uX3e3zm95wl8fMMsnjnvPq5+flxp\nW5922Sy86mneu/I/jJ5+Z2mCE0+S4buqMVbs0xDHmOiU0ESJmY01s+VmttTM/mtmrwb/XmVmW4L3\n/zWzg4P+e5jZT2Z2Ubn95JnZM2HLw8xsUvB+pJl9ZWbvm9mnZjanZH9B+yQzGxa8nx/+JFQz62Nm\n88OW+wV9PjWzJWY2y8y6RernU15lf42Xn5Ff2R/sZlZpQ1zO5q8q/jr4cv1XfLziUw476pB6Cqp+\nVfpI3XKfz/Aex/PvxTPpckcOQx8dzT9Pu7X057Bo7XL6TjyN/n89lzFHnEfTlCZRiLpukuG7qjGW\n9Km4XUMaY1mRmz+jOTQJzMwOAgYBvdy9O3A0cJa79wAuAN5w9x7B6+1gs+HAu8AZleyyj5llV3G4\np929p7t3Bu4CnjWzrlX0bWNmJ1QS757AFOAGd+/s7r2AO4FOtRvxr5eRkUH+2vzS5YL8AtLT2pbr\nk17aZ/v27WzdspXWrVuXWV+ybVpaGvGmbcaerCv4+S/A9QUbaNO2TTVbVDR7+oscO+godtppp/oO\nr14UbPmSzFZ7li5ntGzDuq1flekzou+JPLv0JQAWfLGMpilN2H2XVmX6fPxlHj9s+x9Ze0btK1hr\nyfBd1RhL+jTsMSY6JTTRkUboUepFAO6+0d1rqkeeAYwBMs0so1zbeOCGmg7q7q8CDwOjqugyDrix\nkvWXAo+FJVe4+5vu/lxNx6wvffr2ZtWq1eR9nse2bduYOmUaOYPLTozNGZzD5CcmA/DsM9Ppf0R/\nzIycwTlMnTKNoqIi8j7PY9Wq1fTtV9VT7GOnW6/9yVv9BWvz8tm2bRuznp3NUQOPqNM+cqfNjtvT\nTQCL81fQabd27J2azk6NUxh2wLHMXvl6mT5rv1nPgH36AtClTXua7dSUr77/mr1T00snAbdr1ZbO\ne+zNF1/HXxk/Gb6rGmNIQx9jOLPEu8pJN9aLjrnAH83sE+AlQlWU16rqbGbtgLbuvsDMpgCnARPD\nukwBLjGzfWpx7CXARVW0vQMMMbMjgG/D1mcDj9Vi3yXxjiJImtrt1a62m1UrJSWFe+6bwOCBJ1Fc\nXMyIkeeSlZ3FrTffRq8+vRg0OIeR54/g/BEXkN2lG6mpqTzxZCjkrOwshg4bSs9uvUlJSeHe+yfS\nuHH8XR2TkpLCzePHcv4poygu3sGws4fQues+3Hv7A3Trmc1RA49k6eJlXHL2aLZ+s5VXX5jP/Xc+\nyAvvzQAgf00B6wvW0+/QvjEeSdWKdxQz5vlxPPe7B2jcqDFPLJzByg2fceMxF7EkfyWzV77ODbn3\n8sDQG7n00DNxnIum3ALAQe17MOaIEfxUvJ0d7lw5/S42/bAltgOqRLJ8VzXGhj/GRGfxeuVAojGz\nxsBhwBGEEozr3H2SmQ0Arnb3QWF9rwFauftYM+sO/Mvd+wZteUAf4ETgEOAFYJC7jzSzkUAfd780\nbF9DgFHufkIw1ybX3acF82WuBloAY4FrgfHuPsDMniVUoXk+2Md7Qb+57j66unH27tPL33rvzV/z\no4p7+d/nxTqEiOtx+7mxDiHiNt7xes2dROLAIQceyuJFS+q17LHbvm38hAeG1+cuy5h8/P8tdveo\nlql0yilK3L3Y3ee7+82ETukMrab7GcDIIHmZARxgZp3L9XkCOBzYq4ZD9wRWVtXo7q8AzYDfhq1e\nDvQK63MgcBPQsoZjiYhIA5Fop5yU0ESBmXUpl5D0ANZU1Rf4jbtnuHt7d29PaELu6eH93P0n4B7g\nimqO25/QqaCKt6At63bgD2HLDxJKqMLv1LZLDfsQERGJGc2hiY7mwANm1grYDqyi6om6ZwDTy617\nBvgPcFu59f+i4qTe08zsUEIJyOfAUHevskID4O6zzeyrsOX1ZnYacHcwIflLYCNwa3X7ERGRhiGW\nN8CLlCoTGjNrUd2G7r61/sNJTO6+GKj0vvTuPh+YH7Z8SyV9lgJZwfv2YeuLgPSw5UnApGriGBn2\nfkC5tt7llt8Fyt7SVUREJE5VV6FZTujWX+FJXMmyU/PcDREREYlTsZrrEilVJjTuXj/X34qIiIhE\nWK3m0JjZ6UBHd7/DzDKBPYPTKCIiItLgxO5qpEip8SonM/sroXunnBOs+gH4WySDEhEREamL2lRo\nDnb3Xmb2PoC7bzaz+HtCnIiIiNSKWUN4gGbd1Cah+cnMGhE8G9jMdgN2RDQqERERiaikO+VE6CZr\nzwB7mNmfgDeBuyMalYiIiEgd1FihcffHzWwxcHSwari7fxjZsERERCSSEqs+U/s7BTcGfiJ02kmP\nSxAREZG4UpurnMYCTxG6I20m8KSZXR/pwERERCQyjMR7OGVtKjRnA73d/QcAM7sdWEzogYkiIiIi\nMVebhGZNuX4pwGeRCUdERESiIdGucqru4ZT3EJoz8wOw3MzmBMvHErrSSURERCQuVFehKbmSaTkw\nK2z9u5ELR0RERCLPkufGeu7+r2gGIiIiItFhJN4lyzXOoTGzTsDtQBbQrGS9u+8bwbhEREREaq02\nCdok4FFCCd0JwBTgPxGMSURERCIpeJZTpF6xUJuEZhd3nwPg7qvd/UZCT98WERERiQu1uWy7yELp\n1moz+39AAdAmsmGJiIhIJCXNZdthrgSaA5cTmkvTEjg/kkGJiIiI1EVtHk75XvD2W+CcyIYjIiIi\nkVby6INEUt2N9aYTupFepdz9lIhEJCIiIlJH1VVo/hq1KEQakMzftI91CBG38Y7XYx1CxO18dvdY\nhxAV3z2+JNYhRNx23x7rECJqh++IyH6T6cZ6L0czEBEREYkWoxGJldAk2o0CRUREJAnV5ionERER\nSTCJdsqp1hUaM2sayUBEREREfqkaExoz62dmy4BPg+UDzOyBiEcmIiIiEWEWumw7Uq9YqE2F5n5g\nELAJwN0/QI8+EBERkThSmzk0jdx9TblzbcURikdERESiwBLsKqfaJDRrzawf4GbWGLgM+CSyYYmI\niIjUXm0SmosJnXbaC9gAvBSsExERkQYq0a5yqs2znL4ETo9CLCIiIhIFRuwm70ZKjQmNmf2DSp7p\n5O6jIhKRiIiISB3V5pTTS2HvmwFDgLWRCUdERESiwRLsYQG1OeX0dPiymT0BzItYRCIiIiJ19Ese\nfdAB2Lu+AxEREZHoScY5NF/z8xyaRsBm4LpIBiUiIiJSF9UmNBa6pusAoCBYtcPdK0wQFhERkYYl\n0S7brnZGUJC8THf34uClZEZERETiTm2mOC8ws14Rj0RERESiwiL8TyxUecrJzFLcfTtwKHChma0G\nvgeMUPFGSY6IiEhDZMk1KXgB0As4OUqxiIiIiPwi1SU0BuDuq6MUi4iIiERJMk0K3sPMrqrqFbUI\nJWnNfXEu3bN6kN2lG+PuHl+hvaioiLPPOJfsLt047KD+rMlbU9o27q5xZHfpRvesHsybE7/3gdQY\nE2OMxx1wOB9NmMun97zMtSdeVKF9r93TeWns43xwdy6v3jSZjNZty7TvunNz8h98kwdG3hytkOts\n3pyX6Jndm+5dezDhLxMrtBcVFXHumSPp3rUHAw45svRzfOWlVzj0wMPp1/MgDj3wcOa/+lq0Q6+1\nl+a8TJ/9+9Gzax/uGXdvhfaioiLOO+t39Ozah6MOPYY1eV+UaV/7RT4ZrffigYl/jVbIEqa6hKYx\n0BzYtYqXSMQUFxdzxeVX8XzudN5ftpipT09l5YqVZfpMeuQxUlNbsfzjZVx2xaWMvf4mAFauWMnU\nKdNYsnQRM2Y9x+jLrqS4uDgWw6iWxhjS0MfYyBrx4Hm3cMLdvyPr6uM54+BBdM3Yp0yf8Wddz+Nv\nTOeAawdx67MPcOfpV5dpv234Fby2ckE0w66T4uJirho9hmdnTmPRBwuY+vQzrFzxUZk+jz36OK1S\nW7F05X/5/eWXcNMNoeRst912Y+r0p1nw/jv8/V9/48LzKiZ88aC4uJirR/+BaTOm8N4HbzPt6Wf5\naGXZMT7x6L9p1aoV769cxCWXX8wtY/9Upv2Ga8Zy9HFHRTPsX8yARhH8JxaqO+o6d7/V3f9U2Stq\nEUpSWrhgEZ06daRDxw40adKE4acOI3dGbpk+uTNyOeucswA4ZegQ5r8yH3cnd0Yuw08dRtOmTWnf\noT2dOnVk4YJFMRhF9TTGkIY+xn77HMCq9Wv4/Mu1/FT8E/95ZxYn9Tm6TJ+szH14+cN3AHh1+buc\n1Pvn9l4dstmz5e7MXfpmVOOui0ULF9Mx7HMcduopzJo5q0yfWTNnc9Y5ZwIwZOjJzH/1NdydA3oe\nQFp6GgBZ2V0p+vFHioqKoj6GmixeuISOnTrQvmN7mjRpwtBThzB75gtl+sye+QJnnHM6ACedciKv\nvfo6JXczyX1+Fu07tGe/rP2iHboEqktoEuvkmjQohYWFZLbLLF3OyMygoHBdlX1SUlJo0bIFmzZt\noqBwXYVtCwsLoxN4HWiMFfs0xDFmpO7J2k0/jyl/03oyUvcs0+eDNSsZ2u84AIb0PZYWuzSndfNW\nmBkTzr6BaybfHdWY66qwoJDMzIzS5YyMDArLf44F60r7pKSk0LJlCzZt2lymz3PPPk/3Ht1p2rRp\n5IOuo3WF68ho9/MY0zPSWVewrmKfzHQg+K62aMHmTZv5/vvvuW/C/Vx74zVRjfnXMcwi94qF6hKa\nhlE3a8DM7B4zuyJseY6Z/TNseULJfCUzu9LMfjSzlmHtA8ys7J+7ofXzzaxP8L69mX1qZseF9zez\nkWa2w8y6h233oZm1D943N7OHzGy1mb1vZovN7ML6/ylUrrJ7OJb/j6Sy2zyaWaUN8Tj5TWMs6VNx\nu4Y0xspicsrGfvXku+jftR9L7pxB/679yN+0nu3F27nkmLOZ/d/55G9eV2Ef8aR2n2P1fVYsX8kf\nx97M/Q9WnJsSDyq9b2wtx3jnrXdzyeUX07x580iFJ7VQ5VVO7r65qjapN28Dw4F7zawRsDvQIqz9\nYKAk4TkDWAgMASbVZudmlgnMAca4+xwzG1CuSz4wFjitks3/CXwGdHb3HWa2B3B+bY5bHzIyMshf\nm1+6XJBfQHpa23J90slfm09mZgbbt29n65attG7dunR9+LZpaWnRCr3WNMaSPg17jPmb19Nut5/j\nytytLYVff1mmz7qvv2ToPb8H4DdNd2Fov+PZ+r/vOKhzDw7bry+XHHMWzZvtQpPGTfjuxx+4/j/j\nojqGmmRkZpCfX1C6XFBQQFr5zzEznfz8AjKCz3HLlq20bp0a6p9fwJnDz+LhR/5Ox04doxp7baVn\npFOw9ucxFhYUkpbetmKf/MLSMW7dupXU1qksXriY56fP4I833MKWb7bQqFEjmjZryqhLovY34C8S\nj38g/BqxmbkjJd4ilLQAZAMfAt+aWaqZNQW6Au+bWSdCE7RvJJTY1EZbYC5wo7vPqKJPLpBtZl3C\nVwbH6xdsuwPA3b9y96jVxfv07c2qVavJ+zyPbdu2MXXKNHIG55TpkzM4h8lPTAbg2Wem0/+I/pgZ\nOYNzmDplGkVFReR9nseqVavp269PtEKvNY0xpKGPceHqpXRuuzft98hkp8Y7cfpBOcxY/HKZPrvt\nmlr6y+P6k/4fj8yfCsDZD45h78sOp8PlA7j633fx+BvT4y6ZAejdpxerwz7HaVOeZeCggWX6DBw0\nkMlPPAnA9Geeo/+AwzEzvvnmG4aedCq3/PlmDjr4t7EIv1Z69enJ6lWfkff5GrZt28YzU6ZzwqAT\nyvQ5YdDxPPXEfwB4/tkZHD7gMMyMF16ZxbJP/suyT/7LxZf9P8b84cq4T2YSUY1P25bIcfdCM9tu\nZnsRSmzeATKAg4AtwFJ332ZmZwBPAW8AXcysjbt/WeWOQx4nlJBMrabPDuAvwA3AiLD12cAHJclM\nTcxsFDAKoN1e7WqzSY1SUlK4574JDB54EsXFxYwYeS5Z2VncevNt9OrTi0GDcxh5/gjOH3EB2V26\nkZqayhNPPgZAVnYWQ4cNpWe33qSkpHDv/RNp3LhxvcRVnzTGxBhj8Y5iLp30J+Zc/yiNGzXmkflT\nWZH/KX8aNppFn3/IzMUvM6Drgdx5+tU4zusrF/L7R2+Jddh1kpKSwoR7x3NyzikU7yjmnBFnk5Xd\nldtuuZ1evXuSM3ggI847hwtGjqJ71x6kpqYy6d+PAPD3//sHn63+jLvvGMfdd4SStednT6dNmz1i\nOaQKUlJSGHfv3QwdNJzi4mLOHnkmXbP24/Y/3UnPXj0YOPgEzjnvbC4672J6du1DautWPPLEP2ve\ncRxrlGBTZU3Pm4wtM5sMzAROACYSSmgOJpTQ7Obu15nZh8AQd//UzCYCq939weAU0tXuPqjcPucD\nXwLtgKPc/YdgfWl/MxsJ9CF0Sms5cHwQxyCgO3Ceuw8JthtL6NRYG3dPr248vfv08rfei9+rNURK\n7Hx295o7JYDvHl8S6xAibrtvj3UIETXgoCN5f/F/6zX7aJeV6aOfvLw+d1nGNT2vXezuUS2p6pRT\n7L1NKIHpRuiU07uEKjQHA28Fk3Y7A/PMLA84ndqddvoL8B4w1cyqmyu1HZgAXBu2egVwQDCvB3e/\n3d17UHZ+j4iISNxQQhN7bxGqimx29+JgMnYrQknNO4SSl1vcvX3wSgcyzGzvWuz7SmAr8C+rfvbX\nJOBoYA8Ad18FLAL+bGaNAcysGbqUX0QkMQQPp4zUKxaU0MTeMkJXN71bbt0Wd99IqCIzvdw204P1\nAEeZWX7Y66CSTh46nzgCSCNUsamUu28D7gfahK2+ANgNWGVmi4GXKFvFERERiRuaFBxj7l5MuVM5\n7j4y7H2HSrYJf5bWzpXsdkBY323AsWFt84P1kwi7/Nvd7yeU1JQsbwXi8x7lIiLyKxmWYEV3VWhE\nRESkwVOFRkREJMkYoQerJpLEGo2IiIgkJVVoREREklCiPfpACY2IiEgS0qRgERERkTijCo2IiEjS\nid0N8CJFFRoRERFp8FShERERSTKG5tCIiIiI/CpmdryZfWxmq8zsumr6DTMzN7Man9ytCo2IiEgS\nitUcmuChxw8CxwD5wEIzm+HuK8r12xW4HHivNvtVhUZERESiqR+wyt0/C543+B/gpEr63Ubowco/\n1manSmhERESSjYFZo4i9gN3NbFHYa1TY0TOAtWHL+cG6n8Mz6wm0c/fc2g5Jp5xERESSTsSftr3R\n3aua91LZgb20MZQR3QOMrMsBVaERERGRaMoH2oUtZwKFYcu7AvsD880sD/gtMKOmicGq0IiIiCSZ\n0NO2Y3bZ9kKgs5l1AAqA04EzSxrdfQuwe8mymc0Hrnb3RdXtVBUaERERiRp33w5cCswBVgJT3H25\nmd1qZif+0v2qQiMiIpKEYvm0bXefDcwut+6PVfQdUJt9qkIjIiIiDZ4qNCIiIkmokR59ICIiIhJf\nVKERERFJMkZs59BEghIaERGRpGMld/RNGEpoRCQpbXm82ltaJIzm5/WOdQgRt+XRhbEOIcISq5IS\nKUpoREREkpAmBYuIiIjEGVVoREREkoxZ4k0KVoVGREREGjxVaERERJKQaQ6NiIiISHxRhUZERCTp\nWMLNoVFCIyIikoR02baIiIhInFGFRkREJMmEnuWUWDWNxBqNiIiIJCVVaERERJKO6bJtERERkXij\nCo2IiEgSSrTLtlWhERERkQZPFRoREZEklGhzaJTQiIiIJCGdchIRERGJM6rQiIiIJBlDjz4QERER\niTtKaCRuzX1xLt2zepDdpRvj7h5fob2oqIizzziX7C7dOOyg/qzJW1PaNu6ucWR36Ub3rB7MmzMv\nmmHXicaYGGN8ac5L9M7uS4+uvZj4l3sqtBcVFTHyzPPp0bUXRx5yNGvyvijTvvaLtaSnZnL/xAei\nFXKdHdf9MD4aN4dPJ7zEtYNHVWjfa7d0Xrr+MT64Yyavjv03Ga3blq5fdNt03r99Bh/eNZuLjjwj\n2qHXWjJ8jqUs9LTtSL1iQQmNxKXi4mKuuPwqns+dzvvLFjP16amsXLGyTJ9JjzxGamorln+8jMuu\nuJSx198EwMoVK5k6ZRpLli5ixqznGH3ZlRQXF8diGNXSGEMSYYxjRl/DtJlTWfDBuzzz9DN8tOKj\nMn0ef/QJWqW25L8rl3DJ5Rdz8w23lGm//uqxHH3c0VGMum4aWSMeHHELJ/zlArL+cAJn/HYQXdP3\nKdNn/JnX8fibz3HADYO5dfpfufPUMQCs++YrDv7TafQceyIH3jyM6waPIq1Vm1gMo1rJ8DkmOiU0\nEpcWLlhEp04d6dCxA02aNGH4qcPInZFbpk/ujFzOOucsAE4ZOoT5r8zH3cmdkcvwU4fRtGlT2ndo\nT6dOHVm4YFEMRlE9jTGkoY9x8cLFdOzUkQ4d29OkSRNOOfUUZs2cXabP7JkvcOY5ocrEyUNP4rVX\nX8PdAch9fhbtO+5N16z9oh57bfXr1J1VG9bw+Vdr+an4J/7z7ixO6n1UmT5ZGfvw8vJ3AHh1xbuc\n1Dv0i/2n4p/Ytn0bAE13akKjOH0gYjJ8juUZjSL2ioX4/GZJ0issLCSzXWbpckZmBgWF66rsk5KS\nQouWLdi0aRMFhesqbFtYWBidwOtAY6zYp0GOsWAdGZkZpcsZGemsKzfGdQWFpX1Kxrh502a+//57\n7h1/H9fdeG1UY66rjNS2rN3885jyN68nI3XPMn0++OIjhvY9DoAhfY6lxc7Nad28FQCZrdvywR0z\nWXvf69yd+zDrvvkyesHXUjJ8jolOCY3EpZK/esKVPy9bSZdQn1psGw80xpI+FbdLljHecetdXHL5\nxTRv3jxS4dWLyn7sTtlBXf3kXfTfrx9L/vw8/bv2I3/zerYXbwdCCdABNwxmnzFHM+KwIbRpsVs0\nwq6TZPgcy9Mcmloys3vM7Iqw5Tlm9s+w5QlmdlXw/koz+9HMWoa1DzCzsrXp0Pr5ZtYneN/ezD41\ns+PC+5vZSDPbYWbdw7b70MzaB++bm9lDZrbazN43s8VmdmE1Y2lvZv8L+q40swVmNqJcn5PNbKmZ\nfWRmy8zs5GD9AWb237B+Z5jZD2a2U7DczcyWho1tUVjfPmY2P3i/i5lNDvb9oZm9aWZ7m9l/g9d6\nMysIW24SbDfEzNzM9gvbb3sz+zDs57wlGNtHZjY+rN+eZpZrZh+Y2QozK1t/jaCMjAzy1+aXLhfk\nF5Ce1rZcn/TSPtu3b2frlq20bt26zPqSbdPS0qITeB1ojCV9GvgYM9MpyC8oXS4oKKRtuTGmh/Up\nGWNq61QWL1jEzTfcTLfO3XnogYeYcPdEHv6/h6Maf23kb15Pu9Y//+wzW7el8OuyVZZ133zJ0Pt+\nT68bT2LslIkAbP3fdxX6LC9YxWFd+kY+6DpKhs8x0UWyQvM2cDCAmTUCdgeyw9oPBt4K3p8BLASG\n1HbnZpYJzAHGuPucSrrkA2Or2PyfwNdAZ3fvCRwPtK7hkKvdvae7dwVOB640s/OCWA4AxgMnuft+\nwInA+CChWgbsbWa7Bvs5GPgI6Bm2/FbYcdqY2QmVHH80sMHdu7n7/sDvgPXu3sPdewB/A+4pWXb3\nbcF2ZwBvBjFX5Y3g59ATGGRmhwTrbwXmufsB7p4FXFfDz6je9Onbm1WrVpP3eR7btm1j6pRp5AzO\nKdMnZ3AOk5+YDMCzz0yn/xH9MTNyBucwdco0ioqKyPs8j1WrVtO3X59ohV5rGmNIQx9jrz69WL1q\nNXmfr2Hbtm08O+VZBg4q+5/wwEHH8+QTTwHw3DPPc/iAwzEzXnz1BZZ9upRlny7l4ssuZsy1VzHq\nkopXEMXaws+W0blte9rvkclOjXfi9N/mMGPJy2X67NY8tfQv8+tPvIhHXpsGQEbrtjTbqSkArXZp\nwSGde/Hxus+iO4BaSIbPMZwRevRBpP6JhUjeWO8toOS6t2zgQyDNzFKBH4CuwPtm1gloDlwD3ABM\nqsW+2wKPAze6+4wq+uQCh5tZF3f/uGRlcLx+wJnuvgPA3b8C7q7twNz9s6C6NAF4FLgauMPdPw/a\nPzezO4Fr3P0cM1sIHAi8BPQGHiSUyCwI/v1S2O7HATcCL5Q7bBpQej1r+JiqYmbNgUOAI4AZwC01\njOt/QTWp5ERyGjA3rH1pFccZBYyC/9/encfLNd9/HH+9kyBKIrFLgggqsm/2X1H8FEmorRJbbO2P\nUjtVtFSpVkJbilbVVmstaZNoa6ulSEiCiFpjqyQUoUQRcvP5/XHOTebe3DWZmXPnzPvZxzw6Z5k5\nn++cuPOZ7wrrb7B+c2G1SIcOHfjFry5m5B57UVNTw5jDDqVP3z6cd85PGDJsCCNGDuewI8ZwxJij\n6LtZf7p27cofbr4egD59+7DvfvsyuP9QOnTowC8vvYT27dsXJa5ichnzU8Zxv7yIfYbvS82iGg4e\ncxCb992cC879KYOHDmKPkXtwyOGH8J3DjmbQ5kPo2rUr19z4+6zDbpWaRTUcd/2Puef0a2jfrj3X\nPHwHz8+ZxY/3PYFpr89k4lN/Z8fNt+LCA04hInjkpakce92PAdi828ZcfOAZRASSGPeX3/Pc7Jcz\nLtHSquE+1iXatcEm3CuHTR4AACAASURBVOWhhtoNi/bm0hvA9sDuJAlhd2Ay8BFwYURsL+ns9NgF\nwGvAlhHxrqQdgVMjYkS993wIGECSzFxRsH/x+ZIOA4aRJAw7R8SYtIllRPrawyOiNbVBPYFJac1I\n7b4uwNsRsbKkp9L3nFFwfCBwbUQMkXQusIgkAboHGJOW/1uSXgG+kSZJD5EkRxcBPwHmA+MiYkdJ\ng0iSi1eBB4DrI+KVguudC3wSEYVNRgcDX4+IIyU9DhwXEU8Vlqfe59aVJLkaHhHvSPoGcBvwdLr/\n2ohoslfm0GFD4rEnHm3pR2uWmS8WfdH8STmw2uFtr3mn2D66dmrWIZTUDlt/naenP13U7GPTAZvE\nLyddVMy3rGPEhvtOj4iyVqmWulPwYyQ1ENuSJDKTC7YfT88ZBdya1pbcBezfgve9HzhE0leaOe9m\nYGtJGzV2gqSz0j4nrR0+oXrP62eGhftqP4ctgakR8SqwiaS1gFUjon796/kktTSLRcQzQC+SGpzV\ngamSNm8mxtHArenzW9Pthnwt7cfzDkmi8056zXvSa/4O6E1So7ZWM9c0M7MKkLcmp1InNLX9aPqT\nNDlNAbZJ9z2W9jHZFLgvrc0ZReNfuoUuAp4AbpfUaLNZRCwkqRUpHEv3PDAw7ddDRFyQ9kHp3Lqi\nMRionSHsnyQ1QoWGpNeCpNxbAP9DktRB0sdnFEsSu8K4/w50BLaut/+TiLgrIr4L3Ajs0VhwktYA\ndgKuTj/b04ADpAbrGP8REQNI7tMxaW1Q7TU/iIibI+IQkn5O2zd2TTMzs6yUo4ZmBPBBRNRExAdA\nF5KkZjJJ8nJuRPRMH92A7pI2bMF7nwR8DPy+kS/pWtcBuwBrAUTELGAacL6k9gCSOkLLU8q0yWYc\nUDu/9TjgBwWjqHqS9Ae6OL3mfOAt4DCWJDSTgRNpIKFJXQCcXnDN7dImIdIRTH0o6FPTgP2AGyJi\nw/SzXR94nSSpalBEvAxcSJoAStqpthYs7dS8MfCvxl5vZmaVQx623SozSUY3Tam376OIeJ+khmJ8\nvdeMZ8mInJ0lzS54bFN7UiSdf8aQdFxttCEwHe1zKVA41/ZRwBrALEnTSZqwmpsRaeN0aPMLwB+B\nyyLi2vQaz6SvnyjpRWAicHq6v9ZjwEoR8Va6PZmkOafBhCYi/gK8V3h94GFJM0n6tEwD7mwi3tEs\n/dneCRzYTDl/Q9KZeiOSDszT0uaoycDVEZHvxmozM6tIJe0UbNXHnYKtUrhTcH64U3DrfXXAJnHp\n3ZcU8y3r2H2DvXLXKdjMzMys5Eo5D03FkdQf+EO93QsiYqss4jEzMyuN7Pq6lIoTmgIRMRMY1OyJ\nZmZmFa5dRsOrS8VNTmZmZlbxXENjZmZWbdQ2V69fHq6hMTMzs4rnGhozM7MqU7vadp64hsbMzMwq\nnmtozMzMqpD70JiZmZm1Ma6hMTMzqzpCOavTcEJjZmZWhdq5ycnMzMysbXENjZmZWZXxsG0zMzOz\nNsg1NGZmZlXIw7bNzMzM2hjX0JiZmVUduQ+NmZmZWVvjGhozM7MqlLc+NE5ozMzMqoyAdjlrpMlX\naczMzKwquYbGrJUWxaKsQyi5dsr/b50VtELWIZTFZ9fPyDqEklt5+GZZh1Bas/5d/PdU/pqc8v9X\ny8zMzHLPNTRmZmZVx8O2zczMzNoc19CYmZlVIfehMTMzM2tjXENjZmZWhfLWh8YJjZmZWZUR+Uto\n3ORkZmZmFc81NGZmZtXInYLNzMzM2hbX0JiZmVUdT6xnZmZm1ua4hsbMzKwKeWI9MzMzszbGNTRm\nZmZVKG99aJzQmJmZVaG8JTRucjIzM7OK5xoaMzOzKiPcKdjMzMyszXENjZmZWdXxxHpmZXPv3+5l\nQJ9B9N2sP2N/Pm6p4wsWLODg0YfSd7P+fG2bHXjzjTcXHxv7s7H03aw/A/oM4r577itn2K1y7z33\nMajvYPr3Hsi4iy5e6viCBQs49MAx9O89kB22/friMs6bN4/dd9mDtbusy8nHn1LusFulWu7jwL6D\n6dd7QKP38ZADD6Vf7wFsv+2Odcv483H06z2AgX0Hc9+995cz7Faphvv4jaE78uLVD/HKNf/g+9/6\n7lLHN1i7O/dfeAszrryXBy/6I93XXHfxsZ8d8QNm/uZ+Zv7mfr61/chyhl2RJO0m6SVJsySd0cDx\nkyU9L+lZSQ9I2rC593RCY21STU0NJx5/Mn+eNJ6nZ07n9ttu54XnX6hzznXXXE/Xrl3450sz+d6J\nx3HWD34IwAvPv8Dtf7yDp56dxoS7/8QJ3zuJmpqaLIrRpJqaGk4+/hTGT7yL6c9O5fZb7+CF51+s\nc87119xAly5dmPniDI474Vh+eOaPAOjYsSM/PPdsfvrzC7IIvcWq5T6edPzJ/GniXTz17DRuv7Xh\nMnbp0oXnXnyW751wLGefuaSMd9x2B9NnTOXPk8ZzYhsuY97vY7t27bj82PPZ/exD6fOdnRi9415s\nvsGmdc4Z9+2zueGBOxl4zK6cd9MvufDw5Ht4jy13Ysgm/Rj03W+w1QkjOW2/o+n0lVWzKEarqIT/\na/K6UnvgcmB3oA8wWlKfeqc9DQyLiAHAHcBFzZXHCY21SVOfnMbGG/dio14bseKKK7L/t/Zj0oRJ\ndc6ZNGESBx1yEAD77Ls3D/39ISKCSRMmsf+39mOllVai50Y92XjjXkx9cloGpWjatCen0augjPsd\nsC+TJtYr48S7OeiQAwHYe99vLi7jKquswrb/sy0rdVwpi9BbrFru48Z17uN+TJp4d51z7p54Nwen\nZdy7sIwT72a/A+qWcVobLGM13MctNxvErLff4PV3/sWXC7/k1ocnsNc2u9Y5p88Gm/LAM48C8OCM\nx9lr610X73945hPULKrh0wWfMeP159lt6I5lLkFF2RKYFRGvRcQXwK3AXoUnRMSDEfFpujkF6NHc\nmzqhsTZp7ty59Fh/yb/f7j26M2fu242e06FDBzqv1pl58+YxZ+7bS7127ty55Qm8FebOfZsePbov\n3u7evTtvz2mujKsxb968ssa5PKrjPs6le4+COLt3Z+6cuUuf08B9nDtnLj0KXtute9stY97vY/c1\n1uWt95bENfv9t+m+xrp1zpnx2gvsu90eAOy93W50XqUTq3fqwozXXmD3YTuy8kodWaNzV74+YBvW\nX6tbWeNvNSWjnEr1aEZ34K2C7dnpvsYcCfy1uTd1p2BrkyJiqX31/yNp4JTknBa8ti1oSRkrpSyN\n8X1s+pwW/RtoA6rhPjYUU/1yn/q78/n1sT/hsP/dn0eee4LZ773Nwpoa7nvqEbb46kAev+RPvPfR\nPCa/8BQLaxaWK/RlVuJOwWtKKqyKuyoirlp86aU18C8IJB0MDAN2aO6CFVFDI+kXkk4s2L5H0tUF\n2xdLOjl9fpKkzyWtVnB8R0l160eT/Q9JGpY+7ynpFUnfKDxf0mGSFkkaUPC65yT1TJ+vKulKSa9K\nelrSdEnfbqIsS8Ui6TpJ+xXE9JKkGZIek7RZun9E+v4z0o5S/yfpLEnPpI+agufHF7z3DEm3tPB6\nUyUNKjjvCEkz005Zz0mqUyVYSt27d2f2W7MXb8+ZPYdu661b75xui89ZuHAhH3/0Mauvvnqd/bWv\nXW+99coTeCt0796N2bPnLN6eM2cO63arW8ZuBZ9DUsaPWH311csa5/KojvvYnTmzC+KcM4f1uq23\n9DkN3MfuPbozu+C1c+e03TLm/T7Ofv/tOrUqPdZcj7kf/LvOOW9/8G/2/cl3GHLc7px1XdKl4+NP\n5wPw01svY/Cxu7HrmQchiVfmvl6+4Num9yNiWMHjqoJjs4H1C7Z7AEtV20naBTgL2DMiFjR3wYpI\naIDHgW0BJLUD1gT6FhzfFngsfT4amArs3dI3l9QDuAc4JSLuaeCU2SQfakOuBj4ENo2IwcBuwPJ+\n4xwUEQOB64GxklYArgJGpvsHAw9FxAURMSgiBgGf1T6PiEvTcm1Oco+3l7RKC653BTA2fW2PtMz/\nk3bK2hp4djnL1WLDthjKrFmv8sbrb/DFF19w+x/vYPjI4XXOGT5yODf94SYA7rpzPDt8fQckMXzk\ncG7/4x0sWLCAN15/g1mzXmWLLYeVK/QWG7rFUF4tKOMdt93J8BH1yjhiD276w80AjL/zT4vLWCmq\n5T7OqnMf72D4iD3qnLPHiD24MS3j+MIyjtiDO26rW8ZhbbCM1XAfp740g0279aTnOuuzQocVGLXD\nnkyYUndE1hqduy7+7+8HBxzHNffeBiQdilfv1AWA/hv1ZsBGm3Pv9EfKW4BWqp1YL6Mmp6nAppI2\nkrQiMAqYUCc+aTDwW5Jk5t2WlKlSmpweA36RPu8LPAesJ6kr8CmwOfC0pI2BVYHTgDOB61rw3usC\nNwBnR8SERs6ZRJIUbBYRL9XuTK+3JXBgRCwCiIj3gJ+3rniNegQ4EehEcq/mpddYALzUxOtqHQj8\ngeTz2RO4penTmUzy2QGsDcwHPkmv+Unt8/okfQf4DsD6G6zf0Cmt1qFDB37xq4sZucde1NTUMOaw\nQ+nTtw/nnfMThgwbwoiRwznsiDEcMeYo+m7Wn65du/KHm68HoE/fPuy7374M7j+UDh068MtLL6F9\n+/ZFiauYOnTowMW/Gsdew79JTc0iDj3sEPr03ZyfnHs+Q4YOZvjI4Yw54lCOOuzb9O89kK5du3L9\nTdcufv3mm/Rl/sfz+eKLL5g4YRIT/vJnNu/TO8MSLa1a7uMlv7qYPYd/k5qamvQ+9uG8c3/CkKFL\nynjkYUfRr/cAunbtyg03XQckZdxn/30YMmBY8lm14TLm/T7WLKrhuCt+yD0X3Ej7du255t7beP7N\nl/nxIacw7ZVnmTjlPnYcsA0XHn4GEcEjzz3BsZefDcAK7VfgH+PuBODjTz/h4IuOp2ZR2xvJ1VZE\nxEJJx5FUJLQHromIf0o6D5iWfhePJfk+vz1NkP4VEXs29b5qqG20LZL0BrA9yTAvkXQgmgx8BFwY\nEdtLOjs9dgHwGrBlRLwraUfg1IgYUe89HwIGkCQzVxTsX3y+pMNI2u+eBHaOiDGSngNGpK89PCJa\nUxu0VCySrgMmRcQdaUynRsQ0SaeRDFs7IG1i2xN4gCTBuqU2iUrf45OIqDNOUNLLwP8CmwHH1f5j\naOJ6JwJrR8SZSobV/YUkGXoAuCsiJjZXvqHDhsRjTzza0o+jIi1a8rHnVjtVSuXtsquUv33Lq5Jq\n9JbVysM3yzqE0pr8b+KjL4p6I/sN7hu3P3hzMd+yjj5dB02PiLJWxVXSX63HSJqWtiVJZCYXbD+e\nnjMKuDX9or8L2L8F73s/cIikrzRz3s3A1pI2auyEgj4tTXXhb+yvaOH+myQ9A2wHnAoQEUcBO5Mk\nVqcC1zQVrKQtgPci4k2ShGRIWqPVkJskzQa+D1yWXq+GpPlsP+Bl4BeSzm3qmmZmZlmppISmth9N\nf5ImpynANum+x9JOu5sC96W1OaNI+tM05yLgCZJqrUab4CJiIXAxyZd+reeBgWm/Hmr7tACdm7je\nPKB+YrE68H7B9kFpX5hvRsTioW0RMTMifkFS67JvM+UaDfROP4tX05gae81BwEYkSdvlBdeLiHgy\nIi4k+Tybu6aZmVWIrCbWK5VKSmgeI2nm+SAiaiLiA6ALSVIzmeQL/NyI6Jk+ugHd1YLpkoGTgI+B\n36vp+tnrgF2AtQAiYhYwDTg/baJBUkcaHpJW6xWgW9phlzS+gcAzjb1AyUiqHQt2DQLebOT02o7T\n+wMDaj8PkkmLGk3wIuJL4GySWqjNJXWTNKSl1zQzM8tSpXQKBphJMrrp5nr7Vo2I9yWNIulfU2g8\nSc3CE8DOabNKrcXNURERksaQ9E25CKg7zeeS876QdCnwq4LdR5F0Xpol6QPgM+rW4tR/jwVKxtVf\nmyY/XwJHRcRHjRcdAadL+m36/v8FDmvi/O2BORExp2DfI0AfSY2Ol4yIzyRdTNKkdR4wTlI34HPg\nPeDoJq5pZmYVJG/9qyqmU7BVBncKzgd3Cs6PvH1pNcSdgluv3+C+cedDtxbzLevo3WVA2TsFV1IN\njZmZmRVJVn1dSsUJTYlI6k8yB0yhBRGxVRbxmJmZ1RJOaKyFImImSUdaMzMzKzEnNGZmZlWnRUsU\nVJT89/wzMzOz3HMNjZmZWVVyDY2ZmZlZm+IaGjMzs2qj/M1R5BoaMzMzq3iuoTEzM6tCnofGzMzM\nKl7eEho3OZmZmVnFcw2NmZlZlZEn1jMzMzNre1xDY2ZmVoXch8bMzMysjXENjZmZWRVyDY2ZmZlZ\nG+MaGjMzsyqUt1FOTmjMzMyqkJuczMzMzNoY19CYmZlVmTxOrOeExorqqelPv79yh1XeLPNl1wTe\nL/M1y81lzAeXMR/KXcYNy3itiuWExooqItYq9zUlTYuIYeW+bjm5jPngMuZDXsroPjRmZmZmbYxr\naMzMzKqSa2jM2pqrsg6gDFzGfHAZ86EaylhxFBFZx2BmZmZlNHDIgPjbo5NK9v7dVtlwern7GbnJ\nyczMrArlbdi2m5zMzMys4rmGxszMrCq5hsbMzKwOSWtI2lvS0KxjserkhMYqiqS+kvYs2P6FpGvS\nx5AsYysGSZ0lbVqwvb+kQ9PHOlnGVix5v4cAko6UdFrB9hxJH0uaL+mYLGMrFkmTJPVLn68HPAcc\nAfxB0omZBlckkkZK2rBg+0eSZkiaIGmjLGMrBpXwkQUnNFZpfkbdKce/AdwNPAj8KJOIimscsF3B\n9oXAFsD2wI8ziaj48n4PAY4GrinYfjciOgNrAaOzCanoNoqI59LnhwP3RcRIYCuSxCYPLgDeA5A0\nAjiYpGwTgN9kGJc1wH1orNKsFxGPF2x/HBF3Akj6v4xiKqYtgMJyzI+I7wFIejSbkIou7/cQoF1E\nzCvYvh0gIj6XtHJGMRXblwXPdwZ+BxAR8yUtyiakoouI+DR9vg/w+4iYDkyX9N0M4yqCLOtSSsMJ\njVWaToUbEbF1webaZY6lFDpE3cmhDil43qXcwZRI3u8hwGqFGxHxUwBJ7YA1Momo+N6S9D1gNjAE\n+BtAmrCtkGVgRSRJqwKfkiRtVxQc65hNSNYYNzlZpZkraav6OyVtDczNIJ5iWyRp3dqN2ip9Sd2B\nvPzqzfs9BLhX0vkN7D8PuLfcwZTIkUBf4DDggIj4T7p/a+DarIIqsl8CzwDTgBciYhqApMHA21kG\ntrykZB6aUj2y4BoaqzTfB26TdB3wVLpvKDAGOCCroIpoLDBR0inA0+m+ISR9a8ZmFlVx5f0eApwG\nXC1pFjAj3TeQ5IvxqMyiKqKIeJekr1D9/Q9Kei2DkIouIq6RdA9JzeGMgkPvkCRy1oY4obGKEhFP\npr/kj2XJH5R/AltHxL8zC6xIIuJGSe8D55P8+oVk9MiPIuKv2UVWPHm/hwAR8V9gtKReLLmPz0fE\nqxmGVXSStgG6A49ExLuSBgBnAF8D1s80uCKJiDnAnHq7OwOnAt8uf0TWGCc0VnHSL728jIZZSkT8\njbQ/Ql7l/R5K2iB9upCCX/a1+yPiX1nEVUySxgIjSJpkvi9pEvBd4KfkZJRTmqCNA7oBfwIuI+lH\nsxVwcYahFYXcKdgsO5IeBBpbUTUiYudyxlNskpr6ko+I+EnZgimRvN/D1N0kZSz8xgiSYdtrA+2z\nCKrIhgOD05FbXUn6Pw2IiFcyjquYfgdcCUwGdiNpIr0ZOCgiPs8yMFuaExqrNKc2sG9r4HTg3TLH\nUgr/bWDfKiQdMNcAKj6hIf/3kIjoX7gtqSdJ36FdSGow8uCz2i/1iPhQ0ks5S2YAVoqI69LnL0k6\nFTgjImoyjKloXENjlqF0DggAJO0A/BBYCTg6D31MImJxNbakTsAJJJOW3UoOqrgh//ewUDrr81ks\naaI4PiK+bPpVFWNjSRMKtnsWbkfEng28ptJ0TEc01X7zfwIMUDqMJyKeavSVVnZOaKziSPoGyZfg\n58AFEfFgxiEVlaTVgZOBg4DrgSER8WG2URVXFdzDfiSJTF/gIuDIvPyqL7BXve1cJNz1vANc0sh2\nADuVPSJrlBMaqyiSppL0QxhL0q5N4fo/lf6LKe1ouQ9wFdA/Ij7JOKSiy/s9TM0A3iLpS7MlsGXh\n3BwRcXxGcRVNRDycdQylFhE7Zh2DtZwTGqs0/yWp9t0vfRTKwy+mU4AFwNnAWQVfgiLpMNs5q8CK\nKO/3EJI+T411fM4FSTNpuIy1/1YHlDmkopO0T1PHI+KucsVSCllNgFcqTmisouT9F1NE5H727rzf\nQ4CCjqR5NiLrAMpgZBPHAqjohCZvnNBYRamCX0yrN3U8Ij4oVyylkvd7CCBpIk3U0OShw2xEvNnQ\nfknbAQeSTJxY0SLi8MaOSVqnnLFY85zQWKXJ+y+m6Sw9f0mtAHqVN5ySyPs9hGQytqohaRBJEvMt\n4HXycQ+XImk1YF+Ssm5OMktyhZKHbZtl7NzGfhnmxI45L1+Tv3pzZMWIuK+hA5J+DlR8h1pJXwVG\nAaOBecBtgCLi65kGVmTp6uF7kiQxQ0hWi/8m8EiWcdnSct9eb7nzgKQzJOU1GR+fdQDlIGkzSRdL\nujt9jEu/IPPicknDC3dIapcuyDkwm5CK7kVgZ2BkRPxPRFwG5GpouqSbgJeBXYFfAz2BDyPioYhY\nlGVsxaESPsrPCY1VmsHAOsB0SdtnHUwJ5KsOuAHpgoYPkYx0uopkevn/Ag+li1bmwa7AxbX9hdJf\n+ROAFWm6ya2S7EsyL8uDkn4naWfy9++3H/Ah8ALwYjqXUK5Hr1WyvP7KtZyKiPnASZKGktTWzAYW\nkZ+hot0lXdrYwTzMX0KyKOXoiHioYN+fJP0dOAfYPZOoiigi3pC0C3CPpLWBQ4AnIuLkjEMrmogY\nD4yXtApJE8xJwDqSrgTGR8S9mQZYBBExUFJvkuam+yW9C3SStG5EvJNxeMslu3qU0lGEk02rLJJ2\nAn4F3ANcTpLQAI2PvKgUkt6kiVWoI+L6MoZTEpJejogGm5fS9YA2K3dMxVYwUeB6wA3AfSQzBgP5\nmDxQUoeIWFhv3+rA/sABEZGH+YTqkDSMpM/Q/sDsiNg245CW2eChg+LvjzfYzasoVu+49vSIGFay\nCzTANTRWUSTdSjKy4MCImJl1PCUwLw9JSzPmN3GsocU5K1HhMgDPkjST1u7Ly+SBT5J0kl0snVbg\nt+mj4kk6LiJ+XbsdEdOAaekilRXf5O2J9cyy9UBE/K6hA5LWiYh/lzugIlsv6wDKYP1GmtVERQ+D\nXaKpkT456ieUr2/Dhh1B0hm4jkiaNip+pFreOKGxilI/mcnXvBBA0sky705r4ti0skWRnT8CG2Qd\nRBGsJanRPkERcUljx6ytyFdO6oTGKk7O54XIfae2KmhSa05evkXaA6uSn/I0ZICkjxvYn4u11fJ2\n45zQWEVJ54XYHriXpCr478CseiNmKlmPvI9yknQtjSduERFHljOeDOQlaX07Is7LOogSmxkRg7MO\nwlrGCY1VmqXmhZCUly8IgM9Ilj/Is0kN7NsAOJHkV3/Fa2ItJwFrlDmcUsnbD/wqlK9b6ITGKkqe\n54VI5X6UU0TcWftcUi/gTJJat58Bv88qriJrai2nvKzztJekFSLiS0hmfwb2AN7MwwKjqduzDsBa\nzjMFW8WJiBcj4kfpfCUnkczz8aSkxzMOrRi+yDqAcpC0uaQbgYnAo0CfiLgyInJR/oh4uKEH8Bqw\nZdbxFcmNJEsBIGkTYDLJ4qnHSroww7iK6T1JmwIoca2kjyU9WzDXUIUSUukeWXANjVW0gnkhTgNO\nyDqeIji2qT+UOZmQ7XZgGElNxUkk6/90rv0jmM5lkhuS1iSZiG00ySi8vKzX1TUiXkmfjwFuiYjv\nSVqRpNn0B9mFVjQnANelz0cDA4CNSJZg+RXwtWzCsoY4obFciIhFkk4CfpF1LMtpHEnfi9qfOPX7\nYeRhQrYtSMp1KnBKuq+wvL2yCKqYJHUC9iZpGv0qSRLTKyJ6ZBpYcRX+29wJGAsQEV9IysHCjQAs\nrG1SA0YAN0TEPJLm7ouaeJ1lwAmN5Ukeerh9H3grIt4GkDSGZJ6dN4BzswureCKiZ9YxlMG7JDPp\nng08GhEhae+MYyq2ZyWNA+YAm5CMPERSl0yjKq5FktYjGYiwM3BBwbGVswnJGuM+NJYneRjt9Btg\nAUC6mviFwPXARyQrU+eSpI0lnSXpuaxjKZIzgY7AlcAPJG2ccTyl8G3gfZJ+NLtGxKfp/j7kp+Pz\nj0gme3wDmBAR/wSQtANJf6iKlSxOWbr/ZVImL05plUTSfBofDrtyRFR0raOkGRExMH1+OfBeRJyb\nbj8TEYOyjK+Y0l++B5A0ywwgSd7uytMaXekortHAKGBTktXEx0fEy5kGZi0mqQPQKSI+LNi3Csn3\n5yfZRbZ8hgwdHA9Peahk7995xS5enNKsKRHRKesYSqx9wSrGOwPfKTiWi/9eJX2b5Eu+B8kyAEcB\nf46IH2caWBFJOpFk9NYzEXEBcIGk/iTl/itQ8TU2kh6k6QkSdy5nPKWQjnAaC2wiaSZwakTMiYi8\nLKKaK7n4A2mWI7cAD0t6n2SSvX/A4mGxH2UZWBFdTjLE98B0lBo5mxwRkmTtUqC3pGeBx4HHgHER\ncWamkRXPqQ3s2xo4naQPUR5cQzItxCMky61cBuyTaURFlIdOh4Wc0Ji1IRFxgaQHSFbdvjeWtAm3\nA76XXWRF1Y1kGPMlktYhqaVZIduQiisiTgVIhzAPA7YlWbn5d5L+ExF9soyvGCJi8YzWaZ+SHwIr\nAUdHxF8zC6y4OhUsiDtWUsVPm5BnTmjM2piImNLAvtz0uYiI90k6y14pqQdJ/5J3Jb1A0r8kLzUY\nkIyE6Qyslj7mAnnqI/QNkkTmc+CCiHgw45CKraOkwSypzFi5cLvS54XKagK8UnFCY2ZlJWnr2qQt\nImaTjIgZl06dGtnlDgAADvpJREFUPyrT4IpE0lVAX2A+8ARJk9MlhR1LK52kqcBaJH1MJqf7Fk8K\nWelf9ql3gEsa2Q7yMS9UbjihMbNyuwJYajbkiHgJyEvH4A1Iml9eIZmnZTbwn0wjKr7/Ap8A+6WP\nQrn4so+IHbOOoXRE3nrROKExMyuyiNhNSX1+X5L+M6cA/SR9AEyOiHMyDbAI8v1ln5BUvwNwkMy9\n80xEzM8gJGuCExozK7dekiY0djAi9ixnMKWSduh+TtJ/SEaofUQyff6WJPPRVDRJM0iGpj8OPBYR\nb2QbUUmMbGDf6sAASUdGxN/LHVAx5at+xgmNmZXfe8DFWQdRSpKOJ6mZ2Q74kmTI9mSSYcB56RR8\nEEkZ/xc4J51s7vHaR0Q8kWVwxRARhze0X9KGJKPztipvRMWWr5TGCY2ZldsnEfFw1kGUWE/gDuCk\n2nW58iYingOeI12SI11VfBRwIklH7/bZRVdaEfGmpFxNNZAHTmjMrNw+lLRuRLwDIOlQkgU43wTO\njYgPMo2uCCLi5KxjKDVJ7YHBLKmJ2pikA/TVpKOe8iodkbcg6ziWizxs28xseXUBvoDFC3D+jGTS\nwEEkv/brj5ixtulj4AWSmZ/PiIjXM46n6CRNZOnlHVYnmfjy4PJHZE1xQmNm5dauoBbmAOCqiLgT\nuFPSMxnGZa1zFLBN+v+Hp/PSTCYZxTUn08iKp/6q4QHMA16JiC8yiCc3JO0G/IqkafLqiPhZveMr\nkSw7MZTkMz+guY7nTmjMrNw65H0BzmoQEbeQrD2GpK+QjN7aDrhQ0ooRsWGW8RVDS/t6SZocEduU\nOp68SJsrLyfpUD4bmCppQkQ8X3DakcCHEbGJpFHAz0l+ADXKfzzMrNyqYQHOqpCObNqKJf1otgDe\nIhnVVU06Zh1AayXT6mXWh2ZLYFZEvAYg6VZgL6AwodkLODd9fgfwa0kqWN9uKU5ozKysqmQBztyT\n9DTJjMjTSIZqXwxMiYhPMg0sGxW3WvxT05++Z+UOq6xZwkt0lDStYPuqiLgqfd6dJPGtNZulh8Av\nPiciFkr6CFiDZGLDBjmhMbOyy/sCnFViDDCzqV/M1nZFxG4ZXr6hqqH6/45ack4d7ZY5HDMzq1oR\n8SzQV9L1kqZJmpo+H5B1bBnI1/jn0psNrF+w3YNkJfoGz5HUgWS1+iandHBCY2ZmrSZpL2A88DBw\nBMlop4dJRqvtlWVsGTgk6wAqzFRgU0kbSVqRZELG+suhTCCpBYRkKoe/N1cbKNcWmplZa6VrOe1V\nfyitpJ7AnyNiYAZhFZWkI4HVI2Jsuj0H6ERSI3N6RFyZZXyVTNIewC9Jhm1fk/atOw+YFhETJHUE\n/kAyeeMHwKjaTsSNvqcTGjMzay1Jz0dEn9YeqyTp3Dq7RcS8dPvpiBicftneGxHbZxuhFXKTk5mZ\nLYsvJW1Qf2e6cOPCDOIphXa1yUzqdoCI+BxYOZuQrDEe5WRmZsviHOB+ST8FppOMQNkCOAP4fpaB\nFdFqhRsR8VMASe1IhhBbG+ImJzMzWyaSBgKnAH1J+pX8ExgXETMyDaxIJF0BfBARZ9fbfz6wZkQc\nnU1k1hAnNGZmZg1IZ0K+mqTmqTZJG0gymeBRVTqJYJvlhMbMzJaJpDHA8UDvdNcLwKURcUN2URWf\npF4ktVAAz0fEq1nGYw1zHxozM2s1SYcCJwInA0+RNDkNAcZKIg9JTUGn54UsqaFZvD8i/pVFXNYw\n19CYmVmrSZpCMjfIG/X29wRujYitMwirqCTNJOnsXDgTcABrAWtHRPtMArMGuYbGzMyWRef6yQxA\nRLwhqXMG8RRdRPQv3E6Tte8DuwA/zSAka4LnoTEzs2Xx2TIeqziSNpV0HfBXkiHqfSLismyjsvrc\n5GRmZq0m6VNgVkOHgF4RsUqZQyo6Sf2As0g6BF8E3BIRNdlGZY1xQmNmZq2WzgjcqIh4s1yxlIqk\nGuAt4G5gqUQmIo4ve1DWKPehMTOzVmtpwiJpckRsU+p4SuRIkk7AVgFcQ2NmZiVTu6Bj1nFY/rmG\nxszMSqlifzVLmkgT8UfEnmUMx5rhhMbMzKxh47IOwFrOCY2ZmZWSmj+lzVoxIu5r6ICknwMPlzke\na4LnoTEzs1I6JOsAlsPlkoYX7pDULp2TZmA2IVljnNCYmVmrSTpS0mkF23MkfSxpvqRjavdHxHPZ\nRFgUuwIXS9oHQNLKwARgRWBkloHZ0jzKyczMWk3SVGC3iJiXbj8dEYMldQTujYjts42wOCT1AO4B\nLiOpbXoiIk7ONipriPvQmJnZsmhXm8ykbgeIiM/TmoyKJ2lI+vR04AbgPuDG2v0R8VRWsdnSXENj\nZmatJmlWRGzSwP52wKyI6JVBWEUl6cEmDkdE7FS2YKxZTmjMzKzVJF0BfBARZ9fbfz6wZkQcnU1k\n5SFp64iYknUctoQTGjMzazVJqwBXA1sAM9LdA4FpwFER8UlWsZWDpH9FxAZZx2FLOKExM7NlJqkX\nyWrUAM9HxKtZxlMukt6KiPWzjsOWcEJjZmatJqnJ2omI+Fe5YsmCa2jaHo9yMjOzZXE3yTpHhTMB\nB7AWsDbQPougiqmJtZwErFHmcKwZrqExM7PlJqkn8H1gF+DSiLgs04CKQNIOTR2PCC990IY4oTEz\ns2UmaVPgLGAr4GLg+oj4MtuoSkvS+sCoiBibdSy2hJc+MDOzVpPUT9ItwJ3A/UC/iLg6r8mMpDUl\nHSPpEeAhYJ2MQ7J6XENjZmatJqkGeIukL01N/eMRcXzZgyoySZ2AvYEDga8C44EDIqJHpoFZg9wp\n2MzMlsWRNNxhNk/eBZ4EzgYejYiQtHfGMVkjXENjZmbWAEknAaOAVYCbgduA+/KwrEMeOaExM7NW\na2JIMwARsWcZwympdPLA0STJzabAOcD4iHg508CsDic0ZmbWatUwpFnSicCjwDMRsTDd158kuTkg\nIjbOMj6ry31ozMxsWawYEfc1dEDSz4GKT2iAHsClQG9JzwKPA48B4yLizEwjs6W4hsbMzFpN0svA\nSRFxd8G+dsA1wLoRsVtmwRWZpBWBYcC2wDbp4z8R0SfTwKwO19CYmdmy2BX4m6SVIuIuSSsDtwMf\nAyOzDa3oVgY6A6ulj7nAzEwjsqW4hsbMzJaJpB7APcBlwCHAExFxcrZRFY+kq0hWEp8PPAFMAaZE\nxIeZBmYN8kzBZmbWapKGkCxCeTpwAckkezdKGpIey4MNgJWAd4A5wGzgP5lGZI1yDY2ZmbWapAeb\nOBwRsVPZgikhSSKppdk2ffQDPgAmR8Q5WcZmdTmhMTOzopK0dURMyTqOYkqb17YjSWpGAGtERJds\no7JCTmjMzKyoJP0rIjbIOo7lJel4kgRmO+BLkiHbk9P/nxkRizIMz+rxKCczMys2ZR1AkfQE7iAZ\nnv52xrFYM1xDY2ZmRZWXGhqrLK6hMTOzVmtiLScBa5Q5HDPX0JiZWetVw1pOVlmc0JiZWdFIWh8Y\nFRFjs47Fqosn1jMzs+UiaU1Jx0h6BHgIWCfjkKwKuQ+NmZm1mqROwN7AgcBXgfFAr4jokWlgVrXc\n5GRmZq0m6TPgSeBs4NGICEmvRUSvjEOzKuUmJzMzWxZnAh2BK4EfSNo443isyrmGxszMlpmkXsBo\nYBSwKXAOMD4iXs40MKs6TmjMzKzVJJ0IPAo8ExEL0339SZKbAyLCNTZWVk5ozMys1SSNI1nnqDfw\nLPA46VpHEfFBlrFZdXJCY2Zmy0zSisAwkuRmm/Txn4jok2lgVnU8bNvMzJbHykBnYLX0MReYmWlE\nVpVcQ2NmZq0m6SqgLzAfeAKYAkyJiA8zDcyqlodtm5nZstgAWAl4B5gDzAb+k2lEVtVcQ2NmZstE\nkkhqabZNH/2AD0g6Bp+TZWxWfZzQmJnZcpHUA9iOJKkZAawREV2yjcqqjRMaMzNrNUnHkyQw2wFf\nkg7ZTv9/ZkQsyjA8q0Ie5WRmZsuiJ3AHcFJEvJ1xLGauoTEzM7PK51FOZmZmVvGc0JiZmVnFc0Jj\nZmUhqUbSM5Kek3S7pK8sx3vtKGlS+nxPSWc0cW4XSd9dhmucK+nUlu6vd851kvZrxbV6SnqutTGa\n2RJOaMysXD6LiEER0Q/4Aji68KASrf6bFBETIuJnTZzSBWh1QmNmlcUJjZll4R/AJmnNxAuSrgCe\nAtaXtKukyZKeSmtyVgWQtJukFyU9CuxT+0aSDpP06/T5OpLGS5qRPrYFfgZsnNYOjU3PO03SVEnP\nSvpxwXudJeklSfcDmzVXCEnfTt9nhqQ769U67SLpH5JeljQiPb+9pLEF1/6/5f0gzSzhhMbMykpS\nB2B3lixguBlwQ0QMBv4LnA3sEhFDgGnAyZI6Ar8DRgJfA9Zt5O0vBR6OiIHAEOCfwBnAq2nt0GmS\ndgU2BbYEBgFDJW0vaSgwChhMkjBt0YLi3BURW6TXewE4suBYT2AHYDjwm7QMRwIfRcQW6ft/W9JG\nLbiOmTXD89CYWbmsLOmZ9Pk/gN8D3YA3I2JKun9roA/wWDKrPiuSTNbWG3g9Il4BkHQj8J0GrrET\ncChARNQAH0nqWu+cXdPH0+n2qiQJTidgfER8ml5jQgvK1E/S+STNWqsC9xQc+2M6udwrkl5Ly7Ar\nMKCgf81q6bVfbsG1zKwJTmjMrFw+i4hBhTvSpOW/hbuA+yJidL3zBgHFmjRLwIUR8dt61zhxGa5x\nHfDNiJgh6TBgx4Jj9d8r0mt/LyIKEx8k9Wzldc2sHjc5mVlbMgXYTtImAJK+IumrwIvARpI2Ts8b\n3cjrHwCOSV/bXlJnYD5J7Uute4AjCvrmdJe0NvAIsLeklSV1Imneak4n4G1JKwAH1Tu2v6R2acy9\ngJfSax+Tno+kr0papQXXMbNmuIbGzNqMiHgvrem4RdJK6e6zI+JlSd8B7pb0PvAoycrO9Z0AXCXp\nSKAGOCYiJkt6LB0W/de0H83mwOS0hugT4OCIeErSbcAzwJskzWLN+SHwRHr+TOomTi8BDwPrAEdH\nxOeSribpW/NUulL1e8A3W/bpmFlTvPSBmZmZVTw3OZmZmVnFc0JjZmZmFc8JjZmZmVU8JzRmZmZW\n8ZzQmJmZWcVzQmNmZmYVzwmNmZmZVTwnNGZmZlbx/h/3lZZ+kZuIjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x146be1f57828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cm = confusion_matrix_rnn(Y_val, best_model.predict(X_val))\n",
    "plot_confusion_matrix(cm, classes=labels, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "np.random.seed(36)\n",
    "rn.seed(36)\n",
    "tf.set_random_seed(36)\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(36)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Scling data\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class scaling_tseries_data(BaseEstimator, TransformerMixin):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    def __init__(self):\n",
    "        self.scale = None\n",
    "\n",
    "    def transform(self, X):\n",
    "        temp_X1 = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
    "        temp_X1 = self.scale.transform(temp_X1)\n",
    "        return temp_X1.reshape(X.shape)\n",
    "\n",
    "    def fit(self, X):\n",
    "        # remove overlaping\n",
    "        remove = int(X.shape[1] / 2)\n",
    "        temp_X = X[:, -remove:, :]\n",
    "        # flatten data\n",
    "        temp_X = temp_X.reshape((temp_X.shape[0] * temp_X.shape[1], temp_X.shape[2]))\n",
    "        scale = StandardScaler()\n",
    "        scale.fit(temp_X)\n",
    "        self.scale = scale\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale = scaling_tseries_data()\n",
    "Scale.fit(X_train)\n",
    "X_train_sc = Scale.transform(X_train)\n",
    "X_val_sc = Scale.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scaled X train (7352, 128, 9)\n",
      "Shape of scaled X test (2947, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of scaled X train',X_train_sc.shape)\n",
    "print('Shape of scaled X test',X_val_sc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 124, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                99250     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 103,556\n",
      "Trainable params: 103,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 6s 764us/step - loss: 0.4207 - acc: 0.8403 - val_loss: 0.3384 - val_acc: 0.8748\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 5s 685us/step - loss: 0.1448 - acc: 0.9411 - val_loss: 0.3163 - val_acc: 0.8799\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 5s 672us/step - loss: 0.1177 - acc: 0.9486 - val_loss: 0.2963 - val_acc: 0.9226\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 5s 686us/step - loss: 0.0912 - acc: 0.9566 - val_loss: 0.2926 - val_acc: 0.9097\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 5s 691us/step - loss: 0.0987 - acc: 0.9567 - val_loss: 0.3676 - val_acc: 0.9036\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 5s 678us/step - loss: 0.0841 - acc: 0.9619 - val_loss: 0.3184 - val_acc: 0.9036\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 5s 695us/step - loss: 0.0727 - acc: 0.9659 - val_loss: 0.3215 - val_acc: 0.9169\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 5s 671us/step - loss: 0.0827 - acc: 0.9630 - val_loss: 0.3346 - val_acc: 0.9199\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 5s 695us/step - loss: 0.0726 - acc: 0.9690 - val_loss: 0.3988 - val_acc: 0.8958\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 5s 678us/step - loss: 0.0724 - acc: 0.9694 - val_loss: 0.4881 - val_acc: 0.8948\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 5s 667us/step - loss: 0.0585 - acc: 0.9746 - val_loss: 0.3294 - val_acc: 0.9148\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 5s 669us/step - loss: 0.0529 - acc: 0.9767 - val_loss: 0.4145 - val_acc: 0.9074\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 5s 685us/step - loss: 0.0578 - acc: 0.9742 - val_loss: 0.4447 - val_acc: 0.9084\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 5s 689us/step - loss: 0.0559 - acc: 0.9751 - val_loss: 0.4771 - val_acc: 0.8935\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 5s 676us/step - loss: 0.0529 - acc: 0.9771 - val_loss: 0.4165 - val_acc: 0.9060\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 5s 663us/step - loss: 0.0498 - acc: 0.9785 - val_loss: 0.4710 - val_acc: 0.8979\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 5s 678us/step - loss: 0.0427 - acc: 0.9833 - val_loss: 0.4036 - val_acc: 0.9155\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 5s 675us/step - loss: 0.0397 - acc: 0.9841 - val_loss: 0.4978 - val_acc: 0.9141\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 5s 651us/step - loss: 0.0475 - acc: 0.9804 - val_loss: 0.4573 - val_acc: 0.9060\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 5s 699us/step - loss: 0.0378 - acc: 0.9831 - val_loss: 0.5176 - val_acc: 0.9111\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 5s 691us/step - loss: 0.0353 - acc: 0.9867 - val_loss: 0.5103 - val_acc: 0.9111\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 5s 692us/step - loss: 0.0427 - acc: 0.9827 - val_loss: 0.5969 - val_acc: 0.9148\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 5s 669us/step - loss: 0.0379 - acc: 0.9837 - val_loss: 0.6271 - val_acc: 0.9046\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 5s 674us/step - loss: 0.0331 - acc: 0.9871 - val_loss: 0.5575 - val_acc: 0.9152\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 5s 687us/step - loss: 0.0259 - acc: 0.9883 - val_loss: 0.5731 - val_acc: 0.9141\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 5s 695us/step - loss: 0.0530 - acc: 0.9834 - val_loss: 0.5450 - val_acc: 0.9186\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 5s 674us/step - loss: 0.0692 - acc: 0.9822 - val_loss: 0.5904 - val_acc: 0.9026\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 5s 676us/step - loss: 0.0664 - acc: 0.9849 - val_loss: 0.4807 - val_acc: 0.9250\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 5s 673us/step - loss: 0.0675 - acc: 0.9845 - val_loss: 0.5125 - val_acc: 0.9264\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 5s 671us/step - loss: 0.0531 - acc: 0.9897 - val_loss: 0.6342 - val_acc: 0.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14761b299ac8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sc,Y_train, epochs=30, batch_size=16,validation_data=(X_val_sc, Y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is giving some good score in train as well as test but it is overfitting so much. i will try some regularization in below models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2,l1\n",
    "import keras\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 124, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 62, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 992)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 32)                31776     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 34,422\n",
      "Trainable params: 34,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform',\n",
    "                 kernel_regularizer=l2(0.1),input_shape=(128,9)))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu',kernel_regularizer=l2(0.06),kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.65))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=0.001)\n",
    "def step_decay(epoch):\n",
    "    return float(0.001 * math.pow(0.6, math.floor((1+epoch)/10)))\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 6s 879us/step - loss: 4.3454 - acc: 0.7266 - val_loss: 1.5457 - val_acc: 0.7815\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 5s 676us/step - loss: 0.7579 - acc: 0.9121 - val_loss: 0.6360 - val_acc: 0.8935\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 5s 668us/step - loss: 0.3876 - acc: 0.9286 - val_loss: 0.5337 - val_acc: 0.8772\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 5s 673us/step - loss: 0.3123 - acc: 0.9283 - val_loss: 0.4940 - val_acc: 0.8673\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 5s 680us/step - loss: 0.2729 - acc: 0.9336 - val_loss: 0.4439 - val_acc: 0.8901\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 5s 676us/step - loss: 0.2629 - acc: 0.9327 - val_loss: 0.4330 - val_acc: 0.8775\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 5s 664us/step - loss: 0.2423 - acc: 0.9393 - val_loss: 0.4225 - val_acc: 0.8711\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 5s 681us/step - loss: 0.2327 - acc: 0.9380 - val_loss: 0.3889 - val_acc: 0.8992\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 5s 670us/step - loss: 0.2237 - acc: 0.9372 - val_loss: 0.3994 - val_acc: 0.8928\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 5s 687us/step - loss: 0.2221 - acc: 0.9377 - val_loss: 0.3850 - val_acc: 0.8880\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 5s 676us/step - loss: 0.2216 - acc: 0.9377 - val_loss: 0.4274 - val_acc: 0.8914\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 5s 684us/step - loss: 0.2085 - acc: 0.9416 - val_loss: 0.3917 - val_acc: 0.8887\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 5s 646us/step - loss: 0.2005 - acc: 0.9448 - val_loss: 0.3987 - val_acc: 0.8843\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 5s 687us/step - loss: 0.2075 - acc: 0.9446 - val_loss: 0.4501 - val_acc: 0.8337\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 5s 678us/step - loss: 0.1980 - acc: 0.9434 - val_loss: 0.3589 - val_acc: 0.8860\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 5s 696us/step - loss: 0.1891 - acc: 0.9449 - val_loss: 0.3954 - val_acc: 0.8931\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 5s 660us/step - loss: 0.1909 - acc: 0.9434 - val_loss: 0.4015 - val_acc: 0.8778\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 5s 689us/step - loss: 0.1893 - acc: 0.9429 - val_loss: 0.3641 - val_acc: 0.8853\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 5s 661us/step - loss: 0.2002 - acc: 0.9389 - val_loss: 0.4151 - val_acc: 0.8728\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 5s 664us/step - loss: 0.1817 - acc: 0.9486 - val_loss: 0.3662 - val_acc: 0.8768\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 5s 670us/step - loss: 0.1828 - acc: 0.9472 - val_loss: 0.3892 - val_acc: 0.8819\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 5s 661us/step - loss: 0.1851 - acc: 0.9449 - val_loss: 0.3684 - val_acc: 0.8907\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 5s 672us/step - loss: 0.1841 - acc: 0.9456 - val_loss: 0.3256 - val_acc: 0.8924\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 5s 674us/step - loss: 0.1777 - acc: 0.9463 - val_loss: 0.3316 - val_acc: 0.8816\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 5s 683us/step - loss: 0.1785 - acc: 0.9448 - val_loss: 0.4006 - val_acc: 0.8622\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 5s 678us/step - loss: 0.1751 - acc: 0.9459 - val_loss: 0.5416 - val_acc: 0.8493\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 5s 697us/step - loss: 0.1773 - acc: 0.9476 - val_loss: 0.3382 - val_acc: 0.8989\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 5s 672us/step - loss: 0.1692 - acc: 0.9506 - val_loss: 0.3668 - val_acc: 0.8826\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 5s 677us/step - loss: 0.1742 - acc: 0.9478 - val_loss: 0.3855 - val_acc: 0.8904\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 5s 679us/step - loss: 0.1754 - acc: 0.9467 - val_loss: 0.3478 - val_acc: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14757856a6d8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sc,Y_train, epochs=30, batch_size=16,validation_data=(X_val_sc, Y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tuning Using Hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scaled():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Data directory\n",
    "    DATADIR = 'UCI_HAR_Dataset'\n",
    "    # Raw data signals\n",
    "    # Signals are from Accelerometer and Gyroscope\n",
    "    # The signals are in x,y,z directions\n",
    "    # Sensor signals are filtered to have only body acceleration\n",
    "    # excluding the acceleration due to gravity\n",
    "    # Triaxial acceleration from the accelerometer is total acceleration\n",
    "    SIGNALS = [\n",
    "        \"body_acc_x\",\n",
    "        \"body_acc_y\",\n",
    "        \"body_acc_z\",\n",
    "        \"body_gyro_x\",\n",
    "        \"body_gyro_y\",\n",
    "        \"body_gyro_z\",\n",
    "        \"total_acc_x\",\n",
    "        \"total_acc_y\",\n",
    "        \"total_acc_z\"\n",
    "        ]\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    class scaling_tseries_data(BaseEstimator, TransformerMixin):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        def __init__(self):\n",
    "            self.scale = None\n",
    "\n",
    "        def transform(self, X):\n",
    "            temp_X1 = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
    "            temp_X1 = self.scale.transform(temp_X1)\n",
    "            return temp_X1.reshape(X.shape)\n",
    "\n",
    "        def fit(self, X):\n",
    "            # remove overlaping\n",
    "            remove = int(X.shape[1] / 2)\n",
    "            temp_X = X[:, -remove:, :]\n",
    "            # flatten data\n",
    "            temp_X = temp_X.reshape((temp_X.shape[0] * temp_X.shape[1], temp_X.shape[2]))\n",
    "            scale = StandardScaler()\n",
    "            scale.fit(temp_X)\n",
    "            self.scale = scale\n",
    "            return self\n",
    "        \n",
    "    # Utility function to read the data from csv file\n",
    "    def _read_csv(filename):\n",
    "        return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "    # Utility function to load the load\n",
    "    def load_signals(subset):\n",
    "        signals_data = []\n",
    "\n",
    "        for signal in SIGNALS:\n",
    "            filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "            signals_data.append( _read_csv(filename).as_matrix()) \n",
    "\n",
    "        # Transpose is used to change the dimensionality of the output,\n",
    "        # aggregating the signals by combination of sample/timestep.\n",
    "        # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "        return np.transpose(signals_data, (1, 2, 0))\n",
    "    \n",
    "    def load_y(subset):\n",
    "        \"\"\"\n",
    "        The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "        that represents a human activity. We return a binary representation of \n",
    "        every sample objective as a 6 bits vector using One Hot Encoding\n",
    "        (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "        \"\"\"\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "        y = _read_csv(filename)[0]\n",
    "        return pd.get_dummies(y).as_matrix()\n",
    "    \n",
    "    X_train, X_val = load_signals('train'), load_signals('test')\n",
    "    Y_train, Y_val = load_y('train'), load_y('test')\n",
    "    ###Scling data\n",
    "    Scale = scaling_tseries_data()\n",
    "    Scale.fit(X_train)\n",
    "    X_train = Scale.transform(X_train)\n",
    "    X_val = Scale.transform(X_val)\n",
    "\n",
    "    return X_train, Y_train, X_val,  Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val,  Y_val = data_scaled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn(X_train, Y_train, X_val, Y_val):\n",
    "    # Importing tensorflow\n",
    "    np.random.seed(36)\n",
    "    import tensorflow as tf\n",
    "    tf.set_random_seed(36)\n",
    "    # Initiliazing the sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters={{choice([28,32,42])}}, kernel_size={{choice([3,5,7])}},activation='relu',kernel_initializer='he_uniform',\n",
    "                 kernel_regularizer=l2({{uniform(0,2.5)}}),input_shape=(128,9)))\n",
    "    \n",
    "    model.add(Conv1D(filters={{choice([16,24,32])}}, kernel_size={{choice([3,5,7])}}, \n",
    "                     activation='relu',kernel_regularizer=l2({{uniform(0,1.5)}}),kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout({{uniform(0.45,0.7)}}))\n",
    "    model.add(MaxPooling1D(pool_size={{choice([2,3])}}))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense({{choice([32,64])}}, activation='relu'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "        \n",
    "    adam = keras.optimizers.Adam(lr={{uniform(0.00065,0.004)}})\n",
    "    rmsprop = keras.optimizers.RMSprop(lr={{uniform(0.00065,0.004)}})\n",
    "   \n",
    "    choiceval = {{choice(['adam', 'rmsprop'])}}\n",
    "    \n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    else:\n",
    "        optim = rmsprop\n",
    "    \n",
    "    print(model.summary())\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
    "    \n",
    "    result = model.fit(X_train, Y_train,\n",
    "              batch_size={{choice([16,32,64])}},\n",
    "              nb_epoch={{choice([25,30,35])}},\n",
    "              verbose=2,\n",
    "              validation_data=(X_val, Y_val))\n",
    "                       \n",
    "    score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    score1, acc1 = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    print('Train accuracy',acc1,'Test accuracy:', acc)\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model,'train_acc':acc1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random as rn\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pickle\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import pyplot\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.convolutional import Conv1D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.convolutional import MaxPooling1D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import to_categorical\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.base import BaseEstimator, TransformerMixin\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'filters': hp.choice('filters', [28,32,42]),\n",
      "        'kernel_size': hp.choice('kernel_size', [3,5,7]),\n",
      "        'l2': hp.uniform('l2', 0,2.5),\n",
      "        'filters_1': hp.choice('filters_1', [16,24,32]),\n",
      "        'kernel_size_1': hp.choice('kernel_size_1', [3,5,7]),\n",
      "        'l2_1': hp.uniform('l2_1', 0,1.5),\n",
      "        'Dropout': hp.uniform('Dropout', 0.45,0.7),\n",
      "        'pool_size': hp.choice('pool_size', [2,3]),\n",
      "        'Dense': hp.choice('Dense', [32,64]),\n",
      "        'lr': hp.uniform('lr', 0.00065,0.004),\n",
      "        'lr_1': hp.uniform('lr_1', 0.00065,0.004),\n",
      "        'choiceval': hp.choice('choiceval', ['adam', 'rmsprop']),\n",
      "        'batch_size': hp.choice('batch_size', [16,32,64]),\n",
      "        'nb_epoch': hp.choice('nb_epoch', [25,30,35]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: \"\"\"\n",
      "   3: Obtain the dataset from multiple files.\n",
      "   4: Returns: X_train, X_test, y_train, y_test\n",
      "   5: \"\"\"\n",
      "   6: # Data directory\n",
      "   7: DATADIR = 'UCI_HAR_Dataset'\n",
      "   8: # Raw data signals\n",
      "   9: # Signals are from Accelerometer and Gyroscope\n",
      "  10: # The signals are in x,y,z directions\n",
      "  11: # Sensor signals are filtered to have only body acceleration\n",
      "  12: # excluding the acceleration due to gravity\n",
      "  13: # Triaxial acceleration from the accelerometer is total acceleration\n",
      "  14: SIGNALS = [\n",
      "  15:     \"body_acc_x\",\n",
      "  16:     \"body_acc_y\",\n",
      "  17:     \"body_acc_z\",\n",
      "  18:     \"body_gyro_x\",\n",
      "  19:     \"body_gyro_y\",\n",
      "  20:     \"body_gyro_z\",\n",
      "  21:     \"total_acc_x\",\n",
      "  22:     \"total_acc_y\",\n",
      "  23:     \"total_acc_z\"\n",
      "  24:     ]\n",
      "  25: from sklearn.base import BaseEstimator, TransformerMixin\n",
      "  26: class scaling_tseries_data(BaseEstimator, TransformerMixin):\n",
      "  27:     from sklearn.preprocessing import StandardScaler\n",
      "  28:     def __init__(self):\n",
      "  29:         self.scale = None\n",
      "  30: \n",
      "  31:     def transform(self, X):\n",
      "  32:         temp_X1 = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
      "  33:         temp_X1 = self.scale.transform(temp_X1)\n",
      "  34:         return temp_X1.reshape(X.shape)\n",
      "  35: \n",
      "  36:     def fit(self, X):\n",
      "  37:         # remove overlaping\n",
      "  38:         remove = int(X.shape[1] / 2)\n",
      "  39:         temp_X = X[:, -remove:, :]\n",
      "  40:         # flatten data\n",
      "  41:         temp_X = temp_X.reshape((temp_X.shape[0] * temp_X.shape[1], temp_X.shape[2]))\n",
      "  42:         scale = StandardScaler()\n",
      "  43:         scale.fit(temp_X)\n",
      "  44:         self.scale = scale\n",
      "  45:         return self\n",
      "  46:     \n",
      "  47: # Utility function to read the data from csv file\n",
      "  48: def _read_csv(filename):\n",
      "  49:     return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "  50: \n",
      "  51: # Utility function to load the load\n",
      "  52: def load_signals(subset):\n",
      "  53:     signals_data = []\n",
      "  54: \n",
      "  55:     for signal in SIGNALS:\n",
      "  56:         filename = f'HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
      "  57:         signals_data.append( _read_csv(filename).as_matrix()) \n",
      "  58: \n",
      "  59:     # Transpose is used to change the dimensionality of the output,\n",
      "  60:     # aggregating the signals by combination of sample/timestep.\n",
      "  61:     # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
      "  62:     return np.transpose(signals_data, (1, 2, 0))\n",
      "  63: \n",
      "  64: def load_y(subset):\n",
      "  65:     \"\"\"\n",
      "  66:     The objective that we are trying to predict is a integer, from 1 to 6,\n",
      "  67:     that represents a human activity. We return a binary representation of \n",
      "  68:     every sample objective as a 6 bits vector using One Hot Encoding\n",
      "  69:     (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
      "  70:     \"\"\"\n",
      "  71:     filename = f'HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
      "  72:     y = _read_csv(filename)[0]\n",
      "  73:     return pd.get_dummies(y).as_matrix()\n",
      "  74: \n",
      "  75: X_train, X_val = load_signals('train'), load_signals('test')\n",
      "  76: Y_train, Y_val = load_y('train'), load_y('test')\n",
      "  77: ###Scling data\n",
      "  78: Scale = scaling_tseries_data()\n",
      "  79: Scale.fit(X_train)\n",
      "  80: X_train = Scale.transform(X_train)\n",
      "  81: X_val = Scale.transform(X_val)\n",
      "  82: \n",
      "  83: \n",
      "  84: \n",
      "  85: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     # Initiliazing the sequential model\n",
      "   4:     model = Sequential()\n",
      "   5:     \n",
      "   6:     model.add(Conv1D(filters=space['filters'], kernel_size=space['kernel_size'],activation='relu',kernel_initializer='he_uniform',\n",
      "   7:                  kernel_regularizer=l2(space['l2']),input_shape=(128,9)))\n",
      "   8:     \n",
      "   9:     model.add(Conv1D(filters=space['filters_1'], kernel_size=space['kernel_size_1'], \n",
      "  10:                      activation='relu',kernel_regularizer=l2(space['l2_1']),kernel_initializer='he_uniform'))\n",
      "  11:     model.add(Dropout(space['Dropout']))\n",
      "  12:     model.add(MaxPooling1D(pool_size=space['pool_size']))\n",
      "  13:     model.add(Flatten())\n",
      "  14:     model.add(Dense(space['Dense'], activation='relu'))\n",
      "  15:     model.add(Dense(6, activation='softmax'))\n",
      "  16:         \n",
      "  17:     adam = keras.optimizers.Adam(lr=space['lr'])\n",
      "  18:     rmsprop = keras.optimizers.RMSprop(lr=space['lr_1'])\n",
      "  19:    \n",
      "  20:     choiceval = space['choiceval']\n",
      "  21:     \n",
      "  22:     if choiceval == 'adam':\n",
      "  23:         optim = adam\n",
      "  24:     else:\n",
      "  25:         optim = rmsprop\n",
      "  26:     \n",
      "  27:     print(model.summary())\n",
      "  28:         \n",
      "  29:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
      "  30:     \n",
      "  31:     result = model.fit(X_train, Y_train,\n",
      "  32:               batch_size=space['batch_size'],\n",
      "  33:               nb_epoch=space['nb_epoch'],\n",
      "  34:               verbose=2,\n",
      "  35:               validation_data=(X_val, Y_val))\n",
      "  36:                        \n",
      "  37:     score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
      "  38:     score1, acc1 = model.evaluate(X_train, Y_train, verbose=0)\n",
      "  39:     print('Train accuracy',acc1,'Test accuracy:', acc)\n",
      "  40:     print('-------------------------------------------------------------------------------------')\n",
      "  41:     return {'loss': -acc, 'status': STATUS_OK, 'model': model,'train_acc':acc1}\n",
      "  42: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 118, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 59, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1416)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                90688     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 97,950\n",
      "Trainable params: 97,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 3s - loss: 45.3420 - acc: 0.7704 - val_loss: 3.6639 - val_acc: 0.7991\n",
      "Epoch 2/30\n",
      " - 3s - loss: 1.2333 - acc: 0.8358 - val_loss: 0.7950 - val_acc: 0.8205\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.5870 - acc: 0.8638 - val_loss: 0.8045 - val_acc: 0.7984\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.5209 - acc: 0.8730 - val_loss: 0.6645 - val_acc: 0.8568\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.4995 - acc: 0.8732 - val_loss: 0.6564 - val_acc: 0.8392\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.4606 - acc: 0.8889 - val_loss: 0.6165 - val_acc: 0.8337\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.4613 - acc: 0.8870 - val_loss: 0.6127 - val_acc: 0.8473\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.4429 - acc: 0.8902 - val_loss: 0.6595 - val_acc: 0.8015\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.4288 - acc: 0.8932 - val_loss: 0.6231 - val_acc: 0.8415\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.3960 - acc: 0.9019 - val_loss: 0.5389 - val_acc: 0.8744\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.3759 - acc: 0.9055 - val_loss: 0.5346 - val_acc: 0.8670\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.3689 - acc: 0.9091 - val_loss: 0.6860 - val_acc: 0.8093\n",
      "Epoch 13/30\n",
      " - 3s - loss: 0.3888 - acc: 0.9027 - val_loss: 0.5244 - val_acc: 0.8571\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.3829 - acc: 0.9071 - val_loss: 0.4928 - val_acc: 0.8636\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.3538 - acc: 0.9127 - val_loss: 0.5904 - val_acc: 0.8144\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.3931 - acc: 0.8998 - val_loss: 0.5092 - val_acc: 0.8432\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.3480 - acc: 0.9117 - val_loss: 0.5083 - val_acc: 0.8551\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.3612 - acc: 0.9079 - val_loss: 0.5626 - val_acc: 0.8537\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.4131 - acc: 0.8972 - val_loss: 0.4857 - val_acc: 0.8554\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.3518 - acc: 0.9115 - val_loss: 0.4884 - val_acc: 0.8717\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.3645 - acc: 0.9132 - val_loss: 0.5522 - val_acc: 0.8334\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.3398 - acc: 0.9155 - val_loss: 0.5387 - val_acc: 0.8439\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.3558 - acc: 0.9108 - val_loss: 0.5040 - val_acc: 0.8663\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.3462 - acc: 0.9149 - val_loss: 0.4547 - val_acc: 0.8673\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.3410 - acc: 0.9134 - val_loss: 0.4967 - val_acc: 0.8371\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.3301 - acc: 0.9170 - val_loss: 0.5228 - val_acc: 0.8215\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.3193 - acc: 0.9168 - val_loss: 0.4587 - val_acc: 0.8734\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.3374 - acc: 0.9157 - val_loss: 0.4538 - val_acc: 0.8531\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.3182 - acc: 0.9155 - val_loss: 0.5331 - val_acc: 0.8327\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.3405 - acc: 0.9136 - val_loss: 0.5148 - val_acc: 0.8636\n",
      "Train accuracy 0.9110446137105549 Test accuracy: 0.8635900916185952\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 126, 28)           784       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 122, 24)           3384      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 122, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 61, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1464)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                46880     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 51,246\n",
      "Trainable params: 51,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 3s - loss: 5.0640 - acc: 0.6525 - val_loss: 0.8492 - val_acc: 0.7553\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.6052 - acc: 0.8453 - val_loss: 1.3102 - val_acc: 0.6607\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4757 - acc: 0.8845 - val_loss: 0.8982 - val_acc: 0.7129\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.4345 - acc: 0.8940 - val_loss: 0.5309 - val_acc: 0.8582\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.3960 - acc: 0.9042 - val_loss: 0.5224 - val_acc: 0.8629\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.3763 - acc: 0.9098 - val_loss: 0.5749 - val_acc: 0.8242\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.3645 - acc: 0.9100 - val_loss: 1.2467 - val_acc: 0.6240\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.3542 - acc: 0.9115 - val_loss: 0.4757 - val_acc: 0.8833\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.3406 - acc: 0.9162 - val_loss: 0.9492 - val_acc: 0.6943\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.3411 - acc: 0.9163 - val_loss: 0.4281 - val_acc: 0.8823\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.3302 - acc: 0.9210 - val_loss: 0.4763 - val_acc: 0.8504\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.3207 - acc: 0.9207 - val_loss: 0.4172 - val_acc: 0.8697\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.3269 - acc: 0.9155 - val_loss: 0.9915 - val_acc: 0.6753\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.3198 - acc: 0.9200 - val_loss: 0.4152 - val_acc: 0.8812\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.3044 - acc: 0.9219 - val_loss: 0.4032 - val_acc: 0.8768\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.3100 - acc: 0.9178 - val_loss: 0.9914 - val_acc: 0.6987\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.3146 - acc: 0.9165 - val_loss: 0.3897 - val_acc: 0.8850\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.3010 - acc: 0.9215 - val_loss: 0.4310 - val_acc: 0.8758\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.3029 - acc: 0.9184 - val_loss: 0.4385 - val_acc: 0.8789\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.2992 - acc: 0.9215 - val_loss: 0.4209 - val_acc: 0.8636\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.2943 - acc: 0.9203 - val_loss: 0.3879 - val_acc: 0.8758\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.2984 - acc: 0.9188 - val_loss: 0.4348 - val_acc: 0.8554\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.3077 - acc: 0.9202 - val_loss: 0.4411 - val_acc: 0.8422\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.2890 - acc: 0.9226 - val_loss: 0.4017 - val_acc: 0.8602\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.3037 - acc: 0.9211 - val_loss: 0.4872 - val_acc: 0.8354\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3116 - acc: 0.9178 - val_loss: 0.4148 - val_acc: 0.8612\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.2944 - acc: 0.9252 - val_loss: 0.4787 - val_acc: 0.8368\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.2845 - acc: 0.9245 - val_loss: 0.5676 - val_acc: 0.8239\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2987 - acc: 0.9232 - val_loss: 0.4795 - val_acc: 0.8602\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2844 - acc: 0.9251 - val_loss: 0.5168 - val_acc: 0.8442\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.3031 - acc: 0.9249 - val_loss: 0.4025 - val_acc: 0.8809\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2885 - acc: 0.9251 - val_loss: 0.3978 - val_acc: 0.8823\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2911 - acc: 0.9218 - val_loss: 0.6231 - val_acc: 0.8022\n",
      "Epoch 34/35\n",
      " - 3s - loss: 0.2916 - acc: 0.9226 - val_loss: 1.4996 - val_acc: 0.6542\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.3018 - acc: 0.9268 - val_loss: 0.5221 - val_acc: 0.8578\n",
      "Train accuracy 0.941240478781284 Test accuracy: 0.8578215134034611\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 122, 28)           1792      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 118, 32)           4512      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 118, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 39, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1248)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                79936     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 86,630\n",
      "Trainable params: 86,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 3s - loss: 21.3175 - acc: 0.7323 - val_loss: 0.8292 - val_acc: 0.8157\n",
      "Epoch 2/35\n",
      " - 3s - loss: 0.5440 - acc: 0.8694 - val_loss: 0.8706 - val_acc: 0.7370\n",
      "Epoch 3/35\n",
      " - 3s - loss: 0.4467 - acc: 0.8900 - val_loss: 0.6157 - val_acc: 0.7805\n",
      "Epoch 4/35\n",
      " - 3s - loss: 0.4128 - acc: 0.8957 - val_loss: 0.5928 - val_acc: 0.8124\n",
      "Epoch 5/35\n",
      " - 3s - loss: 0.3966 - acc: 0.9017 - val_loss: 0.5419 - val_acc: 0.8721\n",
      "Epoch 6/35\n",
      " - 3s - loss: 0.3660 - acc: 0.9060 - val_loss: 0.4645 - val_acc: 0.8717\n",
      "Epoch 7/35\n",
      " - 3s - loss: 0.3549 - acc: 0.9112 - val_loss: 0.4408 - val_acc: 0.8863\n",
      "Epoch 8/35\n",
      " - 3s - loss: 0.3403 - acc: 0.9138 - val_loss: 0.4832 - val_acc: 0.8599\n",
      "Epoch 9/35\n",
      " - 3s - loss: 0.3311 - acc: 0.9185 - val_loss: 0.4378 - val_acc: 0.8636\n",
      "Epoch 10/35\n",
      " - 3s - loss: 0.3359 - acc: 0.9146 - val_loss: 0.4415 - val_acc: 0.8931\n",
      "Epoch 11/35\n",
      " - 3s - loss: 0.3241 - acc: 0.9173 - val_loss: 0.4128 - val_acc: 0.8890\n",
      "Epoch 12/35\n",
      " - 3s - loss: 0.3287 - acc: 0.9142 - val_loss: 0.4476 - val_acc: 0.8778\n",
      "Epoch 13/35\n",
      " - 3s - loss: 0.3242 - acc: 0.9144 - val_loss: 0.4104 - val_acc: 0.8965\n",
      "Epoch 14/35\n",
      " - 3s - loss: 0.3155 - acc: 0.9193 - val_loss: 0.4258 - val_acc: 0.8846\n",
      "Epoch 15/35\n",
      " - 3s - loss: 0.3211 - acc: 0.9191 - val_loss: 0.4041 - val_acc: 0.8856\n",
      "Epoch 16/35\n",
      " - 3s - loss: 0.3082 - acc: 0.9170 - val_loss: 0.5309 - val_acc: 0.8575\n",
      "Epoch 17/35\n",
      " - 3s - loss: 0.3101 - acc: 0.9188 - val_loss: 0.4276 - val_acc: 0.8935\n",
      "Epoch 18/35\n",
      " - 3s - loss: 0.3127 - acc: 0.9188 - val_loss: 0.4314 - val_acc: 0.8968\n",
      "Epoch 19/35\n",
      " - 3s - loss: 0.3093 - acc: 0.9206 - val_loss: 0.4253 - val_acc: 0.8782\n",
      "Epoch 20/35\n",
      " - 3s - loss: 0.2990 - acc: 0.9212 - val_loss: 0.5731 - val_acc: 0.8310\n",
      "Epoch 21/35\n",
      " - 3s - loss: 0.3052 - acc: 0.9193 - val_loss: 0.3815 - val_acc: 0.8982\n",
      "Epoch 22/35\n",
      " - 3s - loss: 0.3042 - acc: 0.9169 - val_loss: 0.4525 - val_acc: 0.8558\n",
      "Epoch 23/35\n",
      " - 3s - loss: 0.3085 - acc: 0.9178 - val_loss: 0.3837 - val_acc: 0.8935\n",
      "Epoch 24/35\n",
      " - 3s - loss: 0.2984 - acc: 0.9210 - val_loss: 0.4201 - val_acc: 0.8826\n",
      "Epoch 25/35\n",
      " - 3s - loss: 0.2980 - acc: 0.9237 - val_loss: 0.4196 - val_acc: 0.8911\n",
      "Epoch 26/35\n",
      " - 3s - loss: 0.2898 - acc: 0.9185 - val_loss: 0.4015 - val_acc: 0.8782\n",
      "Epoch 27/35\n",
      " - 3s - loss: 0.2882 - acc: 0.9200 - val_loss: 1.0529 - val_acc: 0.6569\n",
      "Epoch 28/35\n",
      " - 3s - loss: 0.3073 - acc: 0.9211 - val_loss: 0.5184 - val_acc: 0.8249\n",
      "Epoch 29/35\n",
      " - 3s - loss: 0.2951 - acc: 0.9180 - val_loss: 0.3777 - val_acc: 0.8972\n",
      "Epoch 30/35\n",
      " - 3s - loss: 0.2878 - acc: 0.9236 - val_loss: 0.4222 - val_acc: 0.8870\n",
      "Epoch 31/35\n",
      " - 3s - loss: 0.2895 - acc: 0.9230 - val_loss: 0.3646 - val_acc: 0.8928\n",
      "Epoch 32/35\n",
      " - 3s - loss: 0.2946 - acc: 0.9177 - val_loss: 0.4072 - val_acc: 0.8700\n",
      "Epoch 33/35\n",
      " - 3s - loss: 0.2943 - acc: 0.9222 - val_loss: 0.4008 - val_acc: 0.8653\n",
      "Epoch 34/35\n",
      " - 3s - loss: 0.2857 - acc: 0.9232 - val_loss: 0.4046 - val_acc: 0.8873\n",
      "Epoch 35/35\n",
      " - 3s - loss: 0.2878 - acc: 0.9210 - val_loss: 0.4164 - val_acc: 0.8697\n",
      "Train accuracy 0.9110446137105549 Test accuracy: 0.8696979979640312\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 120, 24)           2328      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,270\n",
      "Trainable params: 66,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 4s - loss: 27.7956 - acc: 0.6970 - val_loss: 0.9407 - val_acc: 0.8090\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.7369 - acc: 0.7890 - val_loss: 0.8387 - val_acc: 0.7486\n",
      "Epoch 3/30\n",
      " - 4s - loss: 0.6319 - acc: 0.8303 - val_loss: 0.7569 - val_acc: 0.8324\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.5590 - acc: 0.8555 - val_loss: 0.6682 - val_acc: 0.8683\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.5298 - acc: 0.8640 - val_loss: 0.6922 - val_acc: 0.8263\n",
      "Epoch 6/30\n",
      " - 4s - loss: 0.5146 - acc: 0.8678 - val_loss: 0.7644 - val_acc: 0.7190\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.4868 - acc: 0.8798 - val_loss: 0.5707 - val_acc: 0.8626\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.4804 - acc: 0.8774 - val_loss: 0.6694 - val_acc: 0.8256\n",
      "Epoch 9/30\n",
      " - 4s - loss: 0.4777 - acc: 0.8811 - val_loss: 0.9647 - val_acc: 0.6434\n",
      "Epoch 10/30\n",
      " - 4s - loss: 0.4602 - acc: 0.8878 - val_loss: 0.9447 - val_acc: 0.6854\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.4603 - acc: 0.8822 - val_loss: 0.6184 - val_acc: 0.8426\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.4482 - acc: 0.8928 - val_loss: 0.5112 - val_acc: 0.8792\n",
      "Epoch 13/30\n",
      " - 4s - loss: 0.4455 - acc: 0.8870 - val_loss: 0.5271 - val_acc: 0.8534\n",
      "Epoch 14/30\n",
      " - 4s - loss: 0.4454 - acc: 0.8897 - val_loss: 0.4992 - val_acc: 0.8646\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.4389 - acc: 0.8902 - val_loss: 0.6000 - val_acc: 0.8541\n",
      "Epoch 16/30\n",
      " - 4s - loss: 0.4299 - acc: 0.8913 - val_loss: 0.5878 - val_acc: 0.8534\n",
      "Epoch 17/30\n",
      " - 4s - loss: 0.4258 - acc: 0.8945 - val_loss: 0.4728 - val_acc: 0.8704\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.4263 - acc: 0.8921 - val_loss: 0.6675 - val_acc: 0.7991\n",
      "Epoch 19/30\n",
      " - 4s - loss: 0.4179 - acc: 0.8919 - val_loss: 0.6103 - val_acc: 0.7957\n",
      "Epoch 20/30\n",
      " - 4s - loss: 0.4225 - acc: 0.8962 - val_loss: 0.7398 - val_acc: 0.7591\n",
      "Epoch 21/30\n",
      " - 4s - loss: 0.4227 - acc: 0.8935 - val_loss: 0.9899 - val_acc: 0.6688\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.4179 - acc: 0.8953 - val_loss: 0.8645 - val_acc: 0.6325\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.4091 - acc: 0.8942 - val_loss: 0.9141 - val_acc: 0.7170\n",
      "Epoch 24/30\n",
      " - 4s - loss: 0.4173 - acc: 0.8913 - val_loss: 0.6336 - val_acc: 0.7781\n",
      "Epoch 25/30\n",
      " - 3s - loss: 0.4212 - acc: 0.8923 - val_loss: 0.7610 - val_acc: 0.7631\n",
      "Epoch 26/30\n",
      " - 4s - loss: 0.4149 - acc: 0.8947 - val_loss: 0.5665 - val_acc: 0.8463\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.4025 - acc: 0.8979 - val_loss: 0.8253 - val_acc: 0.7645\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.3960 - acc: 0.8993 - val_loss: 1.1675 - val_acc: 0.6909\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.4050 - acc: 0.8980 - val_loss: 0.9959 - val_acc: 0.5694\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.3913 - acc: 0.8964 - val_loss: 0.5740 - val_acc: 0.8079\n",
      "Train accuracy 0.9038356909035858 Test accuracy: 0.8079402782490669\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 120, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                30752     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,246\n",
      "Trainable params: 37,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 3s - loss: 13.6495 - acc: 0.6700 - val_loss: 2.2101 - val_acc: 0.7024\n",
      "Epoch 2/25\n",
      " - 2s - loss: 0.9645 - acc: 0.8139 - val_loss: 0.7633 - val_acc: 0.8076\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.5302 - acc: 0.8664 - val_loss: 0.6662 - val_acc: 0.8015\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.4578 - acc: 0.8852 - val_loss: 0.5661 - val_acc: 0.8782\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.4317 - acc: 0.8848 - val_loss: 0.5911 - val_acc: 0.8442\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.4064 - acc: 0.8947 - val_loss: 0.4967 - val_acc: 0.8809\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.3851 - acc: 0.8973 - val_loss: 0.5429 - val_acc: 0.8578\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3750 - acc: 0.8991 - val_loss: 0.5994 - val_acc: 0.8015\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.3684 - acc: 0.9007 - val_loss: 0.4789 - val_acc: 0.8609\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.3561 - acc: 0.9013 - val_loss: 0.5707 - val_acc: 0.8585\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.3543 - acc: 0.9056 - val_loss: 0.4566 - val_acc: 0.8836\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.3396 - acc: 0.9055 - val_loss: 0.4830 - val_acc: 0.8656\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.3503 - acc: 0.9074 - val_loss: 0.4316 - val_acc: 0.8795\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.3309 - acc: 0.9068 - val_loss: 0.4449 - val_acc: 0.8802\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.3322 - acc: 0.9125 - val_loss: 0.4143 - val_acc: 0.8924\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.3220 - acc: 0.9149 - val_loss: 0.4309 - val_acc: 0.8734\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.3141 - acc: 0.9187 - val_loss: 0.4351 - val_acc: 0.8724\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.3185 - acc: 0.9168 - val_loss: 0.4605 - val_acc: 0.8819\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.3022 - acc: 0.9191 - val_loss: 0.4243 - val_acc: 0.8972\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.3184 - acc: 0.9191 - val_loss: 0.4000 - val_acc: 0.8901\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.3062 - acc: 0.9192 - val_loss: 0.4130 - val_acc: 0.8972\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.3039 - acc: 0.9199 - val_loss: 0.4041 - val_acc: 0.8839\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2902 - acc: 0.9237 - val_loss: 0.4928 - val_acc: 0.8347\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.3003 - acc: 0.9222 - val_loss: 0.4102 - val_acc: 0.8856\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2946 - acc: 0.9195 - val_loss: 0.4074 - val_acc: 0.8680\n",
      "Train accuracy 0.9387921653971708 Test accuracy: 0.8680013573125213\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_11 (Conv1D)           (None, 124, 42)           1932      \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 118, 16)           4720      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 59, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 944)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                30240     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,090\n",
      "Trainable params: 37,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 2s - loss: 25.2198 - acc: 0.5997 - val_loss: 1.3637 - val_acc: 0.6871\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.9933 - acc: 0.7115 - val_loss: 0.9844 - val_acc: 0.7628\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.7523 - acc: 0.7973 - val_loss: 0.8828 - val_acc: 0.7163\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.6736 - acc: 0.8230 - val_loss: 0.8566 - val_acc: 0.7197\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.6361 - acc: 0.8368 - val_loss: 0.7387 - val_acc: 0.7947\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.5801 - acc: 0.8526 - val_loss: 0.6935 - val_acc: 0.8174\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.5439 - acc: 0.8656 - val_loss: 0.6103 - val_acc: 0.8524\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.5533 - acc: 0.8659 - val_loss: 0.6724 - val_acc: 0.8185\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.5151 - acc: 0.8731 - val_loss: 0.7260 - val_acc: 0.8344\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.4970 - acc: 0.8762 - val_loss: 0.5632 - val_acc: 0.8839\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.4946 - acc: 0.8803 - val_loss: 0.7838 - val_acc: 0.7431\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.4858 - acc: 0.8803 - val_loss: 0.5702 - val_acc: 0.8890\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.4654 - acc: 0.8853 - val_loss: 0.5218 - val_acc: 0.8806\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.4581 - acc: 0.8875 - val_loss: 0.5284 - val_acc: 0.8463\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.4683 - acc: 0.8841 - val_loss: 0.5082 - val_acc: 0.8823\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.4459 - acc: 0.8939 - val_loss: 0.4947 - val_acc: 0.8704\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.4483 - acc: 0.8871 - val_loss: 0.6061 - val_acc: 0.8473\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.4473 - acc: 0.8938 - val_loss: 0.5074 - val_acc: 0.8622\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.4354 - acc: 0.8936 - val_loss: 0.4657 - val_acc: 0.8836\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.4473 - acc: 0.8946 - val_loss: 0.5476 - val_acc: 0.8195\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.4366 - acc: 0.8938 - val_loss: 1.3489 - val_acc: 0.5935\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.4414 - acc: 0.8930 - val_loss: 0.5112 - val_acc: 0.8677\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.4413 - acc: 0.8924 - val_loss: 0.4837 - val_acc: 0.8704\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.4361 - acc: 0.8912 - val_loss: 0.5776 - val_acc: 0.8337\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.4351 - acc: 0.8919 - val_loss: 0.5578 - val_acc: 0.8517\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.4286 - acc: 0.8946 - val_loss: 0.4881 - val_acc: 0.8809\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.4097 - acc: 0.9023 - val_loss: 0.4758 - val_acc: 0.8616\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.4181 - acc: 0.8999 - val_loss: 0.5165 - val_acc: 0.8565\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.4073 - acc: 0.9023 - val_loss: 0.7345 - val_acc: 0.7662\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.4152 - acc: 0.8996 - val_loss: 0.4742 - val_acc: 0.8673\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.4051 - acc: 0.9022 - val_loss: 0.5644 - val_acc: 0.8537\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.4050 - acc: 0.9025 - val_loss: 0.4509 - val_acc: 0.8748\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.4093 - acc: 0.9032 - val_loss: 0.7338 - val_acc: 0.7822\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.4097 - acc: 0.8976 - val_loss: 0.8234 - val_acc: 0.7248\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.4103 - acc: 0.9013 - val_loss: 0.6074 - val_acc: 0.8290\n",
      "Train accuracy 0.8925462459194777 Test accuracy: 0.828978622327791\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 120, 24)           3048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 67,630\n",
      "Trainable params: 67,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 3s - loss: 25.9652 - acc: 0.7650 - val_loss: 1.0548 - val_acc: 0.6362\n",
      "Epoch 2/25\n",
      " - 2s - loss: 0.5701 - acc: 0.8569 - val_loss: 0.6099 - val_acc: 0.8700\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.4239 - acc: 0.8919 - val_loss: 0.6441 - val_acc: 0.8093\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.3803 - acc: 0.9021 - val_loss: 0.4727 - val_acc: 0.9013\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.3610 - acc: 0.9045 - val_loss: 0.5091 - val_acc: 0.8612\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3496 - acc: 0.9104 - val_loss: 0.4285 - val_acc: 0.9006\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.3377 - acc: 0.9121 - val_loss: 0.4248 - val_acc: 0.8877\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3349 - acc: 0.9142 - val_loss: 0.4144 - val_acc: 0.8816\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.3324 - acc: 0.9132 - val_loss: 0.4128 - val_acc: 0.8972\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.3209 - acc: 0.9168 - val_loss: 0.4122 - val_acc: 0.8975\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.3224 - acc: 0.9169 - val_loss: 0.4426 - val_acc: 0.8860\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.3195 - acc: 0.9154 - val_loss: 0.4198 - val_acc: 0.8897\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.3098 - acc: 0.9129 - val_loss: 0.4413 - val_acc: 0.8731\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.3108 - acc: 0.9163 - val_loss: 0.7179 - val_acc: 0.7078\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.3072 - acc: 0.9165 - val_loss: 0.6628 - val_acc: 0.7523\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.3074 - acc: 0.9188 - val_loss: 0.4272 - val_acc: 0.8602\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.3041 - acc: 0.9177 - val_loss: 0.3638 - val_acc: 0.8999\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2989 - acc: 0.9195 - val_loss: 0.3717 - val_acc: 0.8951\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.3021 - acc: 0.9207 - val_loss: 0.4031 - val_acc: 0.8802\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2961 - acc: 0.9223 - val_loss: 0.4189 - val_acc: 0.8833\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2964 - acc: 0.9189 - val_loss: 0.4126 - val_acc: 0.8856\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2916 - acc: 0.9221 - val_loss: 0.4405 - val_acc: 0.8616\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2979 - acc: 0.9204 - val_loss: 0.5049 - val_acc: 0.8219\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2910 - acc: 0.9233 - val_loss: 0.4327 - val_acc: 0.8622\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2908 - acc: 0.9208 - val_loss: 0.3847 - val_acc: 0.9033\n",
      "Train accuracy 0.9319912948208873 Test accuracy: 0.9032914828639295\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 122, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 122, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 61, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 976)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                31264     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 34,486\n",
      "Trainable params: 34,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 8s - loss: 12.3182 - acc: 0.7433 - val_loss: 0.9290 - val_acc: 0.7886\n",
      "Epoch 2/30\n",
      " - 7s - loss: 0.6339 - acc: 0.8519 - val_loss: 0.7639 - val_acc: 0.8473\n",
      "Epoch 3/30\n",
      " - 6s - loss: 0.5438 - acc: 0.8746 - val_loss: 0.8724 - val_acc: 0.7408\n",
      "Epoch 4/30\n",
      " - 7s - loss: 0.4897 - acc: 0.8864 - val_loss: 0.6148 - val_acc: 0.8666\n",
      "Epoch 5/30\n",
      " - 7s - loss: 0.4750 - acc: 0.8842 - val_loss: 0.6477 - val_acc: 0.8633\n",
      "Epoch 6/30\n",
      " - 7s - loss: 0.4304 - acc: 0.8942 - val_loss: 0.6484 - val_acc: 0.8246\n",
      "Epoch 7/30\n",
      " - 6s - loss: 0.4311 - acc: 0.8953 - val_loss: 0.5412 - val_acc: 0.8683\n",
      "Epoch 8/30\n",
      " - 7s - loss: 0.4064 - acc: 0.9008 - val_loss: 0.6210 - val_acc: 0.8449\n",
      "Epoch 9/30\n",
      " - 6s - loss: 0.3902 - acc: 0.9034 - val_loss: 0.5972 - val_acc: 0.8741\n",
      "Epoch 10/30\n",
      " - 7s - loss: 0.3913 - acc: 0.9042 - val_loss: 0.5147 - val_acc: 0.8772\n",
      "Epoch 11/30\n",
      " - 7s - loss: 0.3697 - acc: 0.9095 - val_loss: 0.5122 - val_acc: 0.8724\n",
      "Epoch 12/30\n",
      " - 7s - loss: 0.3836 - acc: 0.9055 - val_loss: 0.5635 - val_acc: 0.8666\n",
      "Epoch 13/30\n",
      " - 7s - loss: 0.3538 - acc: 0.9143 - val_loss: 0.4843 - val_acc: 0.8833\n",
      "Epoch 14/30\n",
      " - 6s - loss: 0.3529 - acc: 0.9140 - val_loss: 0.5295 - val_acc: 0.8690\n",
      "Epoch 15/30\n",
      " - 7s - loss: 0.3402 - acc: 0.9184 - val_loss: 0.5248 - val_acc: 0.8629\n",
      "Epoch 16/30\n",
      " - 6s - loss: 0.3382 - acc: 0.9211 - val_loss: 0.5409 - val_acc: 0.8711\n",
      "Epoch 17/30\n",
      " - 7s - loss: 0.3530 - acc: 0.9180 - val_loss: 0.5157 - val_acc: 0.8935\n",
      "Epoch 18/30\n",
      " - 6s - loss: 0.3384 - acc: 0.9184 - val_loss: 0.4540 - val_acc: 0.8918\n",
      "Epoch 19/30\n",
      " - 7s - loss: 0.3258 - acc: 0.9189 - val_loss: 0.4588 - val_acc: 0.8850\n",
      "Epoch 20/30\n",
      " - 6s - loss: 0.3192 - acc: 0.9249 - val_loss: 0.4826 - val_acc: 0.8877\n",
      "Epoch 21/30\n",
      " - 7s - loss: 0.3297 - acc: 0.9183 - val_loss: 0.4209 - val_acc: 0.8890\n",
      "Epoch 22/30\n",
      " - 7s - loss: 0.3232 - acc: 0.9204 - val_loss: 0.4155 - val_acc: 0.8833\n",
      "Epoch 23/30\n",
      " - 6s - loss: 0.3227 - acc: 0.9183 - val_loss: 0.4771 - val_acc: 0.8785\n",
      "Epoch 24/30\n",
      " - 7s - loss: 0.3509 - acc: 0.9119 - val_loss: 0.5136 - val_acc: 0.8812\n",
      "Epoch 25/30\n",
      " - 6s - loss: 0.3007 - acc: 0.9271 - val_loss: 0.4932 - val_acc: 0.8945\n",
      "Epoch 26/30\n",
      " - 7s - loss: 0.3218 - acc: 0.9207 - val_loss: 0.4610 - val_acc: 0.8951\n",
      "Epoch 27/30\n",
      " - 7s - loss: 0.3024 - acc: 0.9229 - val_loss: 0.3987 - val_acc: 0.9030\n",
      "Epoch 28/30\n",
      " - 7s - loss: 0.2932 - acc: 0.9274 - val_loss: 0.4091 - val_acc: 0.8890\n",
      "Epoch 29/30\n",
      " - 6s - loss: 0.3257 - acc: 0.9189 - val_loss: 0.4050 - val_acc: 0.9016\n",
      "Epoch 30/30\n",
      " - 7s - loss: 0.3058 - acc: 0.9195 - val_loss: 0.4308 - val_acc: 0.8890\n",
      "Train accuracy 0.9315832426550599 Test accuracy: 0.8890397013912453\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_17 (Conv1D)           (None, 126, 42)           1176      \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 122, 32)           6752      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 122, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 61, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1952)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                62496     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 70,622\n",
      "Trainable params: 70,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 5s - loss: 15.4657 - acc: 0.6742 - val_loss: 0.8693 - val_acc: 0.7472\n",
      "Epoch 2/35\n",
      " - 4s - loss: 0.7068 - acc: 0.7807 - val_loss: 0.8246 - val_acc: 0.7214\n",
      "Epoch 3/35\n",
      " - 4s - loss: 0.6686 - acc: 0.7942 - val_loss: 0.7972 - val_acc: 0.7917\n",
      "Epoch 4/35\n",
      " - 4s - loss: 0.6442 - acc: 0.8092 - val_loss: 0.7068 - val_acc: 0.8307\n",
      "Epoch 5/35\n",
      " - 4s - loss: 0.6183 - acc: 0.8218 - val_loss: 0.8885 - val_acc: 0.6980\n",
      "Epoch 6/35\n",
      " - 4s - loss: 0.5963 - acc: 0.8324 - val_loss: 0.7499 - val_acc: 0.8056\n",
      "Epoch 7/35\n",
      " - 4s - loss: 0.5940 - acc: 0.8364 - val_loss: 0.6955 - val_acc: 0.8395\n",
      "Epoch 8/35\n",
      " - 4s - loss: 0.5829 - acc: 0.8409 - val_loss: 0.6824 - val_acc: 0.8276\n",
      "Epoch 9/35\n",
      " - 4s - loss: 0.5757 - acc: 0.8448 - val_loss: 0.7829 - val_acc: 0.8107\n",
      "Epoch 10/35\n",
      " - 4s - loss: 0.5558 - acc: 0.8481 - val_loss: 0.7201 - val_acc: 0.8144\n",
      "Epoch 11/35\n",
      " - 4s - loss: 0.5525 - acc: 0.8554 - val_loss: 0.7835 - val_acc: 0.8025\n",
      "Epoch 12/35\n",
      " - 4s - loss: 0.5384 - acc: 0.8592 - val_loss: 0.9675 - val_acc: 0.6807\n",
      "Epoch 13/35\n",
      " - 4s - loss: 0.5349 - acc: 0.8625 - val_loss: 0.6919 - val_acc: 0.8432\n",
      "Epoch 14/35\n",
      " - 4s - loss: 0.5206 - acc: 0.8689 - val_loss: 0.7597 - val_acc: 0.7995\n",
      "Epoch 15/35\n",
      " - 4s - loss: 0.5238 - acc: 0.8677 - val_loss: 0.7964 - val_acc: 0.8015\n",
      "Epoch 16/35\n",
      " - 4s - loss: 0.5120 - acc: 0.8655 - val_loss: 0.8578 - val_acc: 0.7106\n",
      "Epoch 17/35\n",
      " - 4s - loss: 0.5068 - acc: 0.8723 - val_loss: 0.7589 - val_acc: 0.8100\n",
      "Epoch 18/35\n",
      " - 4s - loss: 0.5082 - acc: 0.8720 - val_loss: 0.8592 - val_acc: 0.7625\n",
      "Epoch 19/35\n",
      " - 4s - loss: 0.4990 - acc: 0.8721 - val_loss: 0.7058 - val_acc: 0.7465\n",
      "Epoch 20/35\n",
      " - 4s - loss: 0.4949 - acc: 0.8742 - val_loss: 0.7608 - val_acc: 0.7638\n",
      "Epoch 21/35\n",
      " - 4s - loss: 0.4969 - acc: 0.8753 - val_loss: 0.9662 - val_acc: 0.5714\n",
      "Epoch 22/35\n",
      " - 4s - loss: 0.4729 - acc: 0.8853 - val_loss: 1.0824 - val_acc: 0.6997\n",
      "Epoch 23/35\n",
      " - 4s - loss: 0.4722 - acc: 0.8784 - val_loss: 0.6847 - val_acc: 0.8090\n",
      "Epoch 24/35\n",
      " - 4s - loss: 0.4729 - acc: 0.8808 - val_loss: 0.6892 - val_acc: 0.8154\n",
      "Epoch 25/35\n",
      " - 4s - loss: 0.4691 - acc: 0.8837 - val_loss: 0.6156 - val_acc: 0.8001\n",
      "Epoch 26/35\n",
      " - 4s - loss: 0.4665 - acc: 0.8818 - val_loss: 0.8563 - val_acc: 0.7207\n",
      "Epoch 27/35\n",
      " - 4s - loss: 0.4594 - acc: 0.8817 - val_loss: 0.7700 - val_acc: 0.7574\n",
      "Epoch 28/35\n",
      " - 4s - loss: 0.4559 - acc: 0.8819 - val_loss: 0.6305 - val_acc: 0.8680\n",
      "Epoch 29/35\n",
      " - 4s - loss: 0.4624 - acc: 0.8860 - val_loss: 0.8539 - val_acc: 0.7024\n",
      "Epoch 30/35\n",
      " - 4s - loss: 0.4462 - acc: 0.8894 - val_loss: 0.6595 - val_acc: 0.8320\n",
      "Epoch 31/35\n",
      " - 4s - loss: 0.4444 - acc: 0.8901 - val_loss: 0.6202 - val_acc: 0.8154\n",
      "Epoch 32/35\n",
      " - 4s - loss: 0.4506 - acc: 0.8867 - val_loss: 0.6456 - val_acc: 0.7842\n",
      "Epoch 33/35\n",
      " - 4s - loss: 0.4506 - acc: 0.8848 - val_loss: 0.7049 - val_acc: 0.8402\n",
      "Epoch 34/35\n",
      " - 4s - loss: 0.4471 - acc: 0.8866 - val_loss: 0.5752 - val_acc: 0.8666\n",
      "Epoch 35/35\n",
      " - 4s - loss: 0.4595 - acc: 0.8826 - val_loss: 0.8860 - val_acc: 0.7041\n",
      "Train accuracy 0.7135473340628131 Test accuracy: 0.7041058703766542\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_19 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 118, 16)           3600      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 39, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                20000     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 25,270\n",
      "Trainable params: 25,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 33.1583 - acc: 0.7077 - val_loss: 9.1590 - val_acc: 0.8463\n",
      "Epoch 2/25\n",
      " - 4s - loss: 3.7155 - acc: 0.8868 - val_loss: 1.5044 - val_acc: 0.8436\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.7515 - acc: 0.9047 - val_loss: 0.8519 - val_acc: 0.7855\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.4972 - acc: 0.9057 - val_loss: 0.7259 - val_acc: 0.8103\n",
      "Epoch 5/25\n",
      " - 5s - loss: 0.4501 - acc: 0.9052 - val_loss: 0.6605 - val_acc: 0.8653\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.4197 - acc: 0.9106 - val_loss: 0.6046 - val_acc: 0.8782\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.3938 - acc: 0.9128 - val_loss: 0.5528 - val_acc: 0.8877\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.3883 - acc: 0.9115 - val_loss: 0.6221 - val_acc: 0.8551\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.3514 - acc: 0.9196 - val_loss: 0.5976 - val_acc: 0.8079\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.3569 - acc: 0.9165 - val_loss: 0.5430 - val_acc: 0.8778\n",
      "Epoch 11/25\n",
      " - 5s - loss: 0.3253 - acc: 0.9245 - val_loss: 0.5598 - val_acc: 0.8677\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.3208 - acc: 0.9252 - val_loss: 0.4985 - val_acc: 0.8785\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.3355 - acc: 0.9200 - val_loss: 0.5307 - val_acc: 0.8734\n",
      "Epoch 14/25\n",
      " - 5s - loss: 0.3039 - acc: 0.9287 - val_loss: 0.4901 - val_acc: 0.8938\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2934 - acc: 0.9300 - val_loss: 0.5767 - val_acc: 0.8392\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.3100 - acc: 0.9211 - val_loss: 0.5113 - val_acc: 0.8459\n",
      "Epoch 17/25\n",
      " - 5s - loss: 0.2956 - acc: 0.9282 - val_loss: 0.4581 - val_acc: 0.8744\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.2838 - acc: 0.9312 - val_loss: 0.5231 - val_acc: 0.8761\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2789 - acc: 0.9316 - val_loss: 0.4493 - val_acc: 0.8765\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2712 - acc: 0.9350 - val_loss: 0.4607 - val_acc: 0.8592\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.2739 - acc: 0.9312 - val_loss: 0.4213 - val_acc: 0.8951\n",
      "Epoch 22/25\n",
      " - 5s - loss: 0.2609 - acc: 0.9338 - val_loss: 0.4548 - val_acc: 0.8758\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.2554 - acc: 0.9350 - val_loss: 0.5415 - val_acc: 0.8076\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.2650 - acc: 0.9327 - val_loss: 0.4351 - val_acc: 0.8897\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2926 - acc: 0.9290 - val_loss: 0.4154 - val_acc: 0.8924\n",
      "Train accuracy 0.9402883569096845 Test accuracy: 0.8924329826942654\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 118, 24)           4728      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                29984     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 36,198\n",
      "Trainable params: 36,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 3s - loss: 22.0003 - acc: 0.7575 - val_loss: 0.9952 - val_acc: 0.7954\n",
      "Epoch 2/30\n",
      " - 2s - loss: 0.5749 - acc: 0.8625 - val_loss: 1.0222 - val_acc: 0.6698\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.4590 - acc: 0.8875 - val_loss: 0.5730 - val_acc: 0.8870\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.4050 - acc: 0.8964 - val_loss: 0.5849 - val_acc: 0.8666\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.3764 - acc: 0.9083 - val_loss: 0.5224 - val_acc: 0.8582\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.3698 - acc: 0.9109 - val_loss: 0.5335 - val_acc: 0.8534\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3426 - acc: 0.9131 - val_loss: 0.4697 - val_acc: 0.8795\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.3304 - acc: 0.9169 - val_loss: 0.4343 - val_acc: 0.8982\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.3292 - acc: 0.9134 - val_loss: 0.4552 - val_acc: 0.8704\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.3313 - acc: 0.9146 - val_loss: 0.4631 - val_acc: 0.8799\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.3203 - acc: 0.9177 - val_loss: 0.5109 - val_acc: 0.8364\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.3042 - acc: 0.9221 - val_loss: 0.4424 - val_acc: 0.8748\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.3095 - acc: 0.9204 - val_loss: 0.4410 - val_acc: 0.8792\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.3130 - acc: 0.9173 - val_loss: 0.4639 - val_acc: 0.8599\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.3084 - acc: 0.9207 - val_loss: 0.5122 - val_acc: 0.8297\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.2898 - acc: 0.9229 - val_loss: 0.3869 - val_acc: 0.8897\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2976 - acc: 0.9180 - val_loss: 0.4307 - val_acc: 0.8744\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2923 - acc: 0.9217 - val_loss: 0.4364 - val_acc: 0.8571\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2950 - acc: 0.9251 - val_loss: 0.4431 - val_acc: 0.8785\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2935 - acc: 0.9245 - val_loss: 0.6502 - val_acc: 0.7852\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2951 - acc: 0.9236 - val_loss: 0.4068 - val_acc: 0.8738\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2870 - acc: 0.9257 - val_loss: 0.4662 - val_acc: 0.8510\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2911 - acc: 0.9215 - val_loss: 0.4477 - val_acc: 0.8388\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2883 - acc: 0.9244 - val_loss: 0.5285 - val_acc: 0.7991\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2867 - acc: 0.9257 - val_loss: 0.3972 - val_acc: 0.8911\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2849 - acc: 0.9242 - val_loss: 0.4130 - val_acc: 0.8741\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2880 - acc: 0.9218 - val_loss: 0.5486 - val_acc: 0.8137\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2804 - acc: 0.9287 - val_loss: 0.4059 - val_acc: 0.8656\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2889 - acc: 0.9226 - val_loss: 0.7382 - val_acc: 0.7747\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2833 - acc: 0.9291 - val_loss: 0.4879 - val_acc: 0.8219\n",
      "Train accuracy 0.8803046789989118 Test accuracy: 0.8218527315914489\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_23 (Conv1D)           (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 116, 32)           9440      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 116, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 38, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1216)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                77888     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 90,406\n",
      "Trainable params: 90,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 4.2436 - acc: 0.8079 - val_loss: 0.5711 - val_acc: 0.8636\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.4683 - acc: 0.8844 - val_loss: 0.6810 - val_acc: 0.8093\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.4119 - acc: 0.8973 - val_loss: 0.6572 - val_acc: 0.8412\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.3911 - acc: 0.9026 - val_loss: 0.4871 - val_acc: 0.8588\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.3806 - acc: 0.9027 - val_loss: 0.4511 - val_acc: 0.8721\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.3686 - acc: 0.9045 - val_loss: 0.5533 - val_acc: 0.8232\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.3675 - acc: 0.9057 - val_loss: 0.6532 - val_acc: 0.7703\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.3647 - acc: 0.9097 - val_loss: 0.4831 - val_acc: 0.8599\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.3650 - acc: 0.9106 - val_loss: 0.7605 - val_acc: 0.7469\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.3588 - acc: 0.9082 - val_loss: 0.7704 - val_acc: 0.7089\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.3535 - acc: 0.9095 - val_loss: 0.4914 - val_acc: 0.8680\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.3511 - acc: 0.9101 - val_loss: 0.5851 - val_acc: 0.7852\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.3507 - acc: 0.9091 - val_loss: 0.3763 - val_acc: 0.8904\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.3444 - acc: 0.9128 - val_loss: 0.4630 - val_acc: 0.8663\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.3669 - acc: 0.9081 - val_loss: 0.4374 - val_acc: 0.8521\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.3502 - acc: 0.9117 - val_loss: 0.4200 - val_acc: 0.8700\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.3462 - acc: 0.9149 - val_loss: 0.5515 - val_acc: 0.8039\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.3321 - acc: 0.9153 - val_loss: 0.5360 - val_acc: 0.8195\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.3365 - acc: 0.9154 - val_loss: 0.4456 - val_acc: 0.8459\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.3266 - acc: 0.9161 - val_loss: 0.3982 - val_acc: 0.8816\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.3478 - acc: 0.9128 - val_loss: 0.5870 - val_acc: 0.8032\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.3437 - acc: 0.9142 - val_loss: 0.4387 - val_acc: 0.8748\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.3247 - acc: 0.9144 - val_loss: 0.4087 - val_acc: 0.8856\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.3268 - acc: 0.9115 - val_loss: 0.3774 - val_acc: 0.8867\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.3255 - acc: 0.9176 - val_loss: 0.4234 - val_acc: 0.8622\n",
      "Train accuracy 0.9236942327969482 Test accuracy: 0.8622327790973872\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 120, 32)           5152      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                81984     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 88,998\n",
      "Trainable params: 88,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 4s - loss: 91.6109 - acc: 0.7274 - val_loss: 20.5480 - val_acc: 0.7713\n",
      "Epoch 2/30\n",
      " - 2s - loss: 7.8445 - acc: 0.8384 - val_loss: 2.3996 - val_acc: 0.7431\n",
      "Epoch 3/30\n",
      " - 2s - loss: 1.1033 - acc: 0.8599 - val_loss: 0.9668 - val_acc: 0.8415\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.6050 - acc: 0.8774 - val_loss: 0.8111 - val_acc: 0.8527\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.5668 - acc: 0.8747 - val_loss: 0.7943 - val_acc: 0.8442\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.5385 - acc: 0.8828 - val_loss: 0.7514 - val_acc: 0.8429\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.4746 - acc: 0.8919 - val_loss: 0.7028 - val_acc: 0.8225\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.4651 - acc: 0.8912 - val_loss: 0.7666 - val_acc: 0.8151\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.4642 - acc: 0.8900 - val_loss: 0.6762 - val_acc: 0.8588\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.4537 - acc: 0.8893 - val_loss: 0.6286 - val_acc: 0.8666\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.4080 - acc: 0.9045 - val_loss: 0.6110 - val_acc: 0.8633\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.4068 - acc: 0.8998 - val_loss: 0.6332 - val_acc: 0.8463\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.4012 - acc: 0.9017 - val_loss: 0.6238 - val_acc: 0.8364\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.3900 - acc: 0.9033 - val_loss: 0.5950 - val_acc: 0.8521\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.3884 - acc: 0.9015 - val_loss: 0.6049 - val_acc: 0.8568\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.3807 - acc: 0.9036 - val_loss: 0.6256 - val_acc: 0.8531\n",
      "Epoch 17/30\n",
      " - 3s - loss: 0.4079 - acc: 0.9015 - val_loss: 0.5884 - val_acc: 0.8636\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.3759 - acc: 0.9076 - val_loss: 0.6103 - val_acc: 0.8616\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.4024 - acc: 0.8961 - val_loss: 0.5990 - val_acc: 0.8144\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.3695 - acc: 0.9075 - val_loss: 0.5853 - val_acc: 0.8571\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.3759 - acc: 0.9060 - val_loss: 0.5910 - val_acc: 0.8419\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.3784 - acc: 0.9030 - val_loss: 0.5485 - val_acc: 0.8823\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.3656 - acc: 0.9081 - val_loss: 0.5569 - val_acc: 0.8901\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.3383 - acc: 0.9199 - val_loss: 0.5249 - val_acc: 0.8585\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.4042 - acc: 0.8985 - val_loss: 0.5675 - val_acc: 0.8599\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.3456 - acc: 0.9188 - val_loss: 0.5822 - val_acc: 0.8626\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.3543 - acc: 0.9161 - val_loss: 0.5797 - val_acc: 0.8364\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.3425 - acc: 0.9154 - val_loss: 0.5437 - val_acc: 0.8622\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.3220 - acc: 0.9246 - val_loss: 0.5397 - val_acc: 0.8694\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.3443 - acc: 0.9161 - val_loss: 0.4974 - val_acc: 0.8639\n",
      "Train accuracy 0.9197497279651795 Test accuracy: 0.8639294197488971\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 126, 42)           1176      \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 124, 24)           3048      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 124, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 62, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1488)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                95296     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 99,910\n",
      "Trainable params: 99,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 4s - loss: 35.4818 - acc: 0.7365 - val_loss: 1.2519 - val_acc: 0.7645\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.7410 - acc: 0.8230 - val_loss: 0.7950 - val_acc: 0.7811\n",
      "Epoch 3/30\n",
      " - 3s - loss: 0.6246 - acc: 0.8414 - val_loss: 0.7543 - val_acc: 0.8069\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.5642 - acc: 0.8576 - val_loss: 0.7985 - val_acc: 0.7557\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.5363 - acc: 0.8637 - val_loss: 0.6684 - val_acc: 0.8195\n",
      "Epoch 6/30\n",
      " - 3s - loss: 0.4955 - acc: 0.8762 - val_loss: 0.7244 - val_acc: 0.7771\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.5006 - acc: 0.8686 - val_loss: 0.7676 - val_acc: 0.8042\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.4527 - acc: 0.8879 - val_loss: 0.5642 - val_acc: 0.8493\n",
      "Epoch 9/30\n",
      " - 3s - loss: 0.4582 - acc: 0.8853 - val_loss: 0.6889 - val_acc: 0.8314\n",
      "Epoch 10/30\n",
      " - 3s - loss: 0.4547 - acc: 0.8864 - val_loss: 0.6378 - val_acc: 0.8517\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.4442 - acc: 0.8886 - val_loss: 0.5697 - val_acc: 0.8599\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.4211 - acc: 0.8930 - val_loss: 0.5194 - val_acc: 0.8785\n",
      "Epoch 13/30\n",
      " - 3s - loss: 0.4081 - acc: 0.9002 - val_loss: 0.6659 - val_acc: 0.7727\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.4002 - acc: 0.8995 - val_loss: 0.6751 - val_acc: 0.7615\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.3853 - acc: 0.9071 - val_loss: 0.5253 - val_acc: 0.8734\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.3952 - acc: 0.9003 - val_loss: 0.5621 - val_acc: 0.8677\n",
      "Epoch 17/30\n",
      " - 3s - loss: 0.4270 - acc: 0.8984 - val_loss: 0.4994 - val_acc: 0.8921\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.3933 - acc: 0.9007 - val_loss: 0.6029 - val_acc: 0.8490\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.3689 - acc: 0.9090 - val_loss: 0.5713 - val_acc: 0.8300\n",
      "Epoch 20/30\n",
      " - 3s - loss: 0.3653 - acc: 0.9110 - val_loss: 0.4760 - val_acc: 0.8833\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.3713 - acc: 0.9056 - val_loss: 0.4707 - val_acc: 0.8683\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.3936 - acc: 0.9068 - val_loss: 0.5288 - val_acc: 0.8846\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.3470 - acc: 0.9162 - val_loss: 0.4120 - val_acc: 0.8816\n",
      "Epoch 24/30\n",
      " - 3s - loss: 0.3585 - acc: 0.9087 - val_loss: 0.4459 - val_acc: 0.8833\n",
      "Epoch 25/30\n",
      " - 3s - loss: 0.3368 - acc: 0.9185 - val_loss: 0.4237 - val_acc: 0.8792\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.3483 - acc: 0.9128 - val_loss: 0.4607 - val_acc: 0.8755\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.3311 - acc: 0.9189 - val_loss: 0.4189 - val_acc: 0.8921\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.3116 - acc: 0.9232 - val_loss: 0.4055 - val_acc: 0.8938\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.3375 - acc: 0.9154 - val_loss: 0.5142 - val_acc: 0.8419\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.3531 - acc: 0.9113 - val_loss: 0.4770 - val_acc: 0.8514\n",
      "Train accuracy 0.9139009793253536 Test accuracy: 0.8513742789277231\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_29 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 118, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                29984     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,054\n",
      "Trainable params: 37,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 4s - loss: 20.3809 - acc: 0.7291 - val_loss: 2.9204 - val_acc: 0.8090\n",
      "Epoch 2/25\n",
      " - 4s - loss: 1.0833 - acc: 0.8726 - val_loss: 0.8612 - val_acc: 0.8426\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.5268 - acc: 0.8875 - val_loss: 0.7121 - val_acc: 0.8548\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.4572 - acc: 0.8966 - val_loss: 0.7138 - val_acc: 0.8738\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.4335 - acc: 0.8970 - val_loss: 0.6639 - val_acc: 0.8364\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.4060 - acc: 0.9007 - val_loss: 0.6129 - val_acc: 0.8873\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.4219 - acc: 0.8995 - val_loss: 0.5754 - val_acc: 0.9002\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.3727 - acc: 0.9115 - val_loss: 0.5795 - val_acc: 0.8568\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.3573 - acc: 0.9104 - val_loss: 0.6117 - val_acc: 0.8351\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.3441 - acc: 0.9162 - val_loss: 0.5354 - val_acc: 0.8948\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.3478 - acc: 0.9116 - val_loss: 0.5007 - val_acc: 0.9019\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.3180 - acc: 0.9197 - val_loss: 0.5056 - val_acc: 0.8989\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.3130 - acc: 0.9236 - val_loss: 0.4728 - val_acc: 0.8955\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.3097 - acc: 0.9211 - val_loss: 0.4581 - val_acc: 0.9104\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2956 - acc: 0.9234 - val_loss: 0.4555 - val_acc: 0.9053\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.3036 - acc: 0.9214 - val_loss: 0.4797 - val_acc: 0.8938\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.3032 - acc: 0.9230 - val_loss: 0.4508 - val_acc: 0.8819\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.2848 - acc: 0.9279 - val_loss: 0.4111 - val_acc: 0.9192\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2817 - acc: 0.9275 - val_loss: 0.4110 - val_acc: 0.9128\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2917 - acc: 0.9226 - val_loss: 0.4152 - val_acc: 0.9050\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.2715 - acc: 0.9314 - val_loss: 0.4112 - val_acc: 0.8938\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.2868 - acc: 0.9193 - val_loss: 0.4240 - val_acc: 0.9002\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.2637 - acc: 0.9329 - val_loss: 0.4017 - val_acc: 0.9002\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.2576 - acc: 0.9313 - val_loss: 0.4015 - val_acc: 0.9084\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2557 - acc: 0.9331 - val_loss: 0.3854 - val_acc: 0.9080\n",
      "Train accuracy 0.948721436343852 Test accuracy: 0.9080420766881574\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_31 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 118, 16)           3152      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 39, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 32)                20000     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 24,638\n",
      "Trainable params: 24,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 3s - loss: 15.3245 - acc: 0.7458 - val_loss: 1.2714 - val_acc: 0.7805\n",
      "Epoch 2/30\n",
      " - 1s - loss: 0.6392 - acc: 0.8550 - val_loss: 0.7413 - val_acc: 0.8409\n",
      "Epoch 3/30\n",
      " - 1s - loss: 0.4923 - acc: 0.8857 - val_loss: 0.6626 - val_acc: 0.8622\n",
      "Epoch 4/30\n",
      " - 1s - loss: 0.4680 - acc: 0.8860 - val_loss: 0.6297 - val_acc: 0.8473\n",
      "Epoch 5/30\n",
      " - 1s - loss: 0.4677 - acc: 0.8882 - val_loss: 0.6407 - val_acc: 0.8656\n",
      "Epoch 6/30\n",
      " - 1s - loss: 0.4308 - acc: 0.8950 - val_loss: 0.7057 - val_acc: 0.7842\n",
      "Epoch 7/30\n",
      " - 1s - loss: 0.4097 - acc: 0.9008 - val_loss: 0.6249 - val_acc: 0.8344\n",
      "Epoch 8/30\n",
      " - 1s - loss: 0.4138 - acc: 0.8966 - val_loss: 0.5428 - val_acc: 0.8595\n",
      "Epoch 9/30\n",
      " - 1s - loss: 0.3861 - acc: 0.9086 - val_loss: 0.6079 - val_acc: 0.8398\n",
      "Epoch 10/30\n",
      " - 1s - loss: 0.3920 - acc: 0.9053 - val_loss: 0.5732 - val_acc: 0.8476\n",
      "Epoch 11/30\n",
      " - 1s - loss: 0.3687 - acc: 0.9100 - val_loss: 0.5987 - val_acc: 0.8398\n",
      "Epoch 12/30\n",
      " - 1s - loss: 0.3888 - acc: 0.8998 - val_loss: 0.5543 - val_acc: 0.8738\n",
      "Epoch 13/30\n",
      " - 1s - loss: 0.3739 - acc: 0.9051 - val_loss: 0.5441 - val_acc: 0.8609\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.3720 - acc: 0.9051 - val_loss: 0.5179 - val_acc: 0.8609\n",
      "Epoch 15/30\n",
      " - 1s - loss: 0.3505 - acc: 0.9115 - val_loss: 0.5880 - val_acc: 0.8229\n",
      "Epoch 16/30\n",
      " - 1s - loss: 0.3415 - acc: 0.9138 - val_loss: 0.4769 - val_acc: 0.8884\n",
      "Epoch 17/30\n",
      " - 1s - loss: 0.3342 - acc: 0.9123 - val_loss: 0.4564 - val_acc: 0.8951\n",
      "Epoch 18/30\n",
      " - 1s - loss: 0.3228 - acc: 0.9214 - val_loss: 0.4618 - val_acc: 0.8985\n",
      "Epoch 19/30\n",
      " - 1s - loss: 0.3444 - acc: 0.9149 - val_loss: 0.4618 - val_acc: 0.9019\n",
      "Epoch 20/30\n",
      " - 1s - loss: 0.3535 - acc: 0.9087 - val_loss: 0.4896 - val_acc: 0.8931\n",
      "Epoch 21/30\n",
      " - 1s - loss: 0.3269 - acc: 0.9174 - val_loss: 0.4670 - val_acc: 0.8799\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.3380 - acc: 0.9136 - val_loss: 0.5943 - val_acc: 0.8476\n",
      "Epoch 23/30\n",
      " - 1s - loss: 0.3278 - acc: 0.9157 - val_loss: 0.5482 - val_acc: 0.8673\n",
      "Epoch 24/30\n",
      " - 1s - loss: 0.3038 - acc: 0.9259 - val_loss: 0.4524 - val_acc: 0.8816\n",
      "Epoch 25/30\n",
      " - 1s - loss: 0.2950 - acc: 0.9256 - val_loss: 0.4678 - val_acc: 0.8673\n",
      "Epoch 26/30\n",
      " - 1s - loss: 0.2893 - acc: 0.9271 - val_loss: 0.4022 - val_acc: 0.8921\n",
      "Epoch 27/30\n",
      " - 1s - loss: 0.3299 - acc: 0.9168 - val_loss: 0.6079 - val_acc: 0.8663\n",
      "Epoch 28/30\n",
      " - 1s - loss: 0.3191 - acc: 0.9233 - val_loss: 0.3898 - val_acc: 0.8921\n",
      "Epoch 29/30\n",
      " - 1s - loss: 0.3074 - acc: 0.9208 - val_loss: 0.6789 - val_acc: 0.7703\n",
      "Epoch 30/30\n",
      " - 1s - loss: 0.3375 - acc: 0.9166 - val_loss: 0.4229 - val_acc: 0.9077\n",
      "Train accuracy 0.9439608269858542 Test accuracy: 0.9077027485578555\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 126, 28)           784       \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 124, 16)           1360      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 41, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 656)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                42048     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 44,582\n",
      "Trainable params: 44,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 3s - loss: 67.7185 - acc: 0.6288 - val_loss: 49.4894 - val_acc: 0.7367\n",
      "Epoch 2/30\n",
      " - 1s - loss: 37.1992 - acc: 0.8252 - val_loss: 27.4454 - val_acc: 0.7659\n",
      "Epoch 3/30\n",
      " - 1s - loss: 20.4884 - acc: 0.8706 - val_loss: 15.2680 - val_acc: 0.7689\n",
      "Epoch 4/30\n",
      " - 1s - loss: 11.2570 - acc: 0.8902 - val_loss: 8.5185 - val_acc: 0.8174\n",
      "Epoch 5/30\n",
      " - 1s - loss: 6.1733 - acc: 0.8919 - val_loss: 4.8209 - val_acc: 0.8181\n",
      "Epoch 6/30\n",
      " - 1s - loss: 3.4088 - acc: 0.8977 - val_loss: 2.8336 - val_acc: 0.8266\n",
      "Epoch 7/30\n",
      " - 1s - loss: 1.9367 - acc: 0.9032 - val_loss: 1.8325 - val_acc: 0.7869\n",
      "Epoch 8/30\n",
      " - 2s - loss: 1.1843 - acc: 0.9022 - val_loss: 1.3294 - val_acc: 0.7933\n",
      "Epoch 9/30\n",
      " - 1s - loss: 0.8109 - acc: 0.9091 - val_loss: 1.0191 - val_acc: 0.8497\n",
      "Epoch 10/30\n",
      " - 1s - loss: 0.6267 - acc: 0.9106 - val_loss: 0.8913 - val_acc: 0.8347\n",
      "Epoch 11/30\n",
      " - 1s - loss: 0.5430 - acc: 0.9087 - val_loss: 0.7963 - val_acc: 0.8646\n",
      "Epoch 12/30\n",
      " - 1s - loss: 0.4968 - acc: 0.9079 - val_loss: 0.7564 - val_acc: 0.8609\n",
      "Epoch 13/30\n",
      " - 1s - loss: 0.4760 - acc: 0.9081 - val_loss: 0.7551 - val_acc: 0.8588\n",
      "Epoch 14/30\n",
      " - 1s - loss: 0.4512 - acc: 0.9115 - val_loss: 0.7723 - val_acc: 0.8164\n",
      "Epoch 15/30\n",
      " - 1s - loss: 0.4325 - acc: 0.9132 - val_loss: 0.7058 - val_acc: 0.8612\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.4363 - acc: 0.9041 - val_loss: 0.6773 - val_acc: 0.8677\n",
      "Epoch 17/30\n",
      " - 1s - loss: 0.4068 - acc: 0.9149 - val_loss: 0.6637 - val_acc: 0.8687\n",
      "Epoch 18/30\n",
      " - 1s - loss: 0.4053 - acc: 0.9138 - val_loss: 0.6468 - val_acc: 0.8673\n",
      "Epoch 19/30\n",
      " - 1s - loss: 0.3873 - acc: 0.9180 - val_loss: 0.6441 - val_acc: 0.8653\n",
      "Epoch 20/30\n",
      " - 1s - loss: 0.3779 - acc: 0.9237 - val_loss: 0.6258 - val_acc: 0.8748\n",
      "Epoch 21/30\n",
      " - 1s - loss: 0.3672 - acc: 0.9204 - val_loss: 0.6213 - val_acc: 0.8744\n",
      "Epoch 22/30\n",
      " - 1s - loss: 0.3643 - acc: 0.9226 - val_loss: 0.6147 - val_acc: 0.8748\n",
      "Epoch 23/30\n",
      " - 1s - loss: 0.3581 - acc: 0.9249 - val_loss: 0.5916 - val_acc: 0.8680\n",
      "Epoch 24/30\n",
      " - 1s - loss: 0.3521 - acc: 0.9253 - val_loss: 0.5863 - val_acc: 0.8690\n",
      "Epoch 25/30\n",
      " - 1s - loss: 0.3434 - acc: 0.9270 - val_loss: 0.6174 - val_acc: 0.8398\n",
      "Epoch 26/30\n",
      " - 1s - loss: 0.3382 - acc: 0.9283 - val_loss: 0.5705 - val_acc: 0.8694\n",
      "Epoch 27/30\n",
      " - 1s - loss: 0.3360 - acc: 0.9260 - val_loss: 0.5708 - val_acc: 0.8683\n",
      "Epoch 28/30\n",
      " - 1s - loss: 0.3264 - acc: 0.9270 - val_loss: 0.5596 - val_acc: 0.8744\n",
      "Epoch 29/30\n",
      " - 1s - loss: 0.3165 - acc: 0.9294 - val_loss: 0.5545 - val_acc: 0.8809\n",
      "Epoch 30/30\n",
      " - 1s - loss: 0.3167 - acc: 0.9276 - val_loss: 0.5340 - val_acc: 0.8744\n",
      "Train accuracy 0.933215451577802 Test accuracy: 0.8744485917882593\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_35 (Conv1D)           (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 120, 16)           2032      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 40, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                20512     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 25,430\n",
      "Trainable params: 25,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 11.7904 - acc: 0.7391 - val_loss: 0.8701 - val_acc: 0.7788\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.6442 - acc: 0.8328 - val_loss: 0.7829 - val_acc: 0.8164\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.5658 - acc: 0.8569 - val_loss: 0.6739 - val_acc: 0.8453\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.5517 - acc: 0.8618 - val_loss: 0.8972 - val_acc: 0.7027\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.5117 - acc: 0.8708 - val_loss: 0.6253 - val_acc: 0.8412\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.4780 - acc: 0.8788 - val_loss: 0.6040 - val_acc: 0.8280\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.4720 - acc: 0.8844 - val_loss: 0.6061 - val_acc: 0.8466\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.4509 - acc: 0.8906 - val_loss: 0.5511 - val_acc: 0.8514\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.4468 - acc: 0.8901 - val_loss: 0.5676 - val_acc: 0.8466\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.4462 - acc: 0.8881 - val_loss: 0.6952 - val_acc: 0.8144\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.4389 - acc: 0.8939 - val_loss: 0.5627 - val_acc: 0.8694\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.4341 - acc: 0.8906 - val_loss: 0.5739 - val_acc: 0.8575\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.4189 - acc: 0.8980 - val_loss: 0.6106 - val_acc: 0.8171\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.4243 - acc: 0.9018 - val_loss: 0.6372 - val_acc: 0.8341\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.4123 - acc: 0.8976 - val_loss: 0.6017 - val_acc: 0.8463\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.3796 - acc: 0.9070 - val_loss: 0.4965 - val_acc: 0.8626\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.3946 - acc: 0.9004 - val_loss: 0.4797 - val_acc: 0.8609\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.3904 - acc: 0.9048 - val_loss: 0.6900 - val_acc: 0.7967\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.3939 - acc: 0.9052 - val_loss: 0.5635 - val_acc: 0.8215\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.3781 - acc: 0.9057 - val_loss: 0.6522 - val_acc: 0.8134\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.3945 - acc: 0.9061 - val_loss: 0.4607 - val_acc: 0.8748\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.3641 - acc: 0.9128 - val_loss: 0.4994 - val_acc: 0.8466\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.4095 - acc: 0.9017 - val_loss: 0.6645 - val_acc: 0.7855\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.3662 - acc: 0.9106 - val_loss: 0.4692 - val_acc: 0.8911\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.3860 - acc: 0.9087 - val_loss: 0.5268 - val_acc: 0.8320\n",
      "Train accuracy 0.8769042437431991 Test accuracy: 0.832032575500509\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_37 (Conv1D)           (None, 122, 28)           1792      \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 116, 24)           4728      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 116, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 58, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1392)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                44576     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 51,294\n",
      "Trainable params: 51,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 3s - loss: 4.6101 - acc: 0.7229 - val_loss: 0.8567 - val_acc: 0.8575\n",
      "Epoch 2/25\n",
      " - 2s - loss: 0.5960 - acc: 0.8694 - val_loss: 0.5388 - val_acc: 0.8999\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.4529 - acc: 0.8985 - val_loss: 0.4633 - val_acc: 0.8873\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.3815 - acc: 0.9074 - val_loss: 0.4082 - val_acc: 0.8931\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.3394 - acc: 0.9135 - val_loss: 0.3843 - val_acc: 0.9013\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3315 - acc: 0.9181 - val_loss: 0.4065 - val_acc: 0.8911\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.3237 - acc: 0.9184 - val_loss: 0.3902 - val_acc: 0.8870\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.2985 - acc: 0.9226 - val_loss: 0.3657 - val_acc: 0.8968\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.3158 - acc: 0.9248 - val_loss: 0.3911 - val_acc: 0.9006\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.3041 - acc: 0.9225 - val_loss: 0.4590 - val_acc: 0.8782\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2902 - acc: 0.9240 - val_loss: 0.3727 - val_acc: 0.8951\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.2983 - acc: 0.9246 - val_loss: 0.6372 - val_acc: 0.7903\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.3210 - acc: 0.9218 - val_loss: 0.3795 - val_acc: 0.8924\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2750 - acc: 0.9285 - val_loss: 0.3721 - val_acc: 0.8928\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.3241 - acc: 0.9199 - val_loss: 0.4096 - val_acc: 0.8806\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.2881 - acc: 0.9283 - val_loss: 0.3993 - val_acc: 0.8829\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.2935 - acc: 0.9283 - val_loss: 0.4347 - val_acc: 0.8768\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2857 - acc: 0.9274 - val_loss: 0.4402 - val_acc: 0.8768\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.3183 - acc: 0.9218 - val_loss: 0.3732 - val_acc: 0.8863\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2959 - acc: 0.9278 - val_loss: 0.3438 - val_acc: 0.9002\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.3066 - acc: 0.9229 - val_loss: 0.3859 - val_acc: 0.8853\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2850 - acc: 0.9272 - val_loss: 0.3951 - val_acc: 0.8795\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2920 - acc: 0.9259 - val_loss: 0.3742 - val_acc: 0.8809\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2962 - acc: 0.9242 - val_loss: 0.4072 - val_acc: 0.8738\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2963 - acc: 0.9249 - val_loss: 0.4095 - val_acc: 0.8761\n",
      "Train accuracy 0.9345756256152289 Test accuracy: 0.8761452324397693\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_39 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 122, 32)           2720      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 122, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                81984     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 86,382\n",
      "Trainable params: 86,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 3s - loss: 22.7968 - acc: 0.7855 - val_loss: 4.4245 - val_acc: 0.8269\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.5498 - acc: 0.9135 - val_loss: 0.7672 - val_acc: 0.8829\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4640 - acc: 0.9123 - val_loss: 0.6182 - val_acc: 0.8836\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.3827 - acc: 0.9218 - val_loss: 0.5272 - val_acc: 0.8734\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.3322 - acc: 0.9304 - val_loss: 0.4792 - val_acc: 0.8982\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.3333 - acc: 0.9245 - val_loss: 0.4604 - val_acc: 0.8867\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.2905 - acc: 0.9358 - val_loss: 0.4597 - val_acc: 0.8795\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.3223 - acc: 0.9245 - val_loss: 0.4677 - val_acc: 0.8958\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.3260 - acc: 0.9217 - val_loss: 0.4409 - val_acc: 0.8928\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.2870 - acc: 0.9350 - val_loss: 0.4316 - val_acc: 0.8775\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.2716 - acc: 0.9347 - val_loss: 0.3952 - val_acc: 0.9040\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.2982 - acc: 0.9274 - val_loss: 0.4363 - val_acc: 0.8904\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.2594 - acc: 0.9362 - val_loss: 0.3815 - val_acc: 0.9006\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.2630 - acc: 0.9369 - val_loss: 0.4391 - val_acc: 0.8802\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.2667 - acc: 0.9340 - val_loss: 0.4025 - val_acc: 0.8968\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.2682 - acc: 0.9312 - val_loss: 0.3907 - val_acc: 0.8884\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.2627 - acc: 0.9323 - val_loss: 0.4910 - val_acc: 0.8660\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.2572 - acc: 0.9363 - val_loss: 0.4170 - val_acc: 0.8921\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.2512 - acc: 0.9350 - val_loss: 0.4513 - val_acc: 0.8819\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.2498 - acc: 0.9372 - val_loss: 0.3645 - val_acc: 0.8877\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.2725 - acc: 0.9328 - val_loss: 0.4023 - val_acc: 0.8694\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.2370 - acc: 0.9418 - val_loss: 0.3780 - val_acc: 0.8907\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.2295 - acc: 0.9403 - val_loss: 0.3392 - val_acc: 0.8914\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.2422 - acc: 0.9369 - val_loss: 0.3856 - val_acc: 0.8985\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.2517 - acc: 0.9368 - val_loss: 0.3717 - val_acc: 0.8938\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.2607 - acc: 0.9343 - val_loss: 0.3326 - val_acc: 0.9050\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.2248 - acc: 0.9430 - val_loss: 0.3536 - val_acc: 0.9006\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.2193 - acc: 0.9433 - val_loss: 0.3477 - val_acc: 0.8914\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2229 - acc: 0.9396 - val_loss: 0.3520 - val_acc: 0.8965\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2261 - acc: 0.9402 - val_loss: 0.3448 - val_acc: 0.9030\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.2981 - acc: 0.9268 - val_loss: 0.3279 - val_acc: 0.9067\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2337 - acc: 0.9366 - val_loss: 0.4004 - val_acc: 0.8853\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2216 - acc: 0.9389 - val_loss: 0.3564 - val_acc: 0.8921\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.2160 - acc: 0.9404 - val_loss: 0.3425 - val_acc: 0.9002\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.2206 - acc: 0.9388 - val_loss: 0.4076 - val_acc: 0.8714\n",
      "Train accuracy 0.9360718171926007 Test accuracy: 0.8713946386155412\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_41 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 118, 16)           3152      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 39, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                20000     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 24,638\n",
      "Trainable params: 24,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 3s - loss: 24.7607 - acc: 0.6374 - val_loss: 12.1744 - val_acc: 0.6956\n",
      "Epoch 2/25\n",
      " - 1s - loss: 6.9210 - acc: 0.8572 - val_loss: 3.8338 - val_acc: 0.8571\n",
      "Epoch 3/25\n",
      " - 1s - loss: 2.1890 - acc: 0.8977 - val_loss: 1.5053 - val_acc: 0.8541\n",
      "Epoch 4/25\n",
      " - 1s - loss: 0.8775 - acc: 0.9068 - val_loss: 0.8604 - val_acc: 0.8721\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.5256 - acc: 0.9143 - val_loss: 0.7066 - val_acc: 0.8751\n",
      "Epoch 6/25\n",
      " - 1s - loss: 0.4235 - acc: 0.9238 - val_loss: 0.6280 - val_acc: 0.8809\n",
      "Epoch 7/25\n",
      " - 1s - loss: 0.3802 - acc: 0.9272 - val_loss: 0.5760 - val_acc: 0.8931\n",
      "Epoch 8/25\n",
      " - 1s - loss: 0.3511 - acc: 0.9297 - val_loss: 0.5842 - val_acc: 0.8843\n",
      "Epoch 9/25\n",
      " - 1s - loss: 0.3254 - acc: 0.9347 - val_loss: 0.5243 - val_acc: 0.8999\n",
      "Epoch 10/25\n",
      " - 1s - loss: 0.3131 - acc: 0.9347 - val_loss: 0.5206 - val_acc: 0.8996\n",
      "Epoch 11/25\n",
      " - 1s - loss: 0.3041 - acc: 0.9372 - val_loss: 0.5029 - val_acc: 0.8748\n",
      "Epoch 12/25\n",
      " - 1s - loss: 0.2853 - acc: 0.9365 - val_loss: 0.4875 - val_acc: 0.9002\n",
      "Epoch 13/25\n",
      " - 1s - loss: 0.2826 - acc: 0.9391 - val_loss: 0.4586 - val_acc: 0.8951\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2819 - acc: 0.9388 - val_loss: 0.4434 - val_acc: 0.9074\n",
      "Epoch 15/25\n",
      " - 1s - loss: 0.2633 - acc: 0.9414 - val_loss: 0.4804 - val_acc: 0.8646\n",
      "Epoch 16/25\n",
      " - 1s - loss: 0.2555 - acc: 0.9411 - val_loss: 0.4194 - val_acc: 0.9121\n",
      "Epoch 17/25\n",
      " - 1s - loss: 0.2678 - acc: 0.9351 - val_loss: 0.4557 - val_acc: 0.9002\n",
      "Epoch 18/25\n",
      " - 1s - loss: 0.2576 - acc: 0.9407 - val_loss: 0.4430 - val_acc: 0.8955\n",
      "Epoch 19/25\n",
      " - 1s - loss: 0.2494 - acc: 0.9395 - val_loss: 0.4019 - val_acc: 0.8907\n",
      "Epoch 20/25\n",
      " - 1s - loss: 0.2348 - acc: 0.9437 - val_loss: 0.4034 - val_acc: 0.8968\n",
      "Epoch 21/25\n",
      " - 1s - loss: 0.2536 - acc: 0.9339 - val_loss: 0.4443 - val_acc: 0.8907\n",
      "Epoch 22/25\n",
      " - 1s - loss: 0.2338 - acc: 0.9441 - val_loss: 0.3991 - val_acc: 0.8863\n",
      "Epoch 23/25\n",
      " - 1s - loss: 0.2265 - acc: 0.9453 - val_loss: 0.3730 - val_acc: 0.9050\n",
      "Epoch 24/25\n",
      " - 1s - loss: 0.2398 - acc: 0.9402 - val_loss: 0.3804 - val_acc: 0.9006\n",
      "Epoch 25/25\n",
      " - 1s - loss: 0.2188 - acc: 0.9445 - val_loss: 0.3689 - val_acc: 0.8955\n",
      "Train accuracy 0.9522578890097932 Test accuracy: 0.8954869358669834\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_43 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 118, 16)           3600      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 39, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                20000     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 25,270\n",
      "Trainable params: 25,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 4s - loss: 15.8332 - acc: 0.6967 - val_loss: 3.0233 - val_acc: 0.7564\n",
      "Epoch 2/30\n",
      " - 3s - loss: 1.1858 - acc: 0.8777 - val_loss: 0.8561 - val_acc: 0.8463\n",
      "Epoch 3/30\n",
      " - 3s - loss: 0.5198 - acc: 0.8874 - val_loss: 0.7322 - val_acc: 0.8436\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.4474 - acc: 0.8984 - val_loss: 0.6273 - val_acc: 0.8734\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.4041 - acc: 0.9036 - val_loss: 0.6474 - val_acc: 0.8395\n",
      "Epoch 6/30\n",
      " - 3s - loss: 0.3901 - acc: 0.9081 - val_loss: 0.7020 - val_acc: 0.8012\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.3900 - acc: 0.9000 - val_loss: 0.5868 - val_acc: 0.8734\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.3681 - acc: 0.9085 - val_loss: 0.5896 - val_acc: 0.8504\n",
      "Epoch 9/30\n",
      " - 3s - loss: 0.3471 - acc: 0.9119 - val_loss: 0.5298 - val_acc: 0.8744\n",
      "Epoch 10/30\n",
      " - 3s - loss: 0.3462 - acc: 0.9129 - val_loss: 0.5315 - val_acc: 0.8809\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.3257 - acc: 0.9173 - val_loss: 0.5010 - val_acc: 0.8748\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.3464 - acc: 0.9076 - val_loss: 0.5478 - val_acc: 0.8772\n",
      "Epoch 13/30\n",
      " - 3s - loss: 0.3178 - acc: 0.9162 - val_loss: 0.5697 - val_acc: 0.8666\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.3070 - acc: 0.9207 - val_loss: 0.4851 - val_acc: 0.8880\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.3045 - acc: 0.9226 - val_loss: 0.5191 - val_acc: 0.8812\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.3009 - acc: 0.9199 - val_loss: 0.4661 - val_acc: 0.8958\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2988 - acc: 0.9217 - val_loss: 0.5313 - val_acc: 0.8317\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.3013 - acc: 0.9206 - val_loss: 0.4925 - val_acc: 0.8853\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.2734 - acc: 0.9314 - val_loss: 0.4544 - val_acc: 0.8738\n",
      "Epoch 20/30\n",
      " - 3s - loss: 0.2791 - acc: 0.9259 - val_loss: 0.4652 - val_acc: 0.8755\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.2842 - acc: 0.9237 - val_loss: 0.4821 - val_acc: 0.8823\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.2662 - acc: 0.9272 - val_loss: 0.4415 - val_acc: 0.8924\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2693 - acc: 0.9289 - val_loss: 0.4626 - val_acc: 0.8758\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2812 - acc: 0.9255 - val_loss: 0.4210 - val_acc: 0.8904\n",
      "Epoch 25/30\n",
      " - 3s - loss: 0.2672 - acc: 0.9276 - val_loss: 0.4201 - val_acc: 0.8816\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.2574 - acc: 0.9291 - val_loss: 0.4177 - val_acc: 0.8962\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2570 - acc: 0.9323 - val_loss: 0.4297 - val_acc: 0.8918\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2668 - acc: 0.9293 - val_loss: 0.4282 - val_acc: 0.8839\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2485 - acc: 0.9365 - val_loss: 0.4765 - val_acc: 0.8480\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.2482 - acc: 0.9366 - val_loss: 0.4277 - val_acc: 0.8945\n",
      "Train accuracy 0.9328073993471164 Test accuracy: 0.8944689514760774\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 118, 16)           3152      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 39, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 32)                20000     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 24,638\n",
      "Trainable params: 24,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 4s - loss: 24.4915 - acc: 0.7338 - val_loss: 9.6958 - val_acc: 0.8449\n",
      "Epoch 2/25\n",
      " - 2s - loss: 4.6933 - acc: 0.9143 - val_loss: 2.2316 - val_acc: 0.8833\n",
      "Epoch 3/25\n",
      " - 2s - loss: 1.1098 - acc: 0.9204 - val_loss: 0.8986 - val_acc: 0.8836\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.5101 - acc: 0.9234 - val_loss: 0.6771 - val_acc: 0.8561\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.4005 - acc: 0.9267 - val_loss: 0.6104 - val_acc: 0.8819\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3578 - acc: 0.9308 - val_loss: 0.5528 - val_acc: 0.8856\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.3387 - acc: 0.9286 - val_loss: 0.5336 - val_acc: 0.8945\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3173 - acc: 0.9353 - val_loss: 0.5215 - val_acc: 0.8894\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.3061 - acc: 0.9324 - val_loss: 0.4767 - val_acc: 0.8904\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.2883 - acc: 0.9358 - val_loss: 0.5144 - val_acc: 0.8636\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2748 - acc: 0.9380 - val_loss: 0.4526 - val_acc: 0.8894\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.2865 - acc: 0.9339 - val_loss: 0.4260 - val_acc: 0.9063\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2607 - acc: 0.9392 - val_loss: 0.4267 - val_acc: 0.8924\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2623 - acc: 0.9382 - val_loss: 0.4755 - val_acc: 0.8636\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.2596 - acc: 0.9357 - val_loss: 0.4522 - val_acc: 0.8938\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.2403 - acc: 0.9438 - val_loss: 0.3898 - val_acc: 0.9026\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.2386 - acc: 0.9421 - val_loss: 0.3915 - val_acc: 0.8982\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2358 - acc: 0.9399 - val_loss: 0.4083 - val_acc: 0.8863\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.2376 - acc: 0.9389 - val_loss: 0.4044 - val_acc: 0.8867\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2339 - acc: 0.9388 - val_loss: 0.3960 - val_acc: 0.8962\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2294 - acc: 0.9403 - val_loss: 0.3983 - val_acc: 0.8907\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2353 - acc: 0.9402 - val_loss: 0.3883 - val_acc: 0.8965\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2266 - acc: 0.9412 - val_loss: 0.3833 - val_acc: 0.9002\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2281 - acc: 0.9362 - val_loss: 0.3575 - val_acc: 0.9060\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2098 - acc: 0.9444 - val_loss: 0.3773 - val_acc: 0.9087\n",
      "Train accuracy 0.9468171926006529 Test accuracy: 0.9087207329487614\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_47 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 118, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                29984     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,054\n",
      "Trainable params: 37,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 30.7482 - acc: 0.6945 - val_loss: 12.6757 - val_acc: 0.7723\n",
      "Epoch 2/25\n",
      " - 4s - loss: 6.4228 - acc: 0.8815 - val_loss: 3.1017 - val_acc: 0.8789\n",
      "Epoch 3/25\n",
      " - 4s - loss: 1.5814 - acc: 0.9102 - val_loss: 1.1832 - val_acc: 0.8415\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.6271 - acc: 0.9207 - val_loss: 0.7677 - val_acc: 0.8867\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.4378 - acc: 0.9266 - val_loss: 0.6758 - val_acc: 0.8921\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.3849 - acc: 0.9309 - val_loss: 0.6361 - val_acc: 0.8884\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.3529 - acc: 0.9342 - val_loss: 0.6003 - val_acc: 0.8951\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.3389 - acc: 0.9325 - val_loss: 0.5626 - val_acc: 0.8962\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.3227 - acc: 0.9331 - val_loss: 0.5471 - val_acc: 0.8894\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.3194 - acc: 0.9285 - val_loss: 0.5725 - val_acc: 0.8802\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.2970 - acc: 0.9412 - val_loss: 0.5044 - val_acc: 0.8877\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.2911 - acc: 0.9347 - val_loss: 0.4854 - val_acc: 0.9084\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.2934 - acc: 0.9339 - val_loss: 0.5101 - val_acc: 0.8870\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.2692 - acc: 0.9387 - val_loss: 0.4758 - val_acc: 0.8979\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2700 - acc: 0.9382 - val_loss: 0.4790 - val_acc: 0.8826\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.2651 - acc: 0.9372 - val_loss: 0.4938 - val_acc: 0.8812\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.2556 - acc: 0.9411 - val_loss: 0.4576 - val_acc: 0.8948\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.2394 - acc: 0.9453 - val_loss: 0.4682 - val_acc: 0.8795\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2452 - acc: 0.9403 - val_loss: 0.4418 - val_acc: 0.8999\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2370 - acc: 0.9433 - val_loss: 0.4561 - val_acc: 0.8751\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.2469 - acc: 0.9373 - val_loss: 0.4023 - val_acc: 0.9002\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.2356 - acc: 0.9395 - val_loss: 0.4127 - val_acc: 0.9053\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.2262 - acc: 0.9427 - val_loss: 0.3983 - val_acc: 0.8999\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.2254 - acc: 0.9403 - val_loss: 0.4087 - val_acc: 0.9026\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2124 - acc: 0.9476 - val_loss: 0.4039 - val_acc: 0.9019\n",
      "Train accuracy 0.9514417845484222 Test accuracy: 0.9019341703427214\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 118, 16)           3152      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 39, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 32)                20000     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 24,638\n",
      "Trainable params: 24,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 4s - loss: 8.6196 - acc: 0.7390 - val_loss: 3.7160 - val_acc: 0.8921\n",
      "Epoch 2/25\n",
      " - 2s - loss: 1.9125 - acc: 0.9249 - val_loss: 1.1556 - val_acc: 0.8958\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.6494 - acc: 0.9402 - val_loss: 0.6623 - val_acc: 0.9023\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.3987 - acc: 0.9402 - val_loss: 0.5116 - val_acc: 0.8975\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.3087 - acc: 0.9438 - val_loss: 0.4542 - val_acc: 0.8938\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.2733 - acc: 0.9429 - val_loss: 0.4127 - val_acc: 0.9040\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.2379 - acc: 0.9464 - val_loss: 0.4030 - val_acc: 0.9091\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.2217 - acc: 0.9467 - val_loss: 0.3690 - val_acc: 0.9074\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.2187 - acc: 0.9442 - val_loss: 0.3577 - val_acc: 0.9148\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.2041 - acc: 0.9489 - val_loss: 0.3870 - val_acc: 0.8941\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.1949 - acc: 0.9483 - val_loss: 0.3585 - val_acc: 0.8935\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.1828 - acc: 0.9489 - val_loss: 0.3670 - val_acc: 0.8982\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2030 - acc: 0.9438 - val_loss: 0.3187 - val_acc: 0.9158\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.1789 - acc: 0.9501 - val_loss: 0.3459 - val_acc: 0.8999\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.1884 - acc: 0.9465 - val_loss: 0.3262 - val_acc: 0.9077\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.1741 - acc: 0.9499 - val_loss: 0.4076 - val_acc: 0.8697\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.1801 - acc: 0.9476 - val_loss: 0.3142 - val_acc: 0.9063\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.1716 - acc: 0.9508 - val_loss: 0.3178 - val_acc: 0.9033\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.1648 - acc: 0.9527 - val_loss: 0.3241 - val_acc: 0.8945\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.1716 - acc: 0.9498 - val_loss: 0.3180 - val_acc: 0.9128\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.1664 - acc: 0.9505 - val_loss: 0.3195 - val_acc: 0.8911\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.1597 - acc: 0.9521 - val_loss: 0.3119 - val_acc: 0.8968\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.1578 - acc: 0.9502 - val_loss: 0.3099 - val_acc: 0.8958\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.1659 - acc: 0.9482 - val_loss: 0.2908 - val_acc: 0.9033\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.1596 - acc: 0.9518 - val_loss: 0.3146 - val_acc: 0.8935\n",
      "Train accuracy 0.9575625680087051 Test accuracy: 0.8934509670851714\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 118, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 32)                29984     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,054\n",
      "Trainable params: 37,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 8.2183 - acc: 0.7568 - val_loss: 1.5245 - val_acc: 0.8459\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.6555 - acc: 0.9153 - val_loss: 0.6685 - val_acc: 0.8860\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.3905 - acc: 0.9204 - val_loss: 0.5843 - val_acc: 0.8666\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.3311 - acc: 0.9283 - val_loss: 0.5501 - val_acc: 0.8799\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.3065 - acc: 0.9280 - val_loss: 0.5932 - val_acc: 0.8005\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.2766 - acc: 0.9357 - val_loss: 0.4405 - val_acc: 0.8890\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.2612 - acc: 0.9365 - val_loss: 0.4637 - val_acc: 0.8731\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.2752 - acc: 0.9316 - val_loss: 0.4310 - val_acc: 0.8894\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.2395 - acc: 0.9377 - val_loss: 0.4556 - val_acc: 0.8714\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.2419 - acc: 0.9385 - val_loss: 0.6264 - val_acc: 0.8137\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.2520 - acc: 0.9359 - val_loss: 0.3904 - val_acc: 0.9033\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.2366 - acc: 0.9422 - val_loss: 0.3757 - val_acc: 0.9016\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.2257 - acc: 0.9410 - val_loss: 0.4105 - val_acc: 0.8911\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.2392 - acc: 0.9376 - val_loss: 0.3785 - val_acc: 0.8826\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2316 - acc: 0.9381 - val_loss: 0.4930 - val_acc: 0.8761\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.2187 - acc: 0.9445 - val_loss: 0.3751 - val_acc: 0.8904\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.2327 - acc: 0.9397 - val_loss: 0.4270 - val_acc: 0.8894\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.2185 - acc: 0.9434 - val_loss: 0.3625 - val_acc: 0.9043\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2102 - acc: 0.9448 - val_loss: 0.3493 - val_acc: 0.8979\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2091 - acc: 0.9461 - val_loss: 0.3420 - val_acc: 0.9019\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.1945 - acc: 0.9480 - val_loss: 0.4161 - val_acc: 0.8616\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.2100 - acc: 0.9427 - val_loss: 0.3706 - val_acc: 0.8897\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.2017 - acc: 0.9438 - val_loss: 0.4271 - val_acc: 0.8853\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.2043 - acc: 0.9440 - val_loss: 0.3463 - val_acc: 0.8968\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2002 - acc: 0.9445 - val_loss: 0.4215 - val_acc: 0.8907\n",
      "Train accuracy 0.9416485309471114 Test accuracy: 0.8907363420427553\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_53 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 118, 16)           3152      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 39, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 624)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 32)                20000     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 24,638\n",
      "Trainable params: 24,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 4s - loss: 21.1995 - acc: 0.7001 - val_loss: 10.0623 - val_acc: 0.8171\n",
      "Epoch 2/25\n",
      " - 2s - loss: 5.2907 - acc: 0.9090 - val_loss: 2.7035 - val_acc: 0.8785\n",
      "Epoch 3/25\n",
      " - 2s - loss: 1.3800 - acc: 0.9195 - val_loss: 1.0836 - val_acc: 0.8728\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.5472 - acc: 0.9278 - val_loss: 0.7491 - val_acc: 0.8670\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.3920 - acc: 0.9264 - val_loss: 0.6373 - val_acc: 0.8816\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3393 - acc: 0.9320 - val_loss: 0.5626 - val_acc: 0.8907\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.3163 - acc: 0.9339 - val_loss: 0.5400 - val_acc: 0.8999\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.2926 - acc: 0.9351 - val_loss: 0.5653 - val_acc: 0.8717\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.2879 - acc: 0.9351 - val_loss: 0.4906 - val_acc: 0.8802\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.2761 - acc: 0.9351 - val_loss: 0.5171 - val_acc: 0.8870\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2649 - acc: 0.9373 - val_loss: 0.5018 - val_acc: 0.8724\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.2614 - acc: 0.9359 - val_loss: 0.4748 - val_acc: 0.8731\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2491 - acc: 0.9402 - val_loss: 0.4643 - val_acc: 0.8945\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2494 - acc: 0.9396 - val_loss: 0.4874 - val_acc: 0.8765\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.2330 - acc: 0.9440 - val_loss: 0.4579 - val_acc: 0.9036\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.2394 - acc: 0.9393 - val_loss: 0.4404 - val_acc: 0.8897\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.2232 - acc: 0.9448 - val_loss: 0.4375 - val_acc: 0.8931\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2202 - acc: 0.9436 - val_loss: 0.4440 - val_acc: 0.8833\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.2301 - acc: 0.9393 - val_loss: 0.4260 - val_acc: 0.9053\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2273 - acc: 0.9399 - val_loss: 0.4500 - val_acc: 0.9033\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2151 - acc: 0.9422 - val_loss: 0.4379 - val_acc: 0.8816\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2092 - acc: 0.9464 - val_loss: 0.4113 - val_acc: 0.8972\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2051 - acc: 0.9448 - val_loss: 0.3817 - val_acc: 0.8989\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2300 - acc: 0.9369 - val_loss: 0.4581 - val_acc: 0.8904\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2039 - acc: 0.9455 - val_loss: 0.4044 - val_acc: 0.8853\n",
      "Train accuracy 0.9494015233949945 Test accuracy: 0.8853070919579233\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 120, 16)           2576      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 40, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 32)                20512     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 24,758\n",
      "Trainable params: 24,758\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 4s - loss: 20.9253 - acc: 0.7541 - val_loss: 1.3615 - val_acc: 0.8137\n",
      "Epoch 2/25\n",
      " - 3s - loss: 0.6803 - acc: 0.8592 - val_loss: 0.8534 - val_acc: 0.8263\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.5249 - acc: 0.8800 - val_loss: 0.6695 - val_acc: 0.8463\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.4987 - acc: 0.8794 - val_loss: 0.6479 - val_acc: 0.8721\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.4581 - acc: 0.8832 - val_loss: 0.6530 - val_acc: 0.8280\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.4513 - acc: 0.8852 - val_loss: 0.6092 - val_acc: 0.8765\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.4057 - acc: 0.9044 - val_loss: 0.5580 - val_acc: 0.8619\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.4046 - acc: 0.9015 - val_loss: 0.5896 - val_acc: 0.8527\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.4048 - acc: 0.8999 - val_loss: 0.5836 - val_acc: 0.8629\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.3715 - acc: 0.9117 - val_loss: 0.6280 - val_acc: 0.8174\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.3650 - acc: 0.9104 - val_loss: 0.5921 - val_acc: 0.8449\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.3500 - acc: 0.9138 - val_loss: 0.5282 - val_acc: 0.8636\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.3516 - acc: 0.9105 - val_loss: 0.5432 - val_acc: 0.8680\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.3617 - acc: 0.9134 - val_loss: 0.5011 - val_acc: 0.8687\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.3414 - acc: 0.9129 - val_loss: 0.5325 - val_acc: 0.8768\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.3380 - acc: 0.9142 - val_loss: 0.4699 - val_acc: 0.8775\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.3194 - acc: 0.9214 - val_loss: 0.5342 - val_acc: 0.8453\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.3163 - acc: 0.9211 - val_loss: 0.5421 - val_acc: 0.8368\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.3047 - acc: 0.9230 - val_loss: 0.4552 - val_acc: 0.8761\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.3207 - acc: 0.9183 - val_loss: 0.4877 - val_acc: 0.8561\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.3187 - acc: 0.9187 - val_loss: 0.4502 - val_acc: 0.8714\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.3164 - acc: 0.9180 - val_loss: 0.4595 - val_acc: 0.8812\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.3084 - acc: 0.9211 - val_loss: 0.4473 - val_acc: 0.8772\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.2982 - acc: 0.9255 - val_loss: 0.4461 - val_acc: 0.8938\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.3228 - acc: 0.9177 - val_loss: 0.4827 - val_acc: 0.8656\n",
      "Train accuracy 0.9287268770402611 Test accuracy: 0.8656260604004072\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 118, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 32)                29984     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,054\n",
      "Trainable params: 37,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 15.8902 - acc: 0.7901 - val_loss: 1.5902 - val_acc: 0.8619\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.6730 - acc: 0.8917 - val_loss: 0.6986 - val_acc: 0.8599\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.4482 - acc: 0.8988 - val_loss: 0.6891 - val_acc: 0.8375\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.4055 - acc: 0.9061 - val_loss: 0.5604 - val_acc: 0.8792\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.3848 - acc: 0.9143 - val_loss: 0.5358 - val_acc: 0.8928\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.3572 - acc: 0.9187 - val_loss: 0.5392 - val_acc: 0.8846\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.3428 - acc: 0.9166 - val_loss: 0.5019 - val_acc: 0.8856\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.3173 - acc: 0.9268 - val_loss: 0.5586 - val_acc: 0.8361\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.3008 - acc: 0.9256 - val_loss: 0.5069 - val_acc: 0.8527\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.3155 - acc: 0.9222 - val_loss: 0.4887 - val_acc: 0.8826\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.3025 - acc: 0.9255 - val_loss: 0.4418 - val_acc: 0.8911\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.2945 - acc: 0.9276 - val_loss: 0.4566 - val_acc: 0.8782\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.2833 - acc: 0.9282 - val_loss: 0.4643 - val_acc: 0.8670\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.2811 - acc: 0.9268 - val_loss: 0.4348 - val_acc: 0.8785\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2736 - acc: 0.9316 - val_loss: 0.5820 - val_acc: 0.8005\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.2745 - acc: 0.9300 - val_loss: 0.4390 - val_acc: 0.8867\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.2730 - acc: 0.9280 - val_loss: 0.4034 - val_acc: 0.8897\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.2631 - acc: 0.9329 - val_loss: 0.3644 - val_acc: 0.9006\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2693 - acc: 0.9280 - val_loss: 0.4187 - val_acc: 0.8714\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2544 - acc: 0.9338 - val_loss: 0.4191 - val_acc: 0.8744\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.2605 - acc: 0.9304 - val_loss: 0.3695 - val_acc: 0.9087\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.2488 - acc: 0.9366 - val_loss: 0.3962 - val_acc: 0.8751\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.2472 - acc: 0.9350 - val_loss: 0.3843 - val_acc: 0.8918\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.2666 - acc: 0.9301 - val_loss: 0.4031 - val_acc: 0.8731\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2480 - acc: 0.9358 - val_loss: 0.3756 - val_acc: 0.8778\n",
      "Train accuracy 0.9447769314472253 Test accuracy: 0.8778418730912793\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_59 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 118, 24)           4728      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 32)                29984     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 36,198\n",
      "Trainable params: 36,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 9.9628 - acc: 0.7378 - val_loss: 0.9818 - val_acc: 0.8039\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.5760 - acc: 0.8694 - val_loss: 0.7367 - val_acc: 0.8405\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.4965 - acc: 0.8825 - val_loss: 0.8518 - val_acc: 0.7570\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.4417 - acc: 0.8930 - val_loss: 0.8363 - val_acc: 0.7428\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.4082 - acc: 0.9015 - val_loss: 0.6166 - val_acc: 0.8670\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.4024 - acc: 0.8995 - val_loss: 0.6572 - val_acc: 0.8242\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.3734 - acc: 0.9079 - val_loss: 0.6035 - val_acc: 0.8426\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.3609 - acc: 0.9095 - val_loss: 0.5459 - val_acc: 0.8609\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.3459 - acc: 0.9165 - val_loss: 0.5682 - val_acc: 0.8541\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.3371 - acc: 0.9139 - val_loss: 0.5187 - val_acc: 0.8772\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.3281 - acc: 0.9200 - val_loss: 0.5440 - val_acc: 0.8524\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.3103 - acc: 0.9214 - val_loss: 0.5263 - val_acc: 0.8660\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.3046 - acc: 0.9252 - val_loss: 0.4650 - val_acc: 0.8877\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.2900 - acc: 0.9289 - val_loss: 0.5126 - val_acc: 0.8666\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2861 - acc: 0.9278 - val_loss: 0.4231 - val_acc: 0.8958\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.2813 - acc: 0.9263 - val_loss: 0.5353 - val_acc: 0.8578\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.2700 - acc: 0.9306 - val_loss: 0.4654 - val_acc: 0.8721\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.2736 - acc: 0.9305 - val_loss: 0.4120 - val_acc: 0.8955\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2544 - acc: 0.9359 - val_loss: 0.4773 - val_acc: 0.8724\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2581 - acc: 0.9308 - val_loss: 0.4545 - val_acc: 0.8812\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.2573 - acc: 0.9329 - val_loss: 0.4221 - val_acc: 0.8948\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.2472 - acc: 0.9343 - val_loss: 0.4365 - val_acc: 0.8744\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.2446 - acc: 0.9338 - val_loss: 0.4151 - val_acc: 0.8819\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.2453 - acc: 0.9348 - val_loss: 0.4562 - val_acc: 0.8795\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2536 - acc: 0.9321 - val_loss: 0.3726 - val_acc: 0.9033\n",
      "Train accuracy 0.9440968443960827 Test accuracy: 0.9032914828639295\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_61 (Conv1D)           (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 120, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 60, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                46112     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 52,606\n",
      "Trainable params: 52,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 32.2143 - acc: 0.7006 - val_loss: 12.4195 - val_acc: 0.8276\n",
      "Epoch 2/25\n",
      " - 4s - loss: 6.3320 - acc: 0.8531 - val_loss: 2.9475 - val_acc: 0.8402\n",
      "Epoch 3/25\n",
      " - 4s - loss: 1.5363 - acc: 0.8766 - val_loss: 1.0293 - val_acc: 0.8327\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.6344 - acc: 0.8879 - val_loss: 0.7495 - val_acc: 0.7896\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.4675 - acc: 0.9006 - val_loss: 0.6167 - val_acc: 0.8585\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.4215 - acc: 0.9052 - val_loss: 0.5821 - val_acc: 0.8558\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.3993 - acc: 0.9055 - val_loss: 0.5463 - val_acc: 0.8748\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.3875 - acc: 0.9042 - val_loss: 0.5566 - val_acc: 0.8806\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.3564 - acc: 0.9143 - val_loss: 0.5258 - val_acc: 0.8663\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.3469 - acc: 0.9197 - val_loss: 0.4740 - val_acc: 0.9026\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.3377 - acc: 0.9176 - val_loss: 0.4737 - val_acc: 0.8816\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.3217 - acc: 0.9226 - val_loss: 0.4828 - val_acc: 0.8839\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.3227 - acc: 0.9212 - val_loss: 0.4552 - val_acc: 0.9006\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.3117 - acc: 0.9256 - val_loss: 0.4900 - val_acc: 0.8758\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2957 - acc: 0.9286 - val_loss: 0.4653 - val_acc: 0.8890\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.2941 - acc: 0.9252 - val_loss: 0.4273 - val_acc: 0.8941\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.2900 - acc: 0.9291 - val_loss: 0.4684 - val_acc: 0.8602\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.2824 - acc: 0.9279 - val_loss: 0.4394 - val_acc: 0.8768\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2770 - acc: 0.9327 - val_loss: 0.4269 - val_acc: 0.8948\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2645 - acc: 0.9331 - val_loss: 0.4069 - val_acc: 0.8867\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.2625 - acc: 0.9362 - val_loss: 0.4195 - val_acc: 0.8789\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.2693 - acc: 0.9294 - val_loss: 0.4198 - val_acc: 0.8911\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.2496 - acc: 0.9376 - val_loss: 0.3832 - val_acc: 0.8985\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.2473 - acc: 0.9369 - val_loss: 0.4074 - val_acc: 0.8812\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2498 - acc: 0.9347 - val_loss: 0.4370 - val_acc: 0.8911\n",
      "Train accuracy 0.9287268770402611 Test accuracy: 0.8910756701730573\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 120, 32)           4512      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 32)                40992     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 46,990\n",
      "Trainable params: 46,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 5s - loss: 20.4811 - acc: 0.7839 - val_loss: 3.7449 - val_acc: 0.7988\n",
      "Epoch 2/35\n",
      " - 3s - loss: 1.2836 - acc: 0.9049 - val_loss: 0.8167 - val_acc: 0.8208\n",
      "Epoch 3/35\n",
      " - 3s - loss: 0.4713 - acc: 0.9029 - val_loss: 0.6202 - val_acc: 0.8897\n",
      "Epoch 4/35\n",
      " - 3s - loss: 0.4039 - acc: 0.9140 - val_loss: 0.6257 - val_acc: 0.8714\n",
      "Epoch 5/35\n",
      " - 3s - loss: 0.3537 - acc: 0.9248 - val_loss: 0.5373 - val_acc: 0.8792\n",
      "Epoch 6/35\n",
      " - 3s - loss: 0.3418 - acc: 0.9221 - val_loss: 0.5179 - val_acc: 0.8863\n",
      "Epoch 7/35\n",
      " - 3s - loss: 0.3141 - acc: 0.9297 - val_loss: 0.4832 - val_acc: 0.9043\n",
      "Epoch 8/35\n",
      " - 3s - loss: 0.3211 - acc: 0.9251 - val_loss: 0.4651 - val_acc: 0.8962\n",
      "Epoch 9/35\n",
      " - 3s - loss: 0.2915 - acc: 0.9308 - val_loss: 0.4530 - val_acc: 0.9026\n",
      "Epoch 10/35\n",
      " - 3s - loss: 0.2804 - acc: 0.9317 - val_loss: 0.4376 - val_acc: 0.8975\n",
      "Epoch 11/35\n",
      " - 3s - loss: 0.2675 - acc: 0.9344 - val_loss: 0.4519 - val_acc: 0.8823\n",
      "Epoch 12/35\n",
      " - 3s - loss: 0.2715 - acc: 0.9338 - val_loss: 0.5556 - val_acc: 0.8544\n",
      "Epoch 13/35\n",
      " - 3s - loss: 0.2862 - acc: 0.9304 - val_loss: 0.4472 - val_acc: 0.8755\n",
      "Epoch 14/35\n",
      " - 3s - loss: 0.2581 - acc: 0.9335 - val_loss: 0.4250 - val_acc: 0.8853\n",
      "Epoch 15/35\n",
      " - 3s - loss: 0.2584 - acc: 0.9340 - val_loss: 0.4055 - val_acc: 0.9002\n",
      "Epoch 16/35\n",
      " - 3s - loss: 0.2548 - acc: 0.9368 - val_loss: 0.3967 - val_acc: 0.8941\n",
      "Epoch 17/35\n",
      " - 3s - loss: 0.2362 - acc: 0.9387 - val_loss: 0.3925 - val_acc: 0.8972\n",
      "Epoch 18/35\n",
      " - 3s - loss: 0.2431 - acc: 0.9382 - val_loss: 0.4084 - val_acc: 0.8948\n",
      "Epoch 19/35\n",
      " - 3s - loss: 0.2411 - acc: 0.9362 - val_loss: 0.3832 - val_acc: 0.9053\n",
      "Epoch 20/35\n",
      " - 3s - loss: 0.2382 - acc: 0.9374 - val_loss: 0.4067 - val_acc: 0.8918\n",
      "Epoch 21/35\n",
      " - 3s - loss: 0.2559 - acc: 0.9350 - val_loss: 0.4027 - val_acc: 0.8941\n",
      "Epoch 22/35\n",
      " - 3s - loss: 0.2368 - acc: 0.9359 - val_loss: 0.4339 - val_acc: 0.8890\n",
      "Epoch 23/35\n",
      " - 3s - loss: 0.2401 - acc: 0.9314 - val_loss: 0.3901 - val_acc: 0.8890\n",
      "Epoch 24/35\n",
      " - 3s - loss: 0.2324 - acc: 0.9391 - val_loss: 0.3588 - val_acc: 0.8962\n",
      "Epoch 25/35\n",
      " - 3s - loss: 0.2315 - acc: 0.9385 - val_loss: 0.4640 - val_acc: 0.8728\n",
      "Epoch 26/35\n",
      " - 3s - loss: 0.2378 - acc: 0.9380 - val_loss: 0.3979 - val_acc: 0.8795\n",
      "Epoch 27/35\n",
      " - 3s - loss: 0.2238 - acc: 0.9378 - val_loss: 0.3723 - val_acc: 0.8809\n",
      "Epoch 28/35\n",
      " - 3s - loss: 0.2224 - acc: 0.9418 - val_loss: 0.3706 - val_acc: 0.8948\n",
      "Epoch 29/35\n",
      " - 3s - loss: 0.2195 - acc: 0.9406 - val_loss: 0.3572 - val_acc: 0.8938\n",
      "Epoch 30/35\n",
      " - 3s - loss: 0.2308 - acc: 0.9374 - val_loss: 0.3824 - val_acc: 0.8870\n",
      "Epoch 31/35\n",
      " - 3s - loss: 0.2183 - acc: 0.9415 - val_loss: 0.4050 - val_acc: 0.8819\n",
      "Epoch 32/35\n",
      " - 3s - loss: 0.2223 - acc: 0.9377 - val_loss: 0.3652 - val_acc: 0.8928\n",
      "Epoch 33/35\n",
      " - 3s - loss: 0.2135 - acc: 0.9400 - val_loss: 0.3510 - val_acc: 0.9063\n",
      "Epoch 34/35\n",
      " - 3s - loss: 0.2112 - acc: 0.9388 - val_loss: 0.3684 - val_acc: 0.8948\n",
      "Epoch 35/35\n",
      " - 3s - loss: 0.2198 - acc: 0.9397 - val_loss: 0.3414 - val_acc: 0.9013\n",
      "Train accuracy 0.9540261153427638 Test accuracy: 0.9012555140821175\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_65 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 118, 16)           3600      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 59, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 944)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 32)                30240     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 35,510\n",
      "Trainable params: 35,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 2.4119 - acc: 0.8198 - val_loss: 0.7778 - val_acc: 0.8229\n",
      "Epoch 2/25\n",
      " - 5s - loss: 0.4228 - acc: 0.9158 - val_loss: 0.5392 - val_acc: 0.8924\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.3405 - acc: 0.9312 - val_loss: 0.5935 - val_acc: 0.8582\n",
      "Epoch 4/25\n",
      " - 5s - loss: 0.2995 - acc: 0.9391 - val_loss: 0.6060 - val_acc: 0.8198\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.2902 - acc: 0.9339 - val_loss: 0.3616 - val_acc: 0.8989\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.2491 - acc: 0.9442 - val_loss: 0.3794 - val_acc: 0.8935\n",
      "Epoch 7/25\n",
      " - 5s - loss: 0.2455 - acc: 0.9406 - val_loss: 0.3848 - val_acc: 0.8924\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.2234 - acc: 0.9431 - val_loss: 0.4754 - val_acc: 0.8558\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.2337 - acc: 0.9430 - val_loss: 0.3442 - val_acc: 0.9080\n",
      "Epoch 10/25\n",
      " - 5s - loss: 0.2033 - acc: 0.9452 - val_loss: 0.3499 - val_acc: 0.9162\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.1916 - acc: 0.9461 - val_loss: 0.3332 - val_acc: 0.8972\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.1959 - acc: 0.9495 - val_loss: 0.3921 - val_acc: 0.8836\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.2336 - acc: 0.9418 - val_loss: 0.3809 - val_acc: 0.8989\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.1905 - acc: 0.9497 - val_loss: 0.3034 - val_acc: 0.9131\n",
      "Epoch 15/25\n",
      " - 5s - loss: 0.1843 - acc: 0.9484 - val_loss: 0.3028 - val_acc: 0.8992\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.1848 - acc: 0.9478 - val_loss: 0.4612 - val_acc: 0.8806\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.1932 - acc: 0.9478 - val_loss: 0.3630 - val_acc: 0.9131\n",
      "Epoch 18/25\n",
      " - 5s - loss: 0.1895 - acc: 0.9471 - val_loss: 0.3528 - val_acc: 0.8928\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.1685 - acc: 0.9494 - val_loss: 0.3101 - val_acc: 0.9067\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.1716 - acc: 0.9497 - val_loss: 0.2922 - val_acc: 0.9077\n",
      "Epoch 21/25\n",
      " - 5s - loss: 0.1626 - acc: 0.9532 - val_loss: 0.2974 - val_acc: 0.8901\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.1713 - acc: 0.9516 - val_loss: 0.3523 - val_acc: 0.8833\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.1687 - acc: 0.9505 - val_loss: 0.3381 - val_acc: 0.8945\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.1799 - acc: 0.9484 - val_loss: 0.2832 - val_acc: 0.9138\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.1663 - acc: 0.9517 - val_loss: 0.3124 - val_acc: 0.9152\n",
      "Train accuracy 0.9585146898803046 Test accuracy: 0.9151679674244995\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 122, 28)           1792      \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 118, 16)           2256      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 59, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 944)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 32)                30240     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 34,486\n",
      "Trainable params: 34,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 4s - loss: 2.2122 - acc: 0.8433 - val_loss: 0.5873 - val_acc: 0.8965\n",
      "Epoch 2/25\n",
      " - 2s - loss: 0.3555 - acc: 0.9280 - val_loss: 0.4135 - val_acc: 0.9046\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.2836 - acc: 0.9344 - val_loss: 0.5157 - val_acc: 0.8544\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.2740 - acc: 0.9355 - val_loss: 0.3735 - val_acc: 0.9040\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.2601 - acc: 0.9325 - val_loss: 0.3419 - val_acc: 0.9226\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.2409 - acc: 0.9418 - val_loss: 0.4031 - val_acc: 0.8795\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.2663 - acc: 0.9344 - val_loss: 0.3566 - val_acc: 0.8924\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.2545 - acc: 0.9355 - val_loss: 0.3538 - val_acc: 0.9074\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.2184 - acc: 0.9423 - val_loss: 0.3228 - val_acc: 0.9158\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.2392 - acc: 0.9380 - val_loss: 0.3983 - val_acc: 0.8887\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2166 - acc: 0.9396 - val_loss: 0.3430 - val_acc: 0.8992\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.2218 - acc: 0.9414 - val_loss: 0.3157 - val_acc: 0.9125\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2486 - acc: 0.9331 - val_loss: 0.4027 - val_acc: 0.8972\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.1996 - acc: 0.9471 - val_loss: 0.3472 - val_acc: 0.9009\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.2281 - acc: 0.9397 - val_loss: 0.4514 - val_acc: 0.8823\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.2149 - acc: 0.9430 - val_loss: 0.3734 - val_acc: 0.9009\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.1987 - acc: 0.9427 - val_loss: 0.3768 - val_acc: 0.8884\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2461 - acc: 0.9332 - val_loss: 0.3856 - val_acc: 0.9002\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.2026 - acc: 0.9445 - val_loss: 0.3621 - val_acc: 0.9050\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2095 - acc: 0.9445 - val_loss: 0.3526 - val_acc: 0.9023\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2152 - acc: 0.9415 - val_loss: 0.4049 - val_acc: 0.8890\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2125 - acc: 0.9431 - val_loss: 0.4043 - val_acc: 0.8935\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.1983 - acc: 0.9425 - val_loss: 0.3984 - val_acc: 0.8636\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2078 - acc: 0.9423 - val_loss: 0.3213 - val_acc: 0.9040\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2058 - acc: 0.9430 - val_loss: 0.3594 - val_acc: 0.8938\n",
      "Train accuracy 0.934031556039173 Test accuracy: 0.8937902952154734\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_69 (Conv1D)           (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 120, 16)           3600      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 60, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 32)                30752     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 35,446\n",
      "Trainable params: 35,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 6s - loss: 2.5612 - acc: 0.7599 - val_loss: 0.7490 - val_acc: 0.8018\n",
      "Epoch 2/35\n",
      " - 5s - loss: 0.4629 - acc: 0.9034 - val_loss: 0.5412 - val_acc: 0.8799\n",
      "Epoch 3/35\n",
      " - 4s - loss: 0.3807 - acc: 0.9203 - val_loss: 0.4479 - val_acc: 0.8914\n",
      "Epoch 4/35\n",
      " - 4s - loss: 0.3636 - acc: 0.9270 - val_loss: 0.4425 - val_acc: 0.8853\n",
      "Epoch 5/35\n",
      " - 5s - loss: 0.3062 - acc: 0.9295 - val_loss: 0.3972 - val_acc: 0.8846\n",
      "Epoch 6/35\n",
      " - 4s - loss: 0.2649 - acc: 0.9384 - val_loss: 0.3870 - val_acc: 0.8962\n",
      "Epoch 7/35\n",
      " - 4s - loss: 0.2820 - acc: 0.9362 - val_loss: 0.4678 - val_acc: 0.8806\n",
      "Epoch 8/35\n",
      " - 4s - loss: 0.2970 - acc: 0.9304 - val_loss: 0.4722 - val_acc: 0.8867\n",
      "Epoch 9/35\n",
      " - 4s - loss: 0.2377 - acc: 0.9436 - val_loss: 0.4379 - val_acc: 0.8704\n",
      "Epoch 10/35\n",
      " - 5s - loss: 0.2221 - acc: 0.9407 - val_loss: 0.4688 - val_acc: 0.8636\n",
      "Epoch 11/35\n",
      " - 4s - loss: 0.2250 - acc: 0.9423 - val_loss: 0.4391 - val_acc: 0.8656\n",
      "Epoch 12/35\n",
      " - 4s - loss: 0.2381 - acc: 0.9431 - val_loss: 0.3621 - val_acc: 0.8996\n",
      "Epoch 13/35\n",
      " - 5s - loss: 0.2137 - acc: 0.9442 - val_loss: 0.4561 - val_acc: 0.8877\n",
      "Epoch 14/35\n",
      " - 4s - loss: 0.2428 - acc: 0.9430 - val_loss: 0.3843 - val_acc: 0.8955\n",
      "Epoch 15/35\n",
      " - 4s - loss: 0.2032 - acc: 0.9476 - val_loss: 0.4148 - val_acc: 0.8839\n",
      "Epoch 16/35\n",
      " - 5s - loss: 0.2330 - acc: 0.9427 - val_loss: 0.3740 - val_acc: 0.8958\n",
      "Epoch 17/35\n",
      " - 4s - loss: 0.2696 - acc: 0.9374 - val_loss: 0.5510 - val_acc: 0.8829\n",
      "Epoch 18/35\n",
      " - 4s - loss: 0.1959 - acc: 0.9508 - val_loss: 0.3538 - val_acc: 0.9043\n",
      "Epoch 19/35\n",
      " - 4s - loss: 0.2249 - acc: 0.9470 - val_loss: 0.3870 - val_acc: 0.8996\n",
      "Epoch 20/35\n",
      " - 4s - loss: 0.1939 - acc: 0.9494 - val_loss: 0.3746 - val_acc: 0.8968\n",
      "Epoch 21/35\n",
      " - 4s - loss: 0.1891 - acc: 0.9498 - val_loss: 0.3758 - val_acc: 0.8951\n",
      "Epoch 22/35\n",
      " - 4s - loss: 0.2256 - acc: 0.9452 - val_loss: 0.4527 - val_acc: 0.8724\n",
      "Epoch 23/35\n",
      " - 4s - loss: 0.2121 - acc: 0.9483 - val_loss: 0.3777 - val_acc: 0.8921\n",
      "Epoch 24/35\n",
      " - 4s - loss: 0.1988 - acc: 0.9482 - val_loss: 0.4232 - val_acc: 0.8921\n",
      "Epoch 25/35\n",
      " - 4s - loss: 0.1821 - acc: 0.9497 - val_loss: 0.4229 - val_acc: 0.8782\n",
      "Epoch 26/35\n",
      " - 4s - loss: 0.1841 - acc: 0.9525 - val_loss: 0.4539 - val_acc: 0.8612\n",
      "Epoch 27/35\n",
      " - 4s - loss: 0.1986 - acc: 0.9450 - val_loss: 0.4321 - val_acc: 0.8711\n",
      "Epoch 28/35\n",
      " - 4s - loss: 0.1956 - acc: 0.9479 - val_loss: 0.3892 - val_acc: 0.8836\n",
      "Epoch 29/35\n",
      " - 4s - loss: 0.1886 - acc: 0.9470 - val_loss: 0.5471 - val_acc: 0.8592\n",
      "Epoch 30/35\n",
      " - 5s - loss: 0.1883 - acc: 0.9493 - val_loss: 0.5066 - val_acc: 0.8599\n",
      "Epoch 31/35\n",
      " - 4s - loss: 0.2226 - acc: 0.9461 - val_loss: 0.4548 - val_acc: 0.8673\n",
      "Epoch 32/35\n",
      " - 4s - loss: 0.1762 - acc: 0.9516 - val_loss: 0.3916 - val_acc: 0.8795\n",
      "Epoch 33/35\n",
      " - 5s - loss: 0.1942 - acc: 0.9505 - val_loss: 0.4922 - val_acc: 0.8646\n",
      "Epoch 34/35\n",
      " - 4s - loss: 0.1785 - acc: 0.9502 - val_loss: 0.3825 - val_acc: 0.8955\n",
      "Epoch 35/35\n",
      " - 4s - loss: 0.2650 - acc: 0.9429 - val_loss: 0.4766 - val_acc: 0.8633\n",
      "Train accuracy 0.9304951033732318 Test accuracy: 0.8632507634882932\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_71 (Conv1D)           (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 118, 16)           3152      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 59, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 944)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 64)                60480     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 65,310\n",
      "Trainable params: 65,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 4s - loss: 5.5761 - acc: 0.8137 - val_loss: 0.7347 - val_acc: 0.7832\n",
      "Epoch 2/25\n",
      " - 2s - loss: 0.4795 - acc: 0.8924 - val_loss: 0.5773 - val_acc: 0.8768\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.4126 - acc: 0.9064 - val_loss: 0.5362 - val_acc: 0.8778\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.4368 - acc: 0.8969 - val_loss: 0.5178 - val_acc: 0.8928\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.3629 - acc: 0.9162 - val_loss: 0.5410 - val_acc: 0.8748\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3657 - acc: 0.9134 - val_loss: 0.5629 - val_acc: 0.8392\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.3419 - acc: 0.9199 - val_loss: 0.5049 - val_acc: 0.8656\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3261 - acc: 0.9197 - val_loss: 0.4725 - val_acc: 0.8806\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.3275 - acc: 0.9229 - val_loss: 0.4221 - val_acc: 0.8850\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.3101 - acc: 0.9227 - val_loss: 0.4963 - val_acc: 0.8877\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.3072 - acc: 0.9267 - val_loss: 0.4794 - val_acc: 0.8765\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.3274 - acc: 0.9185 - val_loss: 0.4268 - val_acc: 0.8656\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.3060 - acc: 0.9252 - val_loss: 0.5090 - val_acc: 0.8612\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.3193 - acc: 0.9236 - val_loss: 0.4052 - val_acc: 0.8839\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.3037 - acc: 0.9200 - val_loss: 0.4777 - val_acc: 0.8636\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.3061 - acc: 0.9241 - val_loss: 0.3998 - val_acc: 0.8775\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.2884 - acc: 0.9282 - val_loss: 0.7031 - val_acc: 0.7509\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.3100 - acc: 0.9229 - val_loss: 0.7581 - val_acc: 0.7760\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.3268 - acc: 0.9197 - val_loss: 0.5099 - val_acc: 0.8497\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2762 - acc: 0.9279 - val_loss: 0.4932 - val_acc: 0.8680\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.3013 - acc: 0.9251 - val_loss: 0.4776 - val_acc: 0.8541\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2814 - acc: 0.9266 - val_loss: 0.5030 - val_acc: 0.8558\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.3099 - acc: 0.9173 - val_loss: 0.5241 - val_acc: 0.8320\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2794 - acc: 0.9260 - val_loss: 0.4706 - val_acc: 0.8544\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2760 - acc: 0.9255 - val_loss: 0.5598 - val_acc: 0.8378\n",
      "Train accuracy 0.891050054406964 Test accuracy: 0.837801153715643\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 116, 16)           4720      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 116, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 58, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 928)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 32)                29728     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,334\n",
      "Trainable params: 37,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 5s - loss: 2.5312 - acc: 0.7933 - val_loss: 0.5613 - val_acc: 0.8683\n",
      "Epoch 2/35\n",
      " - 3s - loss: 0.4623 - acc: 0.8867 - val_loss: 0.5049 - val_acc: 0.8884\n",
      "Epoch 3/35\n",
      " - 3s - loss: 0.4133 - acc: 0.9018 - val_loss: 0.4686 - val_acc: 0.8772\n",
      "Epoch 4/35\n",
      " - 4s - loss: 0.3690 - acc: 0.9061 - val_loss: 0.4792 - val_acc: 0.8694\n",
      "Epoch 5/35\n",
      " - 3s - loss: 0.3565 - acc: 0.9120 - val_loss: 0.5586 - val_acc: 0.8527\n",
      "Epoch 6/35\n",
      " - 3s - loss: 0.3525 - acc: 0.9124 - val_loss: 1.8120 - val_acc: 0.6064\n",
      "Epoch 7/35\n",
      " - 3s - loss: 0.3508 - acc: 0.9075 - val_loss: 0.8299 - val_acc: 0.8154\n",
      "Epoch 8/35\n",
      " - 3s - loss: 0.3660 - acc: 0.9108 - val_loss: 0.5537 - val_acc: 0.8361\n",
      "Epoch 9/35\n",
      " - 3s - loss: 0.3443 - acc: 0.9105 - val_loss: 0.5436 - val_acc: 0.8480\n",
      "Epoch 10/35\n",
      " - 4s - loss: 0.3360 - acc: 0.9101 - val_loss: 0.4817 - val_acc: 0.8605\n",
      "Epoch 11/35\n",
      " - 3s - loss: 0.3405 - acc: 0.9128 - val_loss: 0.7536 - val_acc: 0.7855\n",
      "Epoch 12/35\n",
      " - 3s - loss: 0.3422 - acc: 0.9095 - val_loss: 0.3939 - val_acc: 0.8734\n",
      "Epoch 13/35\n",
      " - 3s - loss: 0.3373 - acc: 0.9093 - val_loss: 0.4616 - val_acc: 0.8792\n",
      "Epoch 14/35\n",
      " - 3s - loss: 0.3444 - acc: 0.9128 - val_loss: 0.4564 - val_acc: 0.8619\n",
      "Epoch 15/35\n",
      " - 3s - loss: 0.3242 - acc: 0.9191 - val_loss: 0.4572 - val_acc: 0.8622\n",
      "Epoch 16/35\n",
      " - 3s - loss: 0.3480 - acc: 0.9121 - val_loss: 0.4201 - val_acc: 0.8795\n",
      "Epoch 17/35\n",
      " - 3s - loss: 0.3233 - acc: 0.9189 - val_loss: 0.5386 - val_acc: 0.8473\n",
      "Epoch 18/35\n",
      " - 3s - loss: 0.3296 - acc: 0.9112 - val_loss: 0.4228 - val_acc: 0.8850\n",
      "Epoch 19/35\n",
      " - 4s - loss: 0.3336 - acc: 0.9151 - val_loss: 0.4307 - val_acc: 0.8643\n",
      "Epoch 20/35\n",
      " - 3s - loss: 0.3377 - acc: 0.9127 - val_loss: 0.5739 - val_acc: 0.8483\n",
      "Epoch 21/35\n",
      " - 3s - loss: 0.3313 - acc: 0.9158 - val_loss: 0.5802 - val_acc: 0.8544\n",
      "Epoch 22/35\n",
      " - 3s - loss: 0.3213 - acc: 0.9181 - val_loss: 0.5462 - val_acc: 0.8286\n",
      "Epoch 23/35\n",
      " - 3s - loss: 0.3313 - acc: 0.9120 - val_loss: 0.3995 - val_acc: 0.8992\n",
      "Epoch 24/35\n",
      " - 3s - loss: 0.3287 - acc: 0.9095 - val_loss: 0.4161 - val_acc: 0.8799\n",
      "Epoch 25/35\n",
      " - 4s - loss: 0.3203 - acc: 0.9138 - val_loss: 0.4464 - val_acc: 0.8741\n",
      "Epoch 26/35\n",
      " - 4s - loss: 0.3230 - acc: 0.9132 - val_loss: 0.5774 - val_acc: 0.8409\n",
      "Epoch 27/35\n",
      " - 3s - loss: 0.3279 - acc: 0.9131 - val_loss: 0.7065 - val_acc: 0.8107\n",
      "Epoch 28/35\n",
      " - 3s - loss: 0.3305 - acc: 0.9129 - val_loss: 0.3893 - val_acc: 0.9023\n",
      "Epoch 29/35\n",
      " - 4s - loss: 0.3362 - acc: 0.9135 - val_loss: 0.5070 - val_acc: 0.8371\n",
      "Epoch 30/35\n",
      " - 3s - loss: 0.3317 - acc: 0.9200 - val_loss: 0.4695 - val_acc: 0.8812\n",
      "Epoch 31/35\n",
      " - 3s - loss: 0.3269 - acc: 0.9131 - val_loss: 1.2070 - val_acc: 0.7750\n",
      "Epoch 32/35\n",
      " - 3s - loss: 0.3240 - acc: 0.9163 - val_loss: 0.4437 - val_acc: 0.8622\n",
      "Epoch 33/35\n",
      " - 3s - loss: 0.3274 - acc: 0.9176 - val_loss: 0.6468 - val_acc: 0.8449\n",
      "Epoch 34/35\n",
      " - 3s - loss: 0.3402 - acc: 0.9150 - val_loss: 0.3913 - val_acc: 0.8870\n",
      "Epoch 35/35\n",
      " - 3s - loss: 0.3264 - acc: 0.9176 - val_loss: 0.4415 - val_acc: 0.8901\n",
      "Train accuracy 0.9294069640914037 Test accuracy: 0.8900576857821514\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 120, 16)           2576      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 60, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 32)                30752     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 34,998\n",
      "Trainable params: 34,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 5.6099 - acc: 0.7828 - val_loss: 0.6939 - val_acc: 0.8517\n",
      "Epoch 2/25\n",
      " - 3s - loss: 0.5010 - acc: 0.8832 - val_loss: 0.6320 - val_acc: 0.8660\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.4524 - acc: 0.8980 - val_loss: 0.6079 - val_acc: 0.8198\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.4149 - acc: 0.9021 - val_loss: 0.6310 - val_acc: 0.8578\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.3934 - acc: 0.9059 - val_loss: 0.5392 - val_acc: 0.8622\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.3836 - acc: 0.9074 - val_loss: 0.5226 - val_acc: 0.8697\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.3900 - acc: 0.9057 - val_loss: 0.6099 - val_acc: 0.8239\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.3778 - acc: 0.9086 - val_loss: 0.5498 - val_acc: 0.8507\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.3354 - acc: 0.9192 - val_loss: 0.5142 - val_acc: 0.8799\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.3553 - acc: 0.9129 - val_loss: 0.5267 - val_acc: 0.8456\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.3488 - acc: 0.9151 - val_loss: 0.4650 - val_acc: 0.8633\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.3224 - acc: 0.9191 - val_loss: 0.6858 - val_acc: 0.8144\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.3712 - acc: 0.9125 - val_loss: 0.5496 - val_acc: 0.8612\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.3105 - acc: 0.9275 - val_loss: 0.4865 - val_acc: 0.8795\n",
      "Epoch 15/25\n",
      " - 3s - loss: 0.3486 - acc: 0.9153 - val_loss: 0.4788 - val_acc: 0.8839\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.3032 - acc: 0.9242 - val_loss: 0.4418 - val_acc: 0.8938\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.2958 - acc: 0.9246 - val_loss: 0.4957 - val_acc: 0.8775\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.3211 - acc: 0.9178 - val_loss: 0.4835 - val_acc: 0.8622\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.3163 - acc: 0.9208 - val_loss: 0.4780 - val_acc: 0.8626\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.2868 - acc: 0.9280 - val_loss: 0.5658 - val_acc: 0.8269\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.2977 - acc: 0.9286 - val_loss: 0.4155 - val_acc: 0.8806\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.2764 - acc: 0.9282 - val_loss: 0.4576 - val_acc: 0.8483\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.3157 - acc: 0.9196 - val_loss: 0.5375 - val_acc: 0.8537\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.2962 - acc: 0.9276 - val_loss: 0.6315 - val_acc: 0.8537\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.2972 - acc: 0.9260 - val_loss: 0.4336 - val_acc: 0.8724\n",
      "Train accuracy 0.941784548422198 Test accuracy: 0.8724126230064473\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_77 (Conv1D)           (None, 126, 28)           784       \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 120, 16)           3152      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 60, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 32)                30752     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 34,886\n",
      "Trainable params: 34,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 4s - loss: 3.5671 - acc: 0.7036 - val_loss: 0.7161 - val_acc: 0.8208\n",
      "Epoch 2/25\n",
      " - 2s - loss: 0.5217 - acc: 0.8678 - val_loss: 0.6253 - val_acc: 0.8409\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.4482 - acc: 0.8853 - val_loss: 0.5464 - val_acc: 0.8439\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.4033 - acc: 0.8969 - val_loss: 0.4733 - val_acc: 0.8677\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.3860 - acc: 0.9091 - val_loss: 0.4315 - val_acc: 0.8907\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3728 - acc: 0.9064 - val_loss: 0.5506 - val_acc: 0.8622\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.3557 - acc: 0.9115 - val_loss: 0.4047 - val_acc: 0.8867\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3560 - acc: 0.9089 - val_loss: 0.4743 - val_acc: 0.8521\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.3516 - acc: 0.9075 - val_loss: 0.4290 - val_acc: 0.8782\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.3422 - acc: 0.9129 - val_loss: 0.4792 - val_acc: 0.8599\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.3385 - acc: 0.9149 - val_loss: 0.5192 - val_acc: 0.8473\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.3365 - acc: 0.9146 - val_loss: 0.4417 - val_acc: 0.8592\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.3314 - acc: 0.9162 - val_loss: 0.4792 - val_acc: 0.8442\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.3220 - acc: 0.9192 - val_loss: 0.3905 - val_acc: 0.8860\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.3228 - acc: 0.9140 - val_loss: 0.3868 - val_acc: 0.8809\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.3231 - acc: 0.9153 - val_loss: 0.4041 - val_acc: 0.8836\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.3044 - acc: 0.9219 - val_loss: 0.7424 - val_acc: 0.8280\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.3146 - acc: 0.9151 - val_loss: 0.5913 - val_acc: 0.8144\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.3013 - acc: 0.9197 - val_loss: 0.3994 - val_acc: 0.8819\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2992 - acc: 0.9188 - val_loss: 0.5800 - val_acc: 0.8134\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2907 - acc: 0.9223 - val_loss: 0.6808 - val_acc: 0.8076\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.3042 - acc: 0.9189 - val_loss: 0.4588 - val_acc: 0.8442\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2983 - acc: 0.9192 - val_loss: 0.4702 - val_acc: 0.8463\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2894 - acc: 0.9219 - val_loss: 0.4336 - val_acc: 0.8649\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2836 - acc: 0.9215 - val_loss: 0.4237 - val_acc: 0.8639\n",
      "Train accuracy 0.9202937976060935 Test accuracy: 0.8639294197488971\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_79 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 122, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 122, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 61, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 976)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 64)                62528     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 65,942\n",
      "Trainable params: 65,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 9s - loss: 11.2076 - acc: 0.7520 - val_loss: 0.8034 - val_acc: 0.7920\n",
      "Epoch 2/35\n",
      " - 7s - loss: 0.6549 - acc: 0.8127 - val_loss: 0.7062 - val_acc: 0.8178\n",
      "Epoch 3/35\n",
      " - 7s - loss: 0.5877 - acc: 0.8346 - val_loss: 0.6881 - val_acc: 0.8100\n",
      "Epoch 4/35\n",
      " - 7s - loss: 0.5794 - acc: 0.8387 - val_loss: 0.6425 - val_acc: 0.8049\n",
      "Epoch 5/35\n",
      " - 7s - loss: 0.5203 - acc: 0.8555 - val_loss: 0.6667 - val_acc: 0.8045\n",
      "Epoch 6/35\n",
      " - 7s - loss: 0.4922 - acc: 0.8615 - val_loss: 0.6576 - val_acc: 0.8157\n",
      "Epoch 7/35\n",
      " - 7s - loss: 0.5112 - acc: 0.8581 - val_loss: 0.6307 - val_acc: 0.8266\n",
      "Epoch 8/35\n",
      " - 7s - loss: 0.4910 - acc: 0.8675 - val_loss: 0.6155 - val_acc: 0.8548\n",
      "Epoch 9/35\n",
      " - 7s - loss: 0.4987 - acc: 0.8694 - val_loss: 0.5561 - val_acc: 0.8663\n",
      "Epoch 10/35\n",
      " - 7s - loss: 0.4598 - acc: 0.8799 - val_loss: 0.6157 - val_acc: 0.8344\n",
      "Epoch 11/35\n",
      " - 7s - loss: 0.4413 - acc: 0.8826 - val_loss: 0.6809 - val_acc: 0.7995\n",
      "Epoch 12/35\n",
      " - 7s - loss: 0.4368 - acc: 0.8837 - val_loss: 0.6414 - val_acc: 0.8042\n",
      "Epoch 13/35\n",
      " - 7s - loss: 0.4171 - acc: 0.8887 - val_loss: 0.5622 - val_acc: 0.8585\n",
      "Epoch 14/35\n",
      " - 7s - loss: 0.4180 - acc: 0.8913 - val_loss: 0.6346 - val_acc: 0.8147\n",
      "Epoch 15/35\n",
      " - 7s - loss: 0.3999 - acc: 0.9027 - val_loss: 0.4814 - val_acc: 0.8622\n",
      "Epoch 16/35\n",
      " - 7s - loss: 0.4157 - acc: 0.8939 - val_loss: 0.5273 - val_acc: 0.8470\n",
      "Epoch 17/35\n",
      " - 7s - loss: 0.3781 - acc: 0.9029 - val_loss: 0.4904 - val_acc: 0.8521\n",
      "Epoch 18/35\n",
      " - 7s - loss: 0.3856 - acc: 0.8980 - val_loss: 0.4701 - val_acc: 0.8751\n",
      "Epoch 19/35\n",
      " - 7s - loss: 0.3920 - acc: 0.9013 - val_loss: 0.5584 - val_acc: 0.8314\n",
      "Epoch 20/35\n",
      " - 7s - loss: 0.4000 - acc: 0.8968 - val_loss: 0.6300 - val_acc: 0.8185\n",
      "Epoch 21/35\n",
      " - 7s - loss: 0.4000 - acc: 0.8964 - val_loss: 0.5349 - val_acc: 0.8276\n",
      "Epoch 22/35\n",
      " - 7s - loss: 0.3756 - acc: 0.9036 - val_loss: 0.6662 - val_acc: 0.8049\n",
      "Epoch 23/35\n",
      " - 7s - loss: 0.3614 - acc: 0.9075 - val_loss: 0.4985 - val_acc: 0.8225\n",
      "Epoch 24/35\n",
      " - 7s - loss: 0.3590 - acc: 0.9095 - val_loss: 0.5227 - val_acc: 0.8381\n",
      "Epoch 25/35\n",
      " - 7s - loss: 0.3492 - acc: 0.9117 - val_loss: 0.6006 - val_acc: 0.8124\n",
      "Epoch 26/35\n",
      " - 7s - loss: 0.3557 - acc: 0.9124 - val_loss: 0.5154 - val_acc: 0.8446\n",
      "Epoch 27/35\n",
      " - 7s - loss: 0.3574 - acc: 0.9082 - val_loss: 0.5310 - val_acc: 0.8683\n",
      "Epoch 28/35\n",
      " - 7s - loss: 0.3736 - acc: 0.9087 - val_loss: 0.5884 - val_acc: 0.8076\n",
      "Epoch 29/35\n",
      " - 7s - loss: 0.3774 - acc: 0.9042 - val_loss: 0.5426 - val_acc: 0.8476\n",
      "Epoch 30/35\n",
      " - 7s - loss: 0.3362 - acc: 0.9162 - val_loss: 0.5364 - val_acc: 0.8232\n",
      "Epoch 31/35\n",
      " - 7s - loss: 0.3665 - acc: 0.9095 - val_loss: 0.5893 - val_acc: 0.8127\n",
      "Epoch 32/35\n",
      " - 7s - loss: 0.3421 - acc: 0.9101 - val_loss: 0.4220 - val_acc: 0.8819\n",
      "Epoch 33/35\n",
      " - 7s - loss: 0.3553 - acc: 0.9102 - val_loss: 0.5093 - val_acc: 0.8093\n",
      "Epoch 34/35\n",
      " - 7s - loss: 0.3334 - acc: 0.9134 - val_loss: 0.5105 - val_acc: 0.8154\n",
      "Epoch 35/35\n",
      " - 7s - loss: 0.3646 - acc: 0.9070 - val_loss: 0.4887 - val_acc: 0.8337\n",
      "Train accuracy 0.8881936887921654 Test accuracy: 0.833729216152019\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 124, 42)           1932      \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 118, 32)           9440      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 118, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 59, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_41 (Flatten)         (None, 1888)              0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 32)                60448     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 72,018\n",
      "Trainable params: 72,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 11.1514 - acc: 0.7269 - val_loss: 0.8073 - val_acc: 0.7530\n",
      "Epoch 2/25\n",
      " - 3s - loss: 0.5540 - acc: 0.8512 - val_loss: 0.5737 - val_acc: 0.8565\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.4798 - acc: 0.8764 - val_loss: 0.5821 - val_acc: 0.8276\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.4592 - acc: 0.8828 - val_loss: 0.5394 - val_acc: 0.8578\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.4336 - acc: 0.8898 - val_loss: 0.5852 - val_acc: 0.8510\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.4165 - acc: 0.8959 - val_loss: 0.4568 - val_acc: 0.8758\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.3984 - acc: 0.9027 - val_loss: 0.4529 - val_acc: 0.8948\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.3941 - acc: 0.9061 - val_loss: 0.4660 - val_acc: 0.8795\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.3833 - acc: 0.9017 - val_loss: 0.4501 - val_acc: 0.8758\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.3835 - acc: 0.9019 - val_loss: 0.3798 - val_acc: 0.9084\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.3836 - acc: 0.9053 - val_loss: 0.4024 - val_acc: 0.8945\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.3799 - acc: 0.9011 - val_loss: 0.4412 - val_acc: 0.8700\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.3761 - acc: 0.9119 - val_loss: 0.4387 - val_acc: 0.8867\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.3649 - acc: 0.9082 - val_loss: 0.4185 - val_acc: 0.8887\n",
      "Epoch 15/25\n",
      " - 3s - loss: 0.3622 - acc: 0.9093 - val_loss: 0.5608 - val_acc: 0.8409\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.3610 - acc: 0.9119 - val_loss: 0.4241 - val_acc: 0.8785\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.3747 - acc: 0.9072 - val_loss: 0.4768 - val_acc: 0.8480\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.3602 - acc: 0.9106 - val_loss: 0.3897 - val_acc: 0.8918\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.3659 - acc: 0.9124 - val_loss: 0.4663 - val_acc: 0.8616\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.3626 - acc: 0.9098 - val_loss: 0.4184 - val_acc: 0.8941\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.3507 - acc: 0.9064 - val_loss: 0.4477 - val_acc: 0.8751\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.3676 - acc: 0.9068 - val_loss: 0.5146 - val_acc: 0.8300\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.3578 - acc: 0.9101 - val_loss: 0.4066 - val_acc: 0.8945\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.3486 - acc: 0.9057 - val_loss: 0.8198 - val_acc: 0.7238\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.3455 - acc: 0.9093 - val_loss: 0.4381 - val_acc: 0.8714\n",
      "Train accuracy 0.9215179542981502 Test accuracy: 0.8713946386155412\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_83 (Conv1D)           (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 118, 16)           2576      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 59, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_42 (Flatten)         (None, 944)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 32)                30240     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 35,062\n",
      "Trainable params: 35,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 7s - loss: 27.1762 - acc: 0.7277 - val_loss: 1.3614 - val_acc: 0.8324\n",
      "Epoch 2/25\n",
      " - 5s - loss: 0.7013 - acc: 0.8685 - val_loss: 0.7475 - val_acc: 0.8286\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.5337 - acc: 0.8848 - val_loss: 0.7020 - val_acc: 0.8042\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.4675 - acc: 0.8973 - val_loss: 0.5805 - val_acc: 0.8639\n",
      "Epoch 5/25\n",
      " - 5s - loss: 0.4652 - acc: 0.8923 - val_loss: 0.5888 - val_acc: 0.8870\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.4253 - acc: 0.9034 - val_loss: 0.5460 - val_acc: 0.8914\n",
      "Epoch 7/25\n",
      " - 5s - loss: 0.3952 - acc: 0.9076 - val_loss: 0.5269 - val_acc: 0.8907\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.3785 - acc: 0.9125 - val_loss: 0.5370 - val_acc: 0.8551\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.3821 - acc: 0.9037 - val_loss: 0.5373 - val_acc: 0.8463\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.3620 - acc: 0.9120 - val_loss: 0.4670 - val_acc: 0.8904\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.3776 - acc: 0.9095 - val_loss: 0.4725 - val_acc: 0.8918\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.3663 - acc: 0.9091 - val_loss: 0.4567 - val_acc: 0.8968\n",
      "Epoch 13/25\n",
      " - 5s - loss: 0.3628 - acc: 0.9068 - val_loss: 0.5204 - val_acc: 0.8521\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.3461 - acc: 0.9165 - val_loss: 0.4536 - val_acc: 0.8816\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.3321 - acc: 0.9173 - val_loss: 0.5775 - val_acc: 0.8432\n",
      "Epoch 16/25\n",
      " - 5s - loss: 0.3288 - acc: 0.9183 - val_loss: 0.4953 - val_acc: 0.8636\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.3338 - acc: 0.9159 - val_loss: 0.5608 - val_acc: 0.8174\n",
      "Epoch 18/25\n",
      " - 5s - loss: 0.3311 - acc: 0.9180 - val_loss: 0.4057 - val_acc: 0.9060\n",
      "Epoch 19/25\n",
      " - 5s - loss: 0.3323 - acc: 0.9178 - val_loss: 0.4332 - val_acc: 0.8833\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.3295 - acc: 0.9197 - val_loss: 0.4325 - val_acc: 0.8921\n",
      "Epoch 21/25\n",
      " - 5s - loss: 0.3137 - acc: 0.9245 - val_loss: 0.4407 - val_acc: 0.8968\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.3205 - acc: 0.9177 - val_loss: 0.4486 - val_acc: 0.8951\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.3210 - acc: 0.9226 - val_loss: 0.4261 - val_acc: 0.8894\n",
      "Epoch 24/25\n",
      " - 5s - loss: 0.3268 - acc: 0.9199 - val_loss: 0.5320 - val_acc: 0.8765\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.3123 - acc: 0.9233 - val_loss: 0.4226 - val_acc: 0.8836\n",
      "Train accuracy 0.9300870512074044 Test accuracy: 0.8836104513064132\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_85 (Conv1D)           (None, 126, 28)           784       \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 120, 16)           3152      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 60, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 65,830\n",
      "Trainable params: 65,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 3.9236 - acc: 0.7994 - val_loss: 0.6350 - val_acc: 0.8541\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.4266 - acc: 0.9008 - val_loss: 0.5079 - val_acc: 0.8853\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.3860 - acc: 0.9061 - val_loss: 0.6102 - val_acc: 0.8517\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.3581 - acc: 0.9135 - val_loss: 0.4793 - val_acc: 0.8768\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.3196 - acc: 0.9232 - val_loss: 0.4518 - val_acc: 0.8728\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.3006 - acc: 0.9290 - val_loss: 0.4396 - val_acc: 0.8758\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.3352 - acc: 0.9181 - val_loss: 0.4172 - val_acc: 0.9023\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.2960 - acc: 0.9260 - val_loss: 0.3940 - val_acc: 0.8972\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.2797 - acc: 0.9287 - val_loss: 0.4360 - val_acc: 0.8687\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.2927 - acc: 0.9298 - val_loss: 0.4079 - val_acc: 0.8833\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.2651 - acc: 0.9339 - val_loss: 0.3828 - val_acc: 0.8738\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.2762 - acc: 0.9293 - val_loss: 0.3679 - val_acc: 0.8765\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.2584 - acc: 0.9368 - val_loss: 0.3531 - val_acc: 0.8907\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.2741 - acc: 0.9301 - val_loss: 0.4148 - val_acc: 0.8531\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2732 - acc: 0.9310 - val_loss: 0.3899 - val_acc: 0.8918\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.2587 - acc: 0.9316 - val_loss: 0.3720 - val_acc: 0.8802\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.2657 - acc: 0.9309 - val_loss: 0.4303 - val_acc: 0.8687\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.2567 - acc: 0.9373 - val_loss: 0.4024 - val_acc: 0.8568\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2452 - acc: 0.9380 - val_loss: 0.3703 - val_acc: 0.8751\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2698 - acc: 0.9331 - val_loss: 0.4168 - val_acc: 0.8761\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.2315 - acc: 0.9403 - val_loss: 0.5369 - val_acc: 0.8375\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.2329 - acc: 0.9381 - val_loss: 0.4783 - val_acc: 0.8656\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.2570 - acc: 0.9325 - val_loss: 0.3702 - val_acc: 0.9030\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.2298 - acc: 0.9423 - val_loss: 0.3321 - val_acc: 0.8884\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2247 - acc: 0.9416 - val_loss: 0.5164 - val_acc: 0.8582\n",
      "Train accuracy 0.9231501632857504 Test accuracy: 0.8581608415337632\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_87 (Conv1D)           (None, 124, 42)           1932      \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 122, 32)           4064      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 122, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 61, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 1952)              0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 32)                62496     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 68,690\n",
      "Trainable params: 68,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 15.4742 - acc: 0.7338 - val_loss: 0.7912 - val_acc: 0.8100\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.5992 - acc: 0.8464 - val_loss: 0.5625 - val_acc: 0.8537\n",
      "Epoch 3/30\n",
      " - 3s - loss: 0.4923 - acc: 0.8807 - val_loss: 0.5012 - val_acc: 0.8802\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.4579 - acc: 0.8847 - val_loss: 0.5514 - val_acc: 0.8561\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.4439 - acc: 0.8901 - val_loss: 0.5712 - val_acc: 0.8181\n",
      "Epoch 6/30\n",
      " - 3s - loss: 0.4265 - acc: 0.8946 - val_loss: 0.4373 - val_acc: 0.8948\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.4266 - acc: 0.8964 - val_loss: 0.4360 - val_acc: 0.8850\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.4167 - acc: 0.8925 - val_loss: 0.6559 - val_acc: 0.7499\n",
      "Epoch 9/30\n",
      " - 3s - loss: 0.4134 - acc: 0.8953 - val_loss: 0.4291 - val_acc: 0.8877\n",
      "Epoch 10/30\n",
      " - 3s - loss: 0.3963 - acc: 0.8970 - val_loss: 0.5227 - val_acc: 0.8202\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.3913 - acc: 0.9022 - val_loss: 0.4991 - val_acc: 0.8551\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.4025 - acc: 0.8985 - val_loss: 0.5791 - val_acc: 0.8147\n",
      "Epoch 13/30\n",
      " - 3s - loss: 0.3869 - acc: 0.9057 - val_loss: 0.5648 - val_acc: 0.8025\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.4073 - acc: 0.8953 - val_loss: 0.4612 - val_acc: 0.8734\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.3964 - acc: 0.9041 - val_loss: 0.4749 - val_acc: 0.8531\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.3814 - acc: 0.9049 - val_loss: 0.4152 - val_acc: 0.8717\n",
      "Epoch 17/30\n",
      " - 3s - loss: 0.3879 - acc: 0.9063 - val_loss: 0.4685 - val_acc: 0.8829\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.3878 - acc: 0.9025 - val_loss: 0.4877 - val_acc: 0.8578\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.3885 - acc: 0.8981 - val_loss: 0.5265 - val_acc: 0.8490\n",
      "Epoch 20/30\n",
      " - 3s - loss: 0.3793 - acc: 0.9037 - val_loss: 0.4773 - val_acc: 0.8537\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.3839 - acc: 0.9060 - val_loss: 0.4736 - val_acc: 0.8850\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.3708 - acc: 0.9051 - val_loss: 0.5082 - val_acc: 0.8246\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.3729 - acc: 0.9048 - val_loss: 0.5330 - val_acc: 0.8565\n",
      "Epoch 24/30\n",
      " - 3s - loss: 0.3717 - acc: 0.9063 - val_loss: 0.6459 - val_acc: 0.8371\n",
      "Epoch 25/30\n",
      " - 3s - loss: 0.3813 - acc: 0.8998 - val_loss: 0.5365 - val_acc: 0.7988\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.3742 - acc: 0.9048 - val_loss: 0.5463 - val_acc: 0.8548\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.3766 - acc: 0.9066 - val_loss: 0.4888 - val_acc: 0.8633\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.3722 - acc: 0.9071 - val_loss: 0.4506 - val_acc: 0.8785\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.3634 - acc: 0.9110 - val_loss: 0.4248 - val_acc: 0.8717\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.3792 - acc: 0.9041 - val_loss: 0.4477 - val_acc: 0.8826\n",
      "Train accuracy 0.9065560391730142 Test accuracy: 0.8825924669155073\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_89 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 118, 16)           3600      \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 59, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_45 (Flatten)         (None, 944)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 32)                30240     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 35,510\n",
      "Trainable params: 35,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 5s - loss: 11.5468 - acc: 0.7382 - val_loss: 0.7696 - val_acc: 0.8045\n",
      "Epoch 2/35\n",
      " - 3s - loss: 0.5729 - acc: 0.8530 - val_loss: 0.6834 - val_acc: 0.8249\n",
      "Epoch 3/35\n",
      " - 3s - loss: 0.5067 - acc: 0.8692 - val_loss: 0.5984 - val_acc: 0.8592\n",
      "Epoch 4/35\n",
      " - 3s - loss: 0.4702 - acc: 0.8840 - val_loss: 0.5183 - val_acc: 0.8931\n",
      "Epoch 5/35\n",
      " - 3s - loss: 0.4204 - acc: 0.8980 - val_loss: 0.5299 - val_acc: 0.8517\n",
      "Epoch 6/35\n",
      " - 3s - loss: 0.4289 - acc: 0.8934 - val_loss: 0.5291 - val_acc: 0.8700\n",
      "Epoch 7/35\n",
      " - 3s - loss: 0.4082 - acc: 0.8966 - val_loss: 0.4704 - val_acc: 0.8938\n",
      "Epoch 8/35\n",
      " - 3s - loss: 0.3915 - acc: 0.9030 - val_loss: 0.4849 - val_acc: 0.8690\n",
      "Epoch 9/35\n",
      " - 3s - loss: 0.4005 - acc: 0.9002 - val_loss: 0.5663 - val_acc: 0.8724\n",
      "Epoch 10/35\n",
      " - 3s - loss: 0.3988 - acc: 0.9038 - val_loss: 0.5646 - val_acc: 0.8154\n",
      "Epoch 11/35\n",
      " - 3s - loss: 0.3717 - acc: 0.9060 - val_loss: 0.4617 - val_acc: 0.8785\n",
      "Epoch 12/35\n",
      " - 3s - loss: 0.3922 - acc: 0.9044 - val_loss: 0.4656 - val_acc: 0.8819\n",
      "Epoch 13/35\n",
      " - 3s - loss: 0.3537 - acc: 0.9093 - val_loss: 0.4923 - val_acc: 0.8371\n",
      "Epoch 14/35\n",
      " - 3s - loss: 0.3690 - acc: 0.9049 - val_loss: 0.4180 - val_acc: 0.8755\n",
      "Epoch 15/35\n",
      " - 3s - loss: 0.3711 - acc: 0.9072 - val_loss: 0.4063 - val_acc: 0.8772\n",
      "Epoch 16/35\n",
      " - 3s - loss: 0.3532 - acc: 0.9083 - val_loss: 0.4669 - val_acc: 0.8768\n",
      "Epoch 17/35\n",
      " - 3s - loss: 0.3594 - acc: 0.9089 - val_loss: 0.5369 - val_acc: 0.8412\n",
      "Epoch 18/35\n",
      " - 3s - loss: 0.3800 - acc: 0.9052 - val_loss: 0.4391 - val_acc: 0.8839\n",
      "Epoch 19/35\n",
      " - 3s - loss: 0.3646 - acc: 0.9095 - val_loss: 0.4745 - val_acc: 0.8670\n",
      "Epoch 20/35\n",
      " - 3s - loss: 0.3599 - acc: 0.9089 - val_loss: 0.4247 - val_acc: 0.8772\n",
      "Epoch 21/35\n",
      " - 3s - loss: 0.3310 - acc: 0.9140 - val_loss: 0.4418 - val_acc: 0.8765\n",
      "Epoch 22/35\n",
      " - 3s - loss: 0.3285 - acc: 0.9161 - val_loss: 0.4521 - val_acc: 0.8582\n",
      "Epoch 23/35\n",
      " - 3s - loss: 0.3630 - acc: 0.9072 - val_loss: 0.4044 - val_acc: 0.8761\n",
      "Epoch 24/35\n",
      " - 3s - loss: 0.3331 - acc: 0.9117 - val_loss: 0.5197 - val_acc: 0.8422\n",
      "Epoch 25/35\n",
      " - 3s - loss: 0.3525 - acc: 0.9095 - val_loss: 0.6099 - val_acc: 0.7978\n",
      "Epoch 26/35\n",
      " - 3s - loss: 0.3891 - acc: 0.9026 - val_loss: 0.6096 - val_acc: 0.8239\n",
      "Epoch 27/35\n",
      " - 3s - loss: 0.3508 - acc: 0.9116 - val_loss: 0.4641 - val_acc: 0.8429\n",
      "Epoch 28/35\n",
      " - 3s - loss: 0.3181 - acc: 0.9143 - val_loss: 0.4692 - val_acc: 0.8507\n",
      "Epoch 29/35\n",
      " - 3s - loss: 0.3120 - acc: 0.9176 - val_loss: 0.4287 - val_acc: 0.8656\n",
      "Epoch 30/35\n",
      " - 3s - loss: 0.3266 - acc: 0.9108 - val_loss: 0.4353 - val_acc: 0.8463\n",
      "Epoch 31/35\n",
      " - 3s - loss: 0.3295 - acc: 0.9095 - val_loss: 0.4434 - val_acc: 0.8670\n",
      "Epoch 32/35\n",
      " - 3s - loss: 0.3670 - acc: 0.9048 - val_loss: 0.4375 - val_acc: 0.8558\n",
      "Epoch 33/35\n",
      " - 3s - loss: 0.3205 - acc: 0.9195 - val_loss: 0.4123 - val_acc: 0.8639\n",
      "Epoch 34/35\n",
      " - 3s - loss: 0.3349 - acc: 0.9127 - val_loss: 0.5441 - val_acc: 0.8191\n",
      "Epoch 35/35\n",
      " - 3s - loss: 0.3298 - acc: 0.9135 - val_loss: 0.4155 - val_acc: 0.8670\n",
      "Train accuracy 0.9151251360174102 Test accuracy: 0.8669833729216152\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 122, 28)           1792      \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 116, 16)           3152      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 116, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 58, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 928)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 64)                59456     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 64,790\n",
      "Trainable params: 64,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 4s - loss: 14.1224 - acc: 0.7764 - val_loss: 0.8613 - val_acc: 0.8324\n",
      "Epoch 2/25\n",
      " - 2s - loss: 0.5556 - acc: 0.8751 - val_loss: 0.7224 - val_acc: 0.7940\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.4908 - acc: 0.8901 - val_loss: 0.7228 - val_acc: 0.8124\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.4757 - acc: 0.8913 - val_loss: 0.5623 - val_acc: 0.8894\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.4047 - acc: 0.9091 - val_loss: 0.6285 - val_acc: 0.8690\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.4235 - acc: 0.9029 - val_loss: 0.5732 - val_acc: 0.8636\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.3981 - acc: 0.9108 - val_loss: 0.5661 - val_acc: 0.8894\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3818 - acc: 0.9121 - val_loss: 0.4896 - val_acc: 0.8887\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.3650 - acc: 0.9127 - val_loss: 0.5023 - val_acc: 0.8666\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.3698 - acc: 0.9158 - val_loss: 0.5703 - val_acc: 0.8307\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.3430 - acc: 0.9180 - val_loss: 0.5050 - val_acc: 0.8911\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.3577 - acc: 0.9177 - val_loss: 0.5017 - val_acc: 0.8965\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.3643 - acc: 0.9163 - val_loss: 0.4940 - val_acc: 0.9030\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.3304 - acc: 0.9240 - val_loss: 0.4770 - val_acc: 0.8799\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.3455 - acc: 0.9146 - val_loss: 0.6261 - val_acc: 0.8239\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.3338 - acc: 0.9241 - val_loss: 0.4990 - val_acc: 0.8877\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.3156 - acc: 0.9255 - val_loss: 0.4398 - val_acc: 0.8965\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.3075 - acc: 0.9260 - val_loss: 0.5896 - val_acc: 0.8212\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.3441 - acc: 0.9221 - val_loss: 0.6169 - val_acc: 0.8164\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.3255 - acc: 0.9249 - val_loss: 0.5002 - val_acc: 0.8704\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2894 - acc: 0.9324 - val_loss: 0.4547 - val_acc: 0.8911\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.3026 - acc: 0.9268 - val_loss: 0.5328 - val_acc: 0.8544\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2981 - acc: 0.9291 - val_loss: 0.4558 - val_acc: 0.8599\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.3203 - acc: 0.9222 - val_loss: 0.5094 - val_acc: 0.8765\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.3036 - acc: 0.9261 - val_loss: 0.4021 - val_acc: 0.9019\n",
      "Train accuracy 0.9472252448313384 Test accuracy: 0.9019341703427214\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_93 (Conv1D)           (None, 124, 42)           1932      \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 120, 32)           6752      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_47 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 32)                61472     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 70,354\n",
      "Trainable params: 70,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 20.6513 - acc: 0.7474 - val_loss: 0.8795 - val_acc: 0.7231\n",
      "Epoch 2/30\n",
      " - 4s - loss: 0.5524 - acc: 0.8553 - val_loss: 0.6381 - val_acc: 0.8568\n",
      "Epoch 3/30\n",
      " - 4s - loss: 0.4818 - acc: 0.8690 - val_loss: 0.5706 - val_acc: 0.8283\n",
      "Epoch 4/30\n",
      " - 4s - loss: 0.4561 - acc: 0.8781 - val_loss: 0.6439 - val_acc: 0.7967\n",
      "Epoch 5/30\n",
      " - 4s - loss: 0.4442 - acc: 0.8791 - val_loss: 0.5864 - val_acc: 0.8103\n",
      "Epoch 6/30\n",
      " - 4s - loss: 0.4307 - acc: 0.8852 - val_loss: 0.5405 - val_acc: 0.8375\n",
      "Epoch 7/30\n",
      " - 4s - loss: 0.4205 - acc: 0.8825 - val_loss: 0.5517 - val_acc: 0.8368\n",
      "Epoch 8/30\n",
      " - 4s - loss: 0.4073 - acc: 0.8890 - val_loss: 0.6337 - val_acc: 0.7794\n",
      "Epoch 9/30\n",
      " - 4s - loss: 0.3932 - acc: 0.8896 - val_loss: 0.5910 - val_acc: 0.7961\n",
      "Epoch 10/30\n",
      " - 4s - loss: 0.3904 - acc: 0.8951 - val_loss: 0.4510 - val_acc: 0.8510\n",
      "Epoch 11/30\n",
      " - 4s - loss: 0.3888 - acc: 0.8927 - val_loss: 0.4871 - val_acc: 0.8711\n",
      "Epoch 12/30\n",
      " - 4s - loss: 0.3840 - acc: 0.8934 - val_loss: 0.3956 - val_acc: 0.8877\n",
      "Epoch 13/30\n",
      " - 4s - loss: 0.3740 - acc: 0.9019 - val_loss: 0.3951 - val_acc: 0.8860\n",
      "Epoch 14/30\n",
      " - 4s - loss: 0.3817 - acc: 0.8957 - val_loss: 0.6313 - val_acc: 0.8314\n",
      "Epoch 15/30\n",
      " - 4s - loss: 0.3750 - acc: 0.9010 - val_loss: 0.5276 - val_acc: 0.8069\n",
      "Epoch 16/30\n",
      " - 4s - loss: 0.3744 - acc: 0.8988 - val_loss: 0.4497 - val_acc: 0.8490\n",
      "Epoch 17/30\n",
      " - 4s - loss: 0.3640 - acc: 0.9011 - val_loss: 0.3706 - val_acc: 0.8873\n",
      "Epoch 18/30\n",
      " - 4s - loss: 0.3587 - acc: 0.9032 - val_loss: 0.4298 - val_acc: 0.8816\n",
      "Epoch 19/30\n",
      " - 4s - loss: 0.3614 - acc: 0.9021 - val_loss: 0.4474 - val_acc: 0.8680\n",
      "Epoch 20/30\n",
      " - 4s - loss: 0.3690 - acc: 0.8996 - val_loss: 0.4803 - val_acc: 0.8327\n",
      "Epoch 21/30\n",
      " - 4s - loss: 0.3646 - acc: 0.9059 - val_loss: 0.4852 - val_acc: 0.8191\n",
      "Epoch 22/30\n",
      " - 4s - loss: 0.3619 - acc: 0.9066 - val_loss: 0.8657 - val_acc: 0.7061\n",
      "Epoch 23/30\n",
      " - 4s - loss: 0.3597 - acc: 0.9060 - val_loss: 0.4068 - val_acc: 0.8863\n",
      "Epoch 24/30\n",
      " - 4s - loss: 0.3690 - acc: 0.9003 - val_loss: 0.6379 - val_acc: 0.8188\n",
      "Epoch 25/30\n",
      " - 4s - loss: 0.3586 - acc: 0.9021 - val_loss: 0.4374 - val_acc: 0.8670\n",
      "Epoch 26/30\n",
      " - 4s - loss: 0.3593 - acc: 0.9045 - val_loss: 0.4816 - val_acc: 0.8375\n",
      "Epoch 27/30\n",
      " - 4s - loss: 0.3702 - acc: 0.9060 - val_loss: 0.7920 - val_acc: 0.7594\n",
      "Epoch 28/30\n",
      " - 4s - loss: 0.3581 - acc: 0.9048 - val_loss: 0.4391 - val_acc: 0.8565\n",
      "Epoch 29/30\n",
      " - 4s - loss: 0.3517 - acc: 0.9076 - val_loss: 0.7177 - val_acc: 0.7917\n",
      "Epoch 30/30\n",
      " - 4s - loss: 0.3618 - acc: 0.9041 - val_loss: 0.3884 - val_acc: 0.8904\n",
      "Train accuracy 0.925734494015234 Test accuracy: 0.8903970139124533\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_95 (Conv1D)           (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 124, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 41, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 656)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 32)                21024     \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 23,670\n",
      "Trainable params: 23,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 7s - loss: 3.9199 - acc: 0.7568 - val_loss: 1.3115 - val_acc: 0.8504\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.5764 - acc: 0.9207 - val_loss: 0.6236 - val_acc: 0.8259\n",
      "Epoch 3/25\n",
      " - 5s - loss: 0.3302 - acc: 0.9264 - val_loss: 0.4838 - val_acc: 0.8850\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.2730 - acc: 0.9343 - val_loss: 0.4120 - val_acc: 0.8989\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.2438 - acc: 0.9408 - val_loss: 0.4230 - val_acc: 0.8867\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.2204 - acc: 0.9456 - val_loss: 0.3906 - val_acc: 0.9070\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.2359 - acc: 0.9388 - val_loss: 0.3531 - val_acc: 0.8985\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.2122 - acc: 0.9476 - val_loss: 0.3350 - val_acc: 0.9074\n",
      "Epoch 9/25\n",
      " - 5s - loss: 0.2003 - acc: 0.9425 - val_loss: 0.3846 - val_acc: 0.8846\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.1874 - acc: 0.9498 - val_loss: 0.3056 - val_acc: 0.9233\n",
      "Epoch 11/25\n",
      " - 5s - loss: 0.1895 - acc: 0.9494 - val_loss: 0.3580 - val_acc: 0.9118\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.1969 - acc: 0.9444 - val_loss: 0.3796 - val_acc: 0.8982\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.1860 - acc: 0.9509 - val_loss: 0.3324 - val_acc: 0.9013\n",
      "Epoch 14/25\n",
      " - 5s - loss: 0.1712 - acc: 0.9543 - val_loss: 0.3050 - val_acc: 0.9135\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.1810 - acc: 0.9475 - val_loss: 0.3063 - val_acc: 0.9094\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.1636 - acc: 0.9516 - val_loss: 0.3497 - val_acc: 0.9104\n",
      "Epoch 17/25\n",
      " - 5s - loss: 0.1579 - acc: 0.9535 - val_loss: 0.3284 - val_acc: 0.9077\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.1715 - acc: 0.9495 - val_loss: 0.2929 - val_acc: 0.9209\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.1720 - acc: 0.9510 - val_loss: 0.2761 - val_acc: 0.9002\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.1516 - acc: 0.9565 - val_loss: 0.3332 - val_acc: 0.9050\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.1854 - acc: 0.9433 - val_loss: 0.3419 - val_acc: 0.8972\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.1568 - acc: 0.9539 - val_loss: 0.3314 - val_acc: 0.8989\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.1568 - acc: 0.9539 - val_loss: 0.3017 - val_acc: 0.9087\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.1506 - acc: 0.9538 - val_loss: 0.3026 - val_acc: 0.9070\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.1608 - acc: 0.9533 - val_loss: 0.2811 - val_acc: 0.9145\n",
      "Train accuracy 0.9613710554951034 Test accuracy: 0.9144893111638955\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_97 (Conv1D)           (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 124, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 62, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 992)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 64)                63552     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,390\n",
      "Trainable params: 66,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 16.4565 - acc: 0.5947 - val_loss: 3.7476 - val_acc: 0.8012\n",
      "Epoch 2/25\n",
      " - 2s - loss: 1.5969 - acc: 0.8796 - val_loss: 0.9833 - val_acc: 0.8616\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.6378 - acc: 0.9120 - val_loss: 0.7204 - val_acc: 0.8887\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.4893 - acc: 0.9211 - val_loss: 0.6302 - val_acc: 0.8806\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.4115 - acc: 0.9211 - val_loss: 0.5471 - val_acc: 0.8931\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3678 - acc: 0.9256 - val_loss: 0.4995 - val_acc: 0.8935\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.3099 - acc: 0.9350 - val_loss: 0.4832 - val_acc: 0.8860\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3044 - acc: 0.9308 - val_loss: 0.4442 - val_acc: 0.9016\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.2944 - acc: 0.9319 - val_loss: 0.4784 - val_acc: 0.8677\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.2729 - acc: 0.9339 - val_loss: 0.4225 - val_acc: 0.9111\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2450 - acc: 0.9416 - val_loss: 0.4151 - val_acc: 0.8904\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.2444 - acc: 0.9384 - val_loss: 0.3890 - val_acc: 0.8863\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2417 - acc: 0.9378 - val_loss: 0.4039 - val_acc: 0.8785\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.2609 - acc: 0.9332 - val_loss: 0.4009 - val_acc: 0.9043\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.2288 - acc: 0.9391 - val_loss: 0.3991 - val_acc: 0.8846\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.2235 - acc: 0.9412 - val_loss: 0.3854 - val_acc: 0.8914\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.2077 - acc: 0.9470 - val_loss: 0.3681 - val_acc: 0.9013\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.2275 - acc: 0.9376 - val_loss: 0.3870 - val_acc: 0.9080\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.2135 - acc: 0.9442 - val_loss: 0.3656 - val_acc: 0.8955\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2119 - acc: 0.9416 - val_loss: 0.3578 - val_acc: 0.9057\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.2102 - acc: 0.9437 - val_loss: 0.3854 - val_acc: 0.8907\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2099 - acc: 0.9407 - val_loss: 0.3475 - val_acc: 0.8989\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.1956 - acc: 0.9440 - val_loss: 0.3455 - val_acc: 0.9145\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.2010 - acc: 0.9442 - val_loss: 0.3476 - val_acc: 0.9030\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2221 - acc: 0.9412 - val_loss: 0.3550 - val_acc: 0.9046\n",
      "Train accuracy 0.9381120783460283 Test accuracy: 0.9046487953851374\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_99 (Conv1D)           (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 124, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 41, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_50 (Flatten)         (None, 656)               0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 32)                21024     \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 23,670\n",
      "Trainable params: 23,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 48.8144 - acc: 0.6893 - val_loss: 4.1941 - val_acc: 0.6790\n",
      "Epoch 2/30\n",
      " - 4s - loss: 1.1903 - acc: 0.7703 - val_loss: 0.9750 - val_acc: 0.6943\n",
      "Epoch 3/30\n",
      " - 4s - loss: 0.6784 - acc: 0.8028 - val_loss: 0.8482 - val_acc: 0.7638\n",
      "Epoch 4/30\n",
      " - 4s - loss: 0.6153 - acc: 0.8211 - val_loss: 0.7753 - val_acc: 0.8222\n",
      "Epoch 5/30\n",
      " - 4s - loss: 0.5791 - acc: 0.8405 - val_loss: 0.7997 - val_acc: 0.7754\n",
      "Epoch 6/30\n",
      " - 4s - loss: 0.5462 - acc: 0.8490 - val_loss: 0.7971 - val_acc: 0.7689\n",
      "Epoch 7/30\n",
      " - 4s - loss: 0.5238 - acc: 0.8576 - val_loss: 0.6791 - val_acc: 0.8205\n",
      "Epoch 8/30\n",
      " - 4s - loss: 0.5081 - acc: 0.8613 - val_loss: 0.6642 - val_acc: 0.8059\n",
      "Epoch 9/30\n",
      " - 4s - loss: 0.4941 - acc: 0.8630 - val_loss: 0.7097 - val_acc: 0.7859\n",
      "Epoch 10/30\n",
      " - 4s - loss: 0.4803 - acc: 0.8724 - val_loss: 0.6713 - val_acc: 0.8354\n",
      "Epoch 11/30\n",
      " - 4s - loss: 0.4761 - acc: 0.8692 - val_loss: 0.6530 - val_acc: 0.8371\n",
      "Epoch 12/30\n",
      " - 4s - loss: 0.4656 - acc: 0.8735 - val_loss: 0.6509 - val_acc: 0.7913\n",
      "Epoch 13/30\n",
      " - 4s - loss: 0.4600 - acc: 0.8727 - val_loss: 0.6125 - val_acc: 0.8344\n",
      "Epoch 14/30\n",
      " - 4s - loss: 0.4551 - acc: 0.8798 - val_loss: 0.6285 - val_acc: 0.8449\n",
      "Epoch 15/30\n",
      " - 4s - loss: 0.4441 - acc: 0.8811 - val_loss: 0.6167 - val_acc: 0.8456\n",
      "Epoch 16/30\n",
      " - 4s - loss: 0.4413 - acc: 0.8853 - val_loss: 0.6444 - val_acc: 0.8198\n",
      "Epoch 17/30\n",
      " - 4s - loss: 0.4287 - acc: 0.8849 - val_loss: 0.6124 - val_acc: 0.8188\n",
      "Epoch 18/30\n",
      " - 4s - loss: 0.4213 - acc: 0.8920 - val_loss: 0.5524 - val_acc: 0.8629\n",
      "Epoch 19/30\n",
      " - 4s - loss: 0.4203 - acc: 0.8866 - val_loss: 0.6787 - val_acc: 0.7604\n",
      "Epoch 20/30\n",
      " - 4s - loss: 0.4217 - acc: 0.8882 - val_loss: 0.6011 - val_acc: 0.8466\n",
      "Epoch 21/30\n",
      " - 4s - loss: 0.4128 - acc: 0.8916 - val_loss: 0.5849 - val_acc: 0.8181\n",
      "Epoch 22/30\n",
      " - 4s - loss: 0.4131 - acc: 0.8901 - val_loss: 0.5697 - val_acc: 0.8388\n",
      "Epoch 23/30\n",
      " - 4s - loss: 0.4116 - acc: 0.8904 - val_loss: 0.5820 - val_acc: 0.8436\n",
      "Epoch 24/30\n",
      " - 4s - loss: 0.3989 - acc: 0.8957 - val_loss: 0.5713 - val_acc: 0.8466\n",
      "Epoch 25/30\n",
      " - 4s - loss: 0.3948 - acc: 0.8949 - val_loss: 0.5398 - val_acc: 0.8595\n",
      "Epoch 26/30\n",
      " - 4s - loss: 0.3994 - acc: 0.8950 - val_loss: 0.8517 - val_acc: 0.7119\n",
      "Epoch 27/30\n",
      " - 4s - loss: 0.3878 - acc: 0.8977 - val_loss: 0.7485 - val_acc: 0.7628\n",
      "Epoch 28/30\n",
      " - 4s - loss: 0.3910 - acc: 0.8984 - val_loss: 0.5619 - val_acc: 0.8331\n",
      "Epoch 29/30\n",
      " - 4s - loss: 0.3803 - acc: 0.8984 - val_loss: 0.5217 - val_acc: 0.8324\n",
      "Epoch 30/30\n",
      " - 4s - loss: 0.3792 - acc: 0.8999 - val_loss: 0.5470 - val_acc: 0.8409\n",
      "Train accuracy 0.9148531011969532 Test accuracy: 0.8408551068883611\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_101 (Conv1D)          (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 124, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 41, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 46,214\n",
      "Trainable params: 46,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 7s - loss: 7.2376 - acc: 0.7301 - val_loss: 1.9546 - val_acc: 0.8327\n",
      "Epoch 2/35\n",
      " - 3s - loss: 0.8647 - acc: 0.9000 - val_loss: 0.7990 - val_acc: 0.8269\n",
      "Epoch 3/35\n",
      " - 4s - loss: 0.4210 - acc: 0.9149 - val_loss: 0.6137 - val_acc: 0.8507\n",
      "Epoch 4/35\n",
      " - 3s - loss: 0.3414 - acc: 0.9246 - val_loss: 0.5740 - val_acc: 0.8605\n",
      "Epoch 5/35\n",
      " - 3s - loss: 0.3235 - acc: 0.9207 - val_loss: 0.5459 - val_acc: 0.8734\n",
      "Epoch 6/35\n",
      " - 4s - loss: 0.3136 - acc: 0.9221 - val_loss: 0.5366 - val_acc: 0.8697\n",
      "Epoch 7/35\n",
      " - 3s - loss: 0.2866 - acc: 0.9261 - val_loss: 0.4931 - val_acc: 0.8724\n",
      "Epoch 8/35\n",
      " - 3s - loss: 0.2726 - acc: 0.9317 - val_loss: 0.4879 - val_acc: 0.8884\n",
      "Epoch 9/35\n",
      " - 3s - loss: 0.2686 - acc: 0.9329 - val_loss: 0.4603 - val_acc: 0.8914\n",
      "Epoch 10/35\n",
      " - 4s - loss: 0.2562 - acc: 0.9325 - val_loss: 0.4843 - val_acc: 0.8843\n",
      "Epoch 11/35\n",
      " - 3s - loss: 0.2531 - acc: 0.9338 - val_loss: 0.4647 - val_acc: 0.8924\n",
      "Epoch 12/35\n",
      " - 3s - loss: 0.2462 - acc: 0.9344 - val_loss: 0.4693 - val_acc: 0.8826\n",
      "Epoch 13/35\n",
      " - 3s - loss: 0.2455 - acc: 0.9347 - val_loss: 0.4400 - val_acc: 0.8907\n",
      "Epoch 14/35\n",
      " - 4s - loss: 0.2431 - acc: 0.9357 - val_loss: 0.4232 - val_acc: 0.8935\n",
      "Epoch 15/35\n",
      " - 3s - loss: 0.2235 - acc: 0.9399 - val_loss: 0.4123 - val_acc: 0.8951\n",
      "Epoch 16/35\n",
      " - 3s - loss: 0.2200 - acc: 0.9406 - val_loss: 0.4153 - val_acc: 0.8962\n",
      "Epoch 17/35\n",
      " - 4s - loss: 0.2162 - acc: 0.9445 - val_loss: 0.4383 - val_acc: 0.8816\n",
      "Epoch 18/35\n",
      " - 3s - loss: 0.2277 - acc: 0.9410 - val_loss: 0.4660 - val_acc: 0.8711\n",
      "Epoch 19/35\n",
      " - 3s - loss: 0.2346 - acc: 0.9395 - val_loss: 0.3980 - val_acc: 0.8965\n",
      "Epoch 20/35\n",
      " - 3s - loss: 0.2203 - acc: 0.9403 - val_loss: 0.4091 - val_acc: 0.8836\n",
      "Epoch 21/35\n",
      " - 4s - loss: 0.2067 - acc: 0.9445 - val_loss: 0.4286 - val_acc: 0.8758\n",
      "Epoch 22/35\n",
      " - 3s - loss: 0.2040 - acc: 0.9437 - val_loss: 0.4247 - val_acc: 0.8863\n",
      "Epoch 23/35\n",
      " - 3s - loss: 0.2072 - acc: 0.9419 - val_loss: 0.4068 - val_acc: 0.8873\n",
      "Epoch 24/35\n",
      " - 3s - loss: 0.2095 - acc: 0.9406 - val_loss: 0.4240 - val_acc: 0.8948\n",
      "Epoch 25/35\n",
      " - 4s - loss: 0.2030 - acc: 0.9437 - val_loss: 0.4013 - val_acc: 0.8887\n",
      "Epoch 26/35\n",
      " - 3s - loss: 0.2031 - acc: 0.9434 - val_loss: 0.3460 - val_acc: 0.9013\n",
      "Epoch 27/35\n",
      " - 3s - loss: 0.1993 - acc: 0.9433 - val_loss: 0.4110 - val_acc: 0.8894\n",
      "Epoch 28/35\n",
      " - 3s - loss: 0.2109 - acc: 0.9423 - val_loss: 0.3851 - val_acc: 0.8941\n",
      "Epoch 29/35\n",
      " - 4s - loss: 0.1909 - acc: 0.9470 - val_loss: 0.3839 - val_acc: 0.8700\n",
      "Epoch 30/35\n",
      " - 3s - loss: 0.1944 - acc: 0.9436 - val_loss: 0.4124 - val_acc: 0.8819\n",
      "Epoch 31/35\n",
      " - 3s - loss: 0.1880 - acc: 0.9446 - val_loss: 0.3479 - val_acc: 0.9057\n",
      "Epoch 32/35\n",
      " - 3s - loss: 0.1930 - acc: 0.9440 - val_loss: 0.3635 - val_acc: 0.9033\n",
      "Epoch 33/35\n",
      " - 4s - loss: 0.2100 - acc: 0.9406 - val_loss: 0.4027 - val_acc: 0.8823\n",
      "Epoch 34/35\n",
      " - 3s - loss: 0.1966 - acc: 0.9422 - val_loss: 0.3719 - val_acc: 0.8958\n",
      "Epoch 35/35\n",
      " - 3s - loss: 0.1822 - acc: 0.9467 - val_loss: 0.3555 - val_acc: 0.8958\n",
      "Train accuracy 0.9435527747551686 Test accuracy: 0.8958262639972854\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_103 (Conv1D)          (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 124, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 62, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 992)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 64)                63552     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,390\n",
      "Trainable params: 66,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 61.2418 - acc: 0.7807 - val_loss: 17.9154 - val_acc: 0.8307\n",
      "Epoch 2/25\n",
      " - 3s - loss: 7.0004 - acc: 0.9026 - val_loss: 2.0242 - val_acc: 0.8775\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.9250 - acc: 0.9052 - val_loss: 0.7673 - val_acc: 0.8320\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.5172 - acc: 0.8939 - val_loss: 0.6225 - val_acc: 0.8734\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.3989 - acc: 0.9127 - val_loss: 0.5753 - val_acc: 0.8785\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3933 - acc: 0.9134 - val_loss: 0.4969 - val_acc: 0.8785\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.3592 - acc: 0.9139 - val_loss: 0.5046 - val_acc: 0.8609\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3358 - acc: 0.9191 - val_loss: 0.4716 - val_acc: 0.8894\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.3132 - acc: 0.9290 - val_loss: 0.4663 - val_acc: 0.8853\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.2976 - acc: 0.9286 - val_loss: 0.4955 - val_acc: 0.8860\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2789 - acc: 0.9327 - val_loss: 0.4329 - val_acc: 0.8795\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.3145 - acc: 0.9233 - val_loss: 0.4440 - val_acc: 0.8968\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2949 - acc: 0.9301 - val_loss: 0.4286 - val_acc: 0.8911\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2932 - acc: 0.9286 - val_loss: 0.4314 - val_acc: 0.8894\n",
      "Epoch 15/25\n",
      " - 3s - loss: 0.2767 - acc: 0.9310 - val_loss: 0.4166 - val_acc: 0.8901\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.2638 - acc: 0.9361 - val_loss: 0.3961 - val_acc: 0.9080\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.2878 - acc: 0.9240 - val_loss: 0.4237 - val_acc: 0.8914\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2730 - acc: 0.9310 - val_loss: 0.3735 - val_acc: 0.9036\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.2677 - acc: 0.9316 - val_loss: 0.3703 - val_acc: 0.8975\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.2409 - acc: 0.9358 - val_loss: 0.3753 - val_acc: 0.8914\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2577 - acc: 0.9331 - val_loss: 0.3721 - val_acc: 0.9053\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2369 - acc: 0.9380 - val_loss: 0.3560 - val_acc: 0.9033\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2323 - acc: 0.9395 - val_loss: 0.4107 - val_acc: 0.8697\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2446 - acc: 0.9355 - val_loss: 0.3456 - val_acc: 0.9077\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.2238 - acc: 0.9389 - val_loss: 0.3664 - val_acc: 0.8918\n",
      "Train accuracy 0.9435527747551686 Test accuracy: 0.8917543264336614\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_105 (Conv1D)          (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 124, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 41, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 656)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 32)                21024     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 23,670\n",
      "Trainable params: 23,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 7s - loss: 16.4963 - acc: 0.7205 - val_loss: 0.9762 - val_acc: 0.7618\n",
      "Epoch 2/25\n",
      " - 5s - loss: 0.7177 - acc: 0.7885 - val_loss: 0.8843 - val_acc: 0.7262\n",
      "Epoch 3/25\n",
      " - 5s - loss: 0.6427 - acc: 0.8033 - val_loss: 0.8549 - val_acc: 0.7533\n",
      "Epoch 4/25\n",
      " - 5s - loss: 0.5748 - acc: 0.8334 - val_loss: 0.7417 - val_acc: 0.7693\n",
      "Epoch 5/25\n",
      " - 5s - loss: 0.5670 - acc: 0.8413 - val_loss: 0.7641 - val_acc: 0.8005\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.5483 - acc: 0.8477 - val_loss: 0.8034 - val_acc: 0.7577\n",
      "Epoch 7/25\n",
      " - 5s - loss: 0.5015 - acc: 0.8679 - val_loss: 0.7603 - val_acc: 0.7838\n",
      "Epoch 8/25\n",
      " - 5s - loss: 0.4859 - acc: 0.8700 - val_loss: 0.6257 - val_acc: 0.8483\n",
      "Epoch 9/25\n",
      " - 5s - loss: 0.4862 - acc: 0.8690 - val_loss: 0.6675 - val_acc: 0.8120\n",
      "Epoch 10/25\n",
      " - 5s - loss: 0.4650 - acc: 0.8716 - val_loss: 0.6007 - val_acc: 0.8551\n",
      "Epoch 11/25\n",
      " - 5s - loss: 0.4490 - acc: 0.8837 - val_loss: 0.8165 - val_acc: 0.6970\n",
      "Epoch 12/25\n",
      " - 5s - loss: 0.4440 - acc: 0.8815 - val_loss: 0.6560 - val_acc: 0.8358\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.4510 - acc: 0.8821 - val_loss: 0.6922 - val_acc: 0.7920\n",
      "Epoch 14/25\n",
      " - 5s - loss: 0.4448 - acc: 0.8808 - val_loss: 0.5452 - val_acc: 0.8551\n",
      "Epoch 15/25\n",
      " - 5s - loss: 0.4215 - acc: 0.8905 - val_loss: 0.6148 - val_acc: 0.8364\n",
      "Epoch 16/25\n",
      " - 5s - loss: 0.4211 - acc: 0.8908 - val_loss: 0.6086 - val_acc: 0.8364\n",
      "Epoch 17/25\n",
      " - 5s - loss: 0.4142 - acc: 0.8913 - val_loss: 0.5331 - val_acc: 0.8537\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.4037 - acc: 0.8946 - val_loss: 0.6793 - val_acc: 0.7917\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.4182 - acc: 0.8916 - val_loss: 0.6947 - val_acc: 0.7876\n",
      "Epoch 20/25\n",
      " - 5s - loss: 0.4134 - acc: 0.8947 - val_loss: 0.4953 - val_acc: 0.8521\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.4253 - acc: 0.8894 - val_loss: 0.6991 - val_acc: 0.7998\n",
      "Epoch 22/25\n",
      " - 5s - loss: 0.4191 - acc: 0.8909 - val_loss: 0.5239 - val_acc: 0.8554\n",
      "Epoch 23/25\n",
      " - 5s - loss: 0.3939 - acc: 0.8965 - val_loss: 0.5239 - val_acc: 0.8290\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.3978 - acc: 0.9004 - val_loss: 0.5010 - val_acc: 0.8571\n",
      "Epoch 25/25\n",
      " - 5s - loss: 0.3926 - acc: 0.8983 - val_loss: 0.5566 - val_acc: 0.8521\n",
      "Train accuracy 0.8876496191512514 Test accuracy: 0.8520529351883271\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_107 (Conv1D)          (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 124, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 41, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 656)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 32)                21024     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 23,670\n",
      "Trainable params: 23,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 7.2943 - acc: 0.7276 - val_loss: 0.8502 - val_acc: 0.7431\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.5941 - acc: 0.8410 - val_loss: 0.7489 - val_acc: 0.7570\n",
      "Epoch 3/30\n",
      " - 3s - loss: 0.5049 - acc: 0.8648 - val_loss: 0.6635 - val_acc: 0.8062\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.4655 - acc: 0.8711 - val_loss: 0.5653 - val_acc: 0.8531\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.4304 - acc: 0.8838 - val_loss: 0.5208 - val_acc: 0.8616\n",
      "Epoch 6/30\n",
      " - 4s - loss: 0.3982 - acc: 0.8901 - val_loss: 0.5428 - val_acc: 0.8578\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.3815 - acc: 0.8980 - val_loss: 0.7239 - val_acc: 0.7750\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.3717 - acc: 0.8989 - val_loss: 0.5074 - val_acc: 0.8649\n",
      "Epoch 9/30\n",
      " - 3s - loss: 0.3615 - acc: 0.9022 - val_loss: 0.4470 - val_acc: 0.8962\n",
      "Epoch 10/30\n",
      " - 4s - loss: 0.3477 - acc: 0.9066 - val_loss: 0.4825 - val_acc: 0.8636\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.3445 - acc: 0.9048 - val_loss: 0.4878 - val_acc: 0.8490\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.3378 - acc: 0.9097 - val_loss: 0.5034 - val_acc: 0.8602\n",
      "Epoch 13/30\n",
      " - 4s - loss: 0.3318 - acc: 0.9085 - val_loss: 0.4340 - val_acc: 0.8924\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.3295 - acc: 0.9104 - val_loss: 0.4473 - val_acc: 0.8809\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.3224 - acc: 0.9187 - val_loss: 0.4072 - val_acc: 0.8938\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.3168 - acc: 0.9129 - val_loss: 0.4318 - val_acc: 0.8761\n",
      "Epoch 17/30\n",
      " - 4s - loss: 0.3249 - acc: 0.9119 - val_loss: 0.4234 - val_acc: 0.8833\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.3150 - acc: 0.9159 - val_loss: 0.4262 - val_acc: 0.8778\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.3131 - acc: 0.9158 - val_loss: 0.4219 - val_acc: 0.8680\n",
      "Epoch 20/30\n",
      " - 4s - loss: 0.3087 - acc: 0.9153 - val_loss: 0.4145 - val_acc: 0.8755\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.3102 - acc: 0.9183 - val_loss: 0.5523 - val_acc: 0.8415\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.3104 - acc: 0.9172 - val_loss: 0.7635 - val_acc: 0.7448\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.3073 - acc: 0.9150 - val_loss: 0.7141 - val_acc: 0.7628\n",
      "Epoch 24/30\n",
      " - 4s - loss: 0.3022 - acc: 0.9212 - val_loss: 0.4858 - val_acc: 0.8259\n",
      "Epoch 25/30\n",
      " - 3s - loss: 0.3095 - acc: 0.9219 - val_loss: 0.5848 - val_acc: 0.7947\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.2968 - acc: 0.9222 - val_loss: 0.5530 - val_acc: 0.8107\n",
      "Epoch 27/30\n",
      " - 4s - loss: 0.2942 - acc: 0.9215 - val_loss: 0.4663 - val_acc: 0.8537\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.3014 - acc: 0.9189 - val_loss: 0.4815 - val_acc: 0.8263\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.2998 - acc: 0.9187 - val_loss: 0.6146 - val_acc: 0.7825\n",
      "Epoch 30/30\n",
      " - 4s - loss: 0.3029 - acc: 0.9177 - val_loss: 0.5795 - val_acc: 0.8025\n",
      "Train accuracy 0.8590859630032645 Test accuracy: 0.8025110281642348\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_109 (Conv1D)          (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 124, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 32)                63520     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 67,718\n",
      "Trainable params: 67,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 7s - loss: 8.6993 - acc: 0.7422 - val_loss: 0.9144 - val_acc: 0.7784\n",
      "Epoch 2/25\n",
      " - 5s - loss: 0.5869 - acc: 0.8547 - val_loss: 0.7051 - val_acc: 0.8303\n",
      "Epoch 3/25\n",
      " - 5s - loss: 0.4864 - acc: 0.8800 - val_loss: 0.6360 - val_acc: 0.8276\n",
      "Epoch 4/25\n",
      " - 5s - loss: 0.4354 - acc: 0.8913 - val_loss: 0.6226 - val_acc: 0.8449\n",
      "Epoch 5/25\n",
      " - 5s - loss: 0.4105 - acc: 0.8932 - val_loss: 0.5604 - val_acc: 0.8558\n",
      "Epoch 6/25\n",
      " - 5s - loss: 0.3962 - acc: 0.8989 - val_loss: 0.6237 - val_acc: 0.8049\n",
      "Epoch 7/25\n",
      " - 5s - loss: 0.3891 - acc: 0.9027 - val_loss: 0.5631 - val_acc: 0.8487\n",
      "Epoch 8/25\n",
      " - 5s - loss: 0.3631 - acc: 0.9071 - val_loss: 0.5022 - val_acc: 0.8568\n",
      "Epoch 9/25\n",
      " - 5s - loss: 0.3509 - acc: 0.9106 - val_loss: 0.5078 - val_acc: 0.8738\n",
      "Epoch 10/25\n",
      " - 5s - loss: 0.3263 - acc: 0.9173 - val_loss: 0.4969 - val_acc: 0.8483\n",
      "Epoch 11/25\n",
      " - 5s - loss: 0.3202 - acc: 0.9200 - val_loss: 0.4656 - val_acc: 0.8616\n",
      "Epoch 12/25\n",
      " - 5s - loss: 0.3206 - acc: 0.9196 - val_loss: 0.4649 - val_acc: 0.8785\n",
      "Epoch 13/25\n",
      " - 5s - loss: 0.3091 - acc: 0.9232 - val_loss: 0.4803 - val_acc: 0.8812\n",
      "Epoch 14/25\n",
      " - 5s - loss: 0.3051 - acc: 0.9263 - val_loss: 0.4823 - val_acc: 0.8619\n",
      "Epoch 15/25\n",
      " - 5s - loss: 0.2792 - acc: 0.9289 - val_loss: 0.5387 - val_acc: 0.8429\n",
      "Epoch 16/25\n",
      " - 5s - loss: 0.3156 - acc: 0.9218 - val_loss: 0.4439 - val_acc: 0.8626\n",
      "Epoch 17/25\n",
      " - 5s - loss: 0.2922 - acc: 0.9238 - val_loss: 0.4209 - val_acc: 0.8924\n",
      "Epoch 18/25\n",
      " - 5s - loss: 0.2949 - acc: 0.9249 - val_loss: 0.3998 - val_acc: 0.8921\n",
      "Epoch 19/25\n",
      " - 5s - loss: 0.3135 - acc: 0.9197 - val_loss: 0.4041 - val_acc: 0.8856\n",
      "Epoch 20/25\n",
      " - 5s - loss: 0.3087 - acc: 0.9219 - val_loss: 0.4810 - val_acc: 0.8551\n",
      "Epoch 21/25\n",
      " - 5s - loss: 0.3053 - acc: 0.9222 - val_loss: 0.3927 - val_acc: 0.8812\n",
      "Epoch 22/25\n",
      " - 5s - loss: 0.2906 - acc: 0.9253 - val_loss: 0.4503 - val_acc: 0.8761\n",
      "Epoch 23/25\n",
      " - 5s - loss: 0.2750 - acc: 0.9282 - val_loss: 0.4167 - val_acc: 0.8687\n",
      "Epoch 24/25\n",
      " - 5s - loss: 0.2985 - acc: 0.9210 - val_loss: 0.4217 - val_acc: 0.8768\n",
      "Epoch 25/25\n",
      " - 5s - loss: 0.2726 - acc: 0.9304 - val_loss: 0.4347 - val_acc: 0.8551\n",
      "Train accuracy 0.9181175190424374 Test accuracy: 0.8551068883610451\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_111 (Conv1D)          (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 124, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 41, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 656)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 64)                42048     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 44,886\n",
      "Trainable params: 44,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 5s - loss: 27.9803 - acc: 0.7326 - val_loss: 4.8843 - val_acc: 0.8341\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.7250 - acc: 0.8796 - val_loss: 0.9626 - val_acc: 0.8531\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.5489 - acc: 0.8970 - val_loss: 0.7314 - val_acc: 0.8690\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.4823 - acc: 0.8976 - val_loss: 0.7276 - val_acc: 0.8517\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.4579 - acc: 0.8988 - val_loss: 0.6242 - val_acc: 0.8812\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.4022 - acc: 0.9132 - val_loss: 0.6094 - val_acc: 0.8711\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.4023 - acc: 0.9068 - val_loss: 0.5805 - val_acc: 0.8717\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.3912 - acc: 0.9120 - val_loss: 0.5675 - val_acc: 0.8687\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.3744 - acc: 0.9151 - val_loss: 0.5704 - val_acc: 0.8646\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.3729 - acc: 0.9116 - val_loss: 0.5922 - val_acc: 0.8558\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.3599 - acc: 0.9142 - val_loss: 0.5119 - val_acc: 0.8789\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.3326 - acc: 0.9197 - val_loss: 0.4924 - val_acc: 0.9002\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.3300 - acc: 0.9226 - val_loss: 0.5215 - val_acc: 0.8690\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.3783 - acc: 0.9075 - val_loss: 0.5516 - val_acc: 0.8683\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.3454 - acc: 0.9181 - val_loss: 0.5556 - val_acc: 0.8521\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.3029 - acc: 0.9256 - val_loss: 0.5167 - val_acc: 0.8490\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.3295 - acc: 0.9169 - val_loss: 0.5313 - val_acc: 0.8429\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.3239 - acc: 0.9177 - val_loss: 0.4892 - val_acc: 0.8880\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.3016 - acc: 0.9241 - val_loss: 0.4432 - val_acc: 0.8968\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.3012 - acc: 0.9274 - val_loss: 0.4653 - val_acc: 0.8738\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.3161 - acc: 0.9225 - val_loss: 0.5062 - val_acc: 0.8497\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.3164 - acc: 0.9255 - val_loss: 0.4527 - val_acc: 0.8728\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.3161 - acc: 0.9203 - val_loss: 0.4972 - val_acc: 0.8347\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.2993 - acc: 0.9259 - val_loss: 0.5269 - val_acc: 0.8290\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.2912 - acc: 0.9300 - val_loss: 0.4920 - val_acc: 0.8585\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.3039 - acc: 0.9289 - val_loss: 0.5328 - val_acc: 0.8076\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.2863 - acc: 0.9274 - val_loss: 0.6839 - val_acc: 0.7805\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.3049 - acc: 0.9226 - val_loss: 0.5165 - val_acc: 0.8307\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2806 - acc: 0.9295 - val_loss: 0.4749 - val_acc: 0.8493\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2847 - acc: 0.9260 - val_loss: 0.5675 - val_acc: 0.8361\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.3033 - acc: 0.9251 - val_loss: 0.5231 - val_acc: 0.8137\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2704 - acc: 0.9350 - val_loss: 0.4261 - val_acc: 0.8694\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2841 - acc: 0.9278 - val_loss: 0.4470 - val_acc: 0.8565\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.3377 - acc: 0.9181 - val_loss: 0.5030 - val_acc: 0.8497\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.2961 - acc: 0.9260 - val_loss: 0.4879 - val_acc: 0.8402\n",
      "Train accuracy 0.8993471164309031 Test accuracy: 0.840176450627757\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_113 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 120, 24)           2328      \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_57 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 32)                30752     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 35,326\n",
      "Trainable params: 35,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 7s - loss: 11.9047 - acc: 0.7330 - val_loss: 1.0429 - val_acc: 0.8388\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.5299 - acc: 0.9006 - val_loss: 0.7633 - val_acc: 0.7896\n",
      "Epoch 3/25\n",
      " - 4s - loss: 0.4528 - acc: 0.9064 - val_loss: 0.6281 - val_acc: 0.8914\n",
      "Epoch 4/25\n",
      " - 4s - loss: 0.3801 - acc: 0.9203 - val_loss: 0.5500 - val_acc: 0.8972\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.3590 - acc: 0.9234 - val_loss: 0.5300 - val_acc: 0.9067\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.3219 - acc: 0.9336 - val_loss: 0.4778 - val_acc: 0.9114\n",
      "Epoch 7/25\n",
      " - 4s - loss: 0.3146 - acc: 0.9314 - val_loss: 0.4738 - val_acc: 0.9209\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.2984 - acc: 0.9348 - val_loss: 0.4679 - val_acc: 0.8965\n",
      "Epoch 9/25\n",
      " - 4s - loss: 0.2966 - acc: 0.9324 - val_loss: 0.4545 - val_acc: 0.8996\n",
      "Epoch 10/25\n",
      " - 4s - loss: 0.2879 - acc: 0.9372 - val_loss: 0.4596 - val_acc: 0.8951\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.2605 - acc: 0.9369 - val_loss: 0.4331 - val_acc: 0.9087\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.2811 - acc: 0.9325 - val_loss: 0.4510 - val_acc: 0.8880\n",
      "Epoch 13/25\n",
      " - 4s - loss: 0.2786 - acc: 0.9289 - val_loss: 0.4101 - val_acc: 0.9101\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.2687 - acc: 0.9357 - val_loss: 0.4053 - val_acc: 0.9094\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2467 - acc: 0.9358 - val_loss: 0.4430 - val_acc: 0.8744\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.2594 - acc: 0.9343 - val_loss: 0.3756 - val_acc: 0.9118\n",
      "Epoch 17/25\n",
      " - 4s - loss: 0.2373 - acc: 0.9392 - val_loss: 0.4044 - val_acc: 0.9013\n",
      "Epoch 18/25\n",
      " - 4s - loss: 0.2518 - acc: 0.9340 - val_loss: 0.4091 - val_acc: 0.8999\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2256 - acc: 0.9395 - val_loss: 0.4113 - val_acc: 0.9030\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2416 - acc: 0.9382 - val_loss: 0.3761 - val_acc: 0.9063\n",
      "Epoch 21/25\n",
      " - 4s - loss: 0.2725 - acc: 0.9342 - val_loss: 0.4235 - val_acc: 0.8700\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.2309 - acc: 0.9408 - val_loss: 0.3487 - val_acc: 0.9094\n",
      "Epoch 23/25\n",
      " - 4s - loss: 0.2238 - acc: 0.9393 - val_loss: 0.3771 - val_acc: 0.8921\n",
      "Epoch 24/25\n",
      " - 4s - loss: 0.2318 - acc: 0.9395 - val_loss: 0.3915 - val_acc: 0.8948\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2398 - acc: 0.9385 - val_loss: 0.3975 - val_acc: 0.8992\n",
      "Train accuracy 0.9426006528835691 Test accuracy: 0.8992195453003053\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_115 (Conv1D)          (None, 126, 42)           1176      \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 124, 16)           2032      \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 62, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_58 (Flatten)         (None, 992)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 32)                31776     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 35,182\n",
      "Trainable params: 35,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 14.7012 - acc: 0.6877 - val_loss: 0.8706 - val_acc: 0.7360\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.6944 - acc: 0.7756 - val_loss: 0.8193 - val_acc: 0.7041\n",
      "Epoch 3/30\n",
      " - 3s - loss: 0.6406 - acc: 0.7889 - val_loss: 0.8631 - val_acc: 0.6956\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.5999 - acc: 0.8164 - val_loss: 0.6735 - val_acc: 0.8215\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.5779 - acc: 0.8229 - val_loss: 0.6811 - val_acc: 0.7900\n",
      "Epoch 6/30\n",
      " - 4s - loss: 0.5616 - acc: 0.8368 - val_loss: 0.7271 - val_acc: 0.7516\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.5464 - acc: 0.8478 - val_loss: 0.6052 - val_acc: 0.8320\n",
      "Epoch 8/30\n",
      " - 4s - loss: 0.5315 - acc: 0.8543 - val_loss: 0.5811 - val_acc: 0.8527\n",
      "Epoch 9/30\n",
      " - 3s - loss: 0.5092 - acc: 0.8615 - val_loss: 0.7547 - val_acc: 0.7231\n",
      "Epoch 10/30\n",
      " - 3s - loss: 0.5060 - acc: 0.8584 - val_loss: 0.6030 - val_acc: 0.8249\n",
      "Epoch 11/30\n",
      " - 4s - loss: 0.4834 - acc: 0.8675 - val_loss: 0.5663 - val_acc: 0.8500\n",
      "Epoch 12/30\n",
      " - 4s - loss: 0.4845 - acc: 0.8712 - val_loss: 0.7085 - val_acc: 0.7655\n",
      "Epoch 13/30\n",
      " - 4s - loss: 0.4791 - acc: 0.8742 - val_loss: 0.8315 - val_acc: 0.6878\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.4715 - acc: 0.8764 - val_loss: 0.5696 - val_acc: 0.8534\n",
      "Epoch 15/30\n",
      " - 4s - loss: 0.4533 - acc: 0.8830 - val_loss: 0.5168 - val_acc: 0.8687\n",
      "Epoch 16/30\n",
      " - 4s - loss: 0.4437 - acc: 0.8872 - val_loss: 0.6593 - val_acc: 0.8100\n",
      "Epoch 17/30\n",
      " - 4s - loss: 0.4491 - acc: 0.8818 - val_loss: 0.5698 - val_acc: 0.8300\n",
      "Epoch 18/30\n",
      " - 4s - loss: 0.4456 - acc: 0.8821 - val_loss: 0.6786 - val_acc: 0.8168\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.4313 - acc: 0.8872 - val_loss: 0.5501 - val_acc: 0.8354\n",
      "Epoch 20/30\n",
      " - 4s - loss: 0.4336 - acc: 0.8834 - val_loss: 0.5132 - val_acc: 0.8544\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.4324 - acc: 0.8874 - val_loss: 0.5285 - val_acc: 0.8558\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.4168 - acc: 0.8891 - val_loss: 0.5715 - val_acc: 0.8327\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.4104 - acc: 0.8916 - val_loss: 0.5952 - val_acc: 0.7900\n",
      "Epoch 24/30\n",
      " - 4s - loss: 0.4203 - acc: 0.8908 - val_loss: 0.5545 - val_acc: 0.8660\n",
      "Epoch 25/30\n",
      " - 4s - loss: 0.4052 - acc: 0.8955 - val_loss: 0.5544 - val_acc: 0.8524\n",
      "Epoch 26/30\n",
      " - 4s - loss: 0.4167 - acc: 0.8909 - val_loss: 0.5528 - val_acc: 0.8320\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.4202 - acc: 0.8921 - val_loss: 0.8486 - val_acc: 0.7513\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.4147 - acc: 0.8939 - val_loss: 0.7550 - val_acc: 0.7662\n",
      "Epoch 29/30\n",
      " - 4s - loss: 0.4339 - acc: 0.8874 - val_loss: 0.5216 - val_acc: 0.8548\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.4258 - acc: 0.8906 - val_loss: 0.5663 - val_acc: 0.8303\n",
      "Train accuracy 0.8703754080522307 Test accuracy: 0.830335934848999\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_117 (Conv1D)          (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 122, 16)           2576      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 122, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 40, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_59 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 32)                20512     \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 24,182\n",
      "Trainable params: 24,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 7s - loss: 30.8358 - acc: 0.7058 - val_loss: 4.4262 - val_acc: 0.7044\n",
      "Epoch 2/25\n",
      " - 3s - loss: 1.6429 - acc: 0.8126 - val_loss: 0.9871 - val_acc: 0.7808\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.6854 - acc: 0.8286 - val_loss: 0.8757 - val_acc: 0.7448\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.6262 - acc: 0.8341 - val_loss: 0.8295 - val_acc: 0.7696\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.5936 - acc: 0.8429 - val_loss: 0.7578 - val_acc: 0.8246\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.5399 - acc: 0.8606 - val_loss: 0.7201 - val_acc: 0.8283\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.5115 - acc: 0.8711 - val_loss: 0.7028 - val_acc: 0.8398\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.4914 - acc: 0.8735 - val_loss: 0.6664 - val_acc: 0.8307\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.4766 - acc: 0.8785 - val_loss: 0.6513 - val_acc: 0.8012\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.4898 - acc: 0.8681 - val_loss: 0.6588 - val_acc: 0.8310\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.4643 - acc: 0.8757 - val_loss: 0.5893 - val_acc: 0.8470\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.4451 - acc: 0.8817 - val_loss: 0.6121 - val_acc: 0.8358\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.4549 - acc: 0.8784 - val_loss: 0.6512 - val_acc: 0.8504\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.4309 - acc: 0.8864 - val_loss: 0.5802 - val_acc: 0.8419\n",
      "Epoch 15/25\n",
      " - 3s - loss: 0.4286 - acc: 0.8844 - val_loss: 0.5748 - val_acc: 0.8442\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.4097 - acc: 0.8936 - val_loss: 0.6548 - val_acc: 0.8344\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.4001 - acc: 0.8968 - val_loss: 0.6155 - val_acc: 0.8320\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.3991 - acc: 0.8940 - val_loss: 0.6884 - val_acc: 0.7801\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.3960 - acc: 0.8954 - val_loss: 0.5954 - val_acc: 0.8470\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.3976 - acc: 0.8945 - val_loss: 0.5961 - val_acc: 0.8541\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.3984 - acc: 0.8927 - val_loss: 0.5921 - val_acc: 0.8609\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.3844 - acc: 0.9037 - val_loss: 0.5499 - val_acc: 0.8731\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.3692 - acc: 0.9052 - val_loss: 0.6297 - val_acc: 0.8683\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.3578 - acc: 0.9076 - val_loss: 0.5555 - val_acc: 0.8571\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.3592 - acc: 0.9101 - val_loss: 0.5500 - val_acc: 0.8653\n",
      "Train accuracy 0.9319912948857454 Test accuracy: 0.8652867322701052\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_119 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 120, 24)           2328      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_60 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,270\n",
      "Trainable params: 66,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 4.3495 - acc: 0.7495 - val_loss: 2.7413 - val_acc: 0.8459\n",
      "Epoch 2/25\n",
      " - 2s - loss: 1.6296 - acc: 0.9180 - val_loss: 1.1715 - val_acc: 0.9030\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.6645 - acc: 0.9475 - val_loss: 0.6454 - val_acc: 0.9036\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.3430 - acc: 0.9521 - val_loss: 0.4889 - val_acc: 0.9077\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.2451 - acc: 0.9516 - val_loss: 0.3857 - val_acc: 0.9318\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.2238 - acc: 0.9494 - val_loss: 0.3657 - val_acc: 0.9165\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.1939 - acc: 0.9551 - val_loss: 0.3421 - val_acc: 0.9274\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.2014 - acc: 0.9508 - val_loss: 0.3561 - val_acc: 0.9040\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.2014 - acc: 0.9498 - val_loss: 0.3117 - val_acc: 0.9192\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.1794 - acc: 0.9544 - val_loss: 0.3435 - val_acc: 0.9138\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.1780 - acc: 0.9514 - val_loss: 0.3316 - val_acc: 0.9138\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.1713 - acc: 0.9553 - val_loss: 0.3260 - val_acc: 0.9186\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.1568 - acc: 0.9577 - val_loss: 0.3113 - val_acc: 0.9220\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.1623 - acc: 0.9536 - val_loss: 0.3801 - val_acc: 0.8907\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.1637 - acc: 0.9558 - val_loss: 0.3516 - val_acc: 0.9257\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.1611 - acc: 0.9531 - val_loss: 0.3047 - val_acc: 0.9155\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.1498 - acc: 0.9578 - val_loss: 0.2892 - val_acc: 0.9301\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.1437 - acc: 0.9573 - val_loss: 0.3393 - val_acc: 0.9243\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.1408 - acc: 0.9591 - val_loss: 0.4105 - val_acc: 0.8721\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.1563 - acc: 0.9555 - val_loss: 0.3408 - val_acc: 0.9233\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.1300 - acc: 0.9606 - val_loss: 0.3021 - val_acc: 0.9287\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.1408 - acc: 0.9565 - val_loss: 0.3086 - val_acc: 0.9240\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.1346 - acc: 0.9587 - val_loss: 0.3492 - val_acc: 0.9114\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.1383 - acc: 0.9588 - val_loss: 0.3698 - val_acc: 0.9077\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.1302 - acc: 0.9607 - val_loss: 0.2972 - val_acc: 0.9230\n",
      "Train accuracy 0.963139281828074 Test accuracy: 0.9229725144214456\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_121 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 120, 24)           2328      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 60, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 64)                92224     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 96,990\n",
      "Trainable params: 96,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 5s - loss: 27.4172 - acc: 0.7273 - val_loss: 12.6662 - val_acc: 0.8453\n",
      "Epoch 2/25\n",
      " - 3s - loss: 6.5987 - acc: 0.9127 - val_loss: 3.0875 - val_acc: 0.8782\n",
      "Epoch 3/25\n",
      " - 2s - loss: 1.5861 - acc: 0.9219 - val_loss: 1.0655 - val_acc: 0.8765\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.5844 - acc: 0.9236 - val_loss: 0.6587 - val_acc: 0.9026\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.3850 - acc: 0.9339 - val_loss: 0.5537 - val_acc: 0.8982\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.3433 - acc: 0.9335 - val_loss: 0.5426 - val_acc: 0.9023\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.3233 - acc: 0.9340 - val_loss: 0.5043 - val_acc: 0.8962\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.2895 - acc: 0.9387 - val_loss: 0.4914 - val_acc: 0.9084\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.2862 - acc: 0.9366 - val_loss: 0.4630 - val_acc: 0.9057\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.2778 - acc: 0.9384 - val_loss: 0.4865 - val_acc: 0.8799\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.2695 - acc: 0.9363 - val_loss: 0.4534 - val_acc: 0.8812\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.2514 - acc: 0.9406 - val_loss: 0.4256 - val_acc: 0.8955\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2533 - acc: 0.9406 - val_loss: 0.4506 - val_acc: 0.8965\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2557 - acc: 0.9353 - val_loss: 0.5058 - val_acc: 0.8714\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.2636 - acc: 0.9373 - val_loss: 0.4219 - val_acc: 0.9060\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.2238 - acc: 0.9445 - val_loss: 0.3794 - val_acc: 0.9023\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.2370 - acc: 0.9412 - val_loss: 0.4036 - val_acc: 0.8965\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2350 - acc: 0.9400 - val_loss: 0.3961 - val_acc: 0.9002\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.2232 - acc: 0.9426 - val_loss: 0.3953 - val_acc: 0.9053\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2194 - acc: 0.9418 - val_loss: 0.3681 - val_acc: 0.8951\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2250 - acc: 0.9406 - val_loss: 0.4315 - val_acc: 0.8806\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.2268 - acc: 0.9392 - val_loss: 0.3884 - val_acc: 0.8955\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.2149 - acc: 0.9429 - val_loss: 0.3738 - val_acc: 0.8999\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2221 - acc: 0.9411 - val_loss: 0.3491 - val_acc: 0.8999\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2237 - acc: 0.9422 - val_loss: 0.3724 - val_acc: 0.9101\n",
      "Train accuracy 0.9445048966267682 Test accuracy: 0.9100780454699695\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_123 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_62 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,110\n",
      "Trainable params: 68,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 48.8714 - acc: 0.6624 - val_loss: 27.6073 - val_acc: 0.8364\n",
      "Epoch 2/30\n",
      " - 2s - loss: 16.7984 - acc: 0.8972 - val_loss: 9.5414 - val_acc: 0.8853\n",
      "Epoch 3/30\n",
      " - 2s - loss: 5.6073 - acc: 0.9221 - val_loss: 3.3938 - val_acc: 0.8768\n",
      "Epoch 4/30\n",
      " - 2s - loss: 1.9049 - acc: 0.9268 - val_loss: 1.4708 - val_acc: 0.8694\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.7797 - acc: 0.9310 - val_loss: 0.8697 - val_acc: 0.8711\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.4685 - acc: 0.9275 - val_loss: 0.6930 - val_acc: 0.8782\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3873 - acc: 0.9305 - val_loss: 0.6478 - val_acc: 0.9046\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.3268 - acc: 0.9368 - val_loss: 0.5983 - val_acc: 0.9053\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.3140 - acc: 0.9348 - val_loss: 0.5803 - val_acc: 0.8894\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.3050 - acc: 0.9323 - val_loss: 0.5903 - val_acc: 0.8901\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.2910 - acc: 0.9385 - val_loss: 0.5271 - val_acc: 0.8918\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.2688 - acc: 0.9441 - val_loss: 0.5027 - val_acc: 0.8968\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.2691 - acc: 0.9393 - val_loss: 0.5169 - val_acc: 0.8941\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.2542 - acc: 0.9415 - val_loss: 0.4986 - val_acc: 0.9016\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2475 - acc: 0.9434 - val_loss: 0.4838 - val_acc: 0.8955\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.2497 - acc: 0.9419 - val_loss: 0.4614 - val_acc: 0.8985\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2488 - acc: 0.9392 - val_loss: 0.4339 - val_acc: 0.9128\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2300 - acc: 0.9441 - val_loss: 0.4668 - val_acc: 0.8951\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2301 - acc: 0.9457 - val_loss: 0.4250 - val_acc: 0.9087\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2273 - acc: 0.9453 - val_loss: 0.4139 - val_acc: 0.9125\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2198 - acc: 0.9444 - val_loss: 0.4311 - val_acc: 0.8996\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2353 - acc: 0.9410 - val_loss: 0.4143 - val_acc: 0.9104\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2480 - acc: 0.9355 - val_loss: 0.4795 - val_acc: 0.8833\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2190 - acc: 0.9478 - val_loss: 0.4147 - val_acc: 0.9060\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2066 - acc: 0.9486 - val_loss: 0.4049 - val_acc: 0.9084\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2046 - acc: 0.9470 - val_loss: 0.3908 - val_acc: 0.9101\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2176 - acc: 0.9411 - val_loss: 0.4208 - val_acc: 0.9043\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2134 - acc: 0.9456 - val_loss: 0.3780 - val_acc: 0.9128\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2012 - acc: 0.9459 - val_loss: 0.3973 - val_acc: 0.9019\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2140 - acc: 0.9436 - val_loss: 0.3785 - val_acc: 0.9179\n",
      "Train accuracy 0.9499455930359086 Test accuracy: 0.9178825924669155\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_125 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_63 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,110\n",
      "Trainable params: 68,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 17.3823 - acc: 0.7144 - val_loss: 1.3445 - val_acc: 0.6675\n",
      "Epoch 2/30\n",
      " - 2s - loss: 0.6146 - acc: 0.8607 - val_loss: 0.6483 - val_acc: 0.8622\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.4675 - acc: 0.8891 - val_loss: 0.7659 - val_acc: 0.7689\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.4013 - acc: 0.8998 - val_loss: 0.5965 - val_acc: 0.8354\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.3879 - acc: 0.9037 - val_loss: 0.7299 - val_acc: 0.7486\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.3623 - acc: 0.9095 - val_loss: 0.5280 - val_acc: 0.8670\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3590 - acc: 0.9106 - val_loss: 0.6155 - val_acc: 0.7988\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.3565 - acc: 0.9087 - val_loss: 0.5859 - val_acc: 0.7967\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.3546 - acc: 0.9140 - val_loss: 0.4361 - val_acc: 0.8802\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.3319 - acc: 0.9225 - val_loss: 0.4676 - val_acc: 0.8544\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.3379 - acc: 0.9143 - val_loss: 0.4439 - val_acc: 0.8996\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.3215 - acc: 0.9206 - val_loss: 0.4290 - val_acc: 0.8694\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.3270 - acc: 0.9159 - val_loss: 0.4299 - val_acc: 0.8887\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.3173 - acc: 0.9166 - val_loss: 0.5044 - val_acc: 0.8656\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.3308 - acc: 0.9163 - val_loss: 0.4358 - val_acc: 0.8890\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.3168 - acc: 0.9184 - val_loss: 0.4497 - val_acc: 0.8819\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.3055 - acc: 0.9226 - val_loss: 0.4123 - val_acc: 0.8836\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.3059 - acc: 0.9210 - val_loss: 0.4720 - val_acc: 0.8487\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.3089 - acc: 0.9183 - val_loss: 0.4604 - val_acc: 0.8707\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2968 - acc: 0.9176 - val_loss: 0.6224 - val_acc: 0.7991\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.3209 - acc: 0.9176 - val_loss: 0.4251 - val_acc: 0.8931\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2925 - acc: 0.9252 - val_loss: 0.7995 - val_acc: 0.7713\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2963 - acc: 0.9192 - val_loss: 0.5472 - val_acc: 0.8446\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.3154 - acc: 0.9144 - val_loss: 0.4371 - val_acc: 0.8951\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.3020 - acc: 0.9236 - val_loss: 0.4852 - val_acc: 0.8677\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.3015 - acc: 0.9197 - val_loss: 0.4004 - val_acc: 0.8897\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.3085 - acc: 0.9200 - val_loss: 0.5358 - val_acc: 0.8541\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2895 - acc: 0.9229 - val_loss: 0.4264 - val_acc: 0.8761\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2990 - acc: 0.9237 - val_loss: 0.4062 - val_acc: 0.9023\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2972 - acc: 0.9238 - val_loss: 0.3753 - val_acc: 0.8935\n",
      "Train accuracy 0.9510337323177367 Test accuracy: 0.8934509670851714\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_127 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,110\n",
      "Trainable params: 68,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 50.6101 - acc: 0.7337 - val_loss: 28.4510 - val_acc: 0.8269\n",
      "Epoch 2/30\n",
      " - 2s - loss: 17.0244 - acc: 0.9115 - val_loss: 9.3103 - val_acc: 0.8690\n",
      "Epoch 3/30\n",
      " - 2s - loss: 5.2981 - acc: 0.9325 - val_loss: 3.0019 - val_acc: 0.8897\n",
      "Epoch 4/30\n",
      " - 2s - loss: 1.6300 - acc: 0.9327 - val_loss: 1.2139 - val_acc: 0.8884\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.6281 - acc: 0.9365 - val_loss: 0.6987 - val_acc: 0.8829\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.3841 - acc: 0.9359 - val_loss: 0.5702 - val_acc: 0.8962\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3192 - acc: 0.9389 - val_loss: 0.5314 - val_acc: 0.9070\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.2997 - acc: 0.9373 - val_loss: 0.5211 - val_acc: 0.8850\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.2662 - acc: 0.9430 - val_loss: 0.4786 - val_acc: 0.8962\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.2582 - acc: 0.9422 - val_loss: 0.4569 - val_acc: 0.8972\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.2389 - acc: 0.9479 - val_loss: 0.4533 - val_acc: 0.9009\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.2679 - acc: 0.9353 - val_loss: 0.4625 - val_acc: 0.9016\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.2395 - acc: 0.9459 - val_loss: 0.4290 - val_acc: 0.8968\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.2274 - acc: 0.9471 - val_loss: 0.4270 - val_acc: 0.8921\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2262 - acc: 0.9453 - val_loss: 0.4322 - val_acc: 0.9050\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.2233 - acc: 0.9412 - val_loss: 0.4134 - val_acc: 0.9006\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2170 - acc: 0.9463 - val_loss: 0.4244 - val_acc: 0.9118\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2194 - acc: 0.9433 - val_loss: 0.3974 - val_acc: 0.9240\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2115 - acc: 0.9480 - val_loss: 0.4025 - val_acc: 0.9016\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2032 - acc: 0.9480 - val_loss: 0.3664 - val_acc: 0.9053\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2113 - acc: 0.9434 - val_loss: 0.3845 - val_acc: 0.9237\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2006 - acc: 0.9476 - val_loss: 0.4382 - val_acc: 0.8853\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.1963 - acc: 0.9482 - val_loss: 0.3699 - val_acc: 0.9108\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.1915 - acc: 0.9465 - val_loss: 0.3475 - val_acc: 0.9216\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.1862 - acc: 0.9476 - val_loss: 0.3768 - val_acc: 0.8999\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2347 - acc: 0.9365 - val_loss: 0.3651 - val_acc: 0.9141\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.1887 - acc: 0.9486 - val_loss: 0.3818 - val_acc: 0.9118\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2066 - acc: 0.9434 - val_loss: 0.3828 - val_acc: 0.9111\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.1933 - acc: 0.9475 - val_loss: 0.3741 - val_acc: 0.8975\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.1845 - acc: 0.9459 - val_loss: 0.3850 - val_acc: 0.9030\n",
      "Train accuracy 0.9457290533188248 Test accuracy: 0.9029521547336274\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_129 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_65 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,110\n",
      "Trainable params: 68,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 75.6152 - acc: 0.6952 - val_loss: 45.9681 - val_acc: 0.7750\n",
      "Epoch 2/30\n",
      " - 2s - loss: 29.3537 - acc: 0.8867 - val_loss: 17.2696 - val_acc: 0.8300\n",
      "Epoch 3/30\n",
      " - 2s - loss: 10.5343 - acc: 0.9244 - val_loss: 6.1212 - val_acc: 0.8816\n",
      "Epoch 4/30\n",
      " - 2s - loss: 3.5535 - acc: 0.9350 - val_loss: 2.2469 - val_acc: 0.8819\n",
      "Epoch 5/30\n",
      " - 2s - loss: 1.2534 - acc: 0.9373 - val_loss: 1.0839 - val_acc: 0.9033\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.5805 - acc: 0.9384 - val_loss: 0.7243 - val_acc: 0.8972\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3978 - acc: 0.9378 - val_loss: 0.6027 - val_acc: 0.9002\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.3298 - acc: 0.9400 - val_loss: 0.5543 - val_acc: 0.8979\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.3049 - acc: 0.9362 - val_loss: 0.5385 - val_acc: 0.9046\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.2950 - acc: 0.9406 - val_loss: 0.5479 - val_acc: 0.8941\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.2760 - acc: 0.9403 - val_loss: 0.4846 - val_acc: 0.8989\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.2573 - acc: 0.9425 - val_loss: 0.4912 - val_acc: 0.9053\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.2598 - acc: 0.9414 - val_loss: 0.4741 - val_acc: 0.8955\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.2438 - acc: 0.9461 - val_loss: 0.4556 - val_acc: 0.8979\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2429 - acc: 0.9414 - val_loss: 0.4385 - val_acc: 0.9063\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.2349 - acc: 0.9442 - val_loss: 0.4254 - val_acc: 0.9030\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2380 - acc: 0.9427 - val_loss: 0.4410 - val_acc: 0.8985\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2252 - acc: 0.9476 - val_loss: 0.4381 - val_acc: 0.8877\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2465 - acc: 0.9404 - val_loss: 0.4440 - val_acc: 0.9002\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2148 - acc: 0.9448 - val_loss: 0.4240 - val_acc: 0.8884\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2321 - acc: 0.9418 - val_loss: 0.4024 - val_acc: 0.8914\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2122 - acc: 0.9474 - val_loss: 0.4108 - val_acc: 0.8958\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2165 - acc: 0.9434 - val_loss: 0.4417 - val_acc: 0.9053\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2108 - acc: 0.9489 - val_loss: 0.4565 - val_acc: 0.8785\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2070 - acc: 0.9470 - val_loss: 0.3806 - val_acc: 0.9002\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2096 - acc: 0.9470 - val_loss: 0.3741 - val_acc: 0.9046\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.1974 - acc: 0.9463 - val_loss: 0.3624 - val_acc: 0.9101\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2164 - acc: 0.9437 - val_loss: 0.3966 - val_acc: 0.8985\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2001 - acc: 0.9467 - val_loss: 0.3922 - val_acc: 0.8850\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2130 - acc: 0.9452 - val_loss: 0.3927 - val_acc: 0.9006\n",
      "Train accuracy 0.9483133841131665 Test accuracy: 0.9005768578215134\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_131 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_66 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,110\n",
      "Trainable params: 68,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 9.8358 - acc: 0.7752 - val_loss: 3.4873 - val_acc: 0.8829\n",
      "Epoch 2/30\n",
      " - 2s - loss: 1.6666 - acc: 0.9310 - val_loss: 1.1205 - val_acc: 0.8887\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.5701 - acc: 0.9382 - val_loss: 0.6510 - val_acc: 0.9053\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.3402 - acc: 0.9406 - val_loss: 0.5602 - val_acc: 0.9019\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.2900 - acc: 0.9418 - val_loss: 0.4787 - val_acc: 0.8992\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.2497 - acc: 0.9445 - val_loss: 0.4167 - val_acc: 0.9179\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.2246 - acc: 0.9478 - val_loss: 0.4231 - val_acc: 0.9172\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.2168 - acc: 0.9465 - val_loss: 0.4257 - val_acc: 0.9019\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.2132 - acc: 0.9468 - val_loss: 0.3907 - val_acc: 0.9148\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.2211 - acc: 0.9456 - val_loss: 0.3603 - val_acc: 0.9230\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.2013 - acc: 0.9494 - val_loss: 0.4070 - val_acc: 0.9023\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.1908 - acc: 0.9482 - val_loss: 0.3575 - val_acc: 0.9158\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.1890 - acc: 0.9486 - val_loss: 0.3430 - val_acc: 0.9138\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.1872 - acc: 0.9480 - val_loss: 0.3360 - val_acc: 0.9114\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2020 - acc: 0.9459 - val_loss: 0.3607 - val_acc: 0.9125\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.1848 - acc: 0.9487 - val_loss: 0.3718 - val_acc: 0.9131\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.1780 - acc: 0.9480 - val_loss: 0.3492 - val_acc: 0.9077\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.1795 - acc: 0.9476 - val_loss: 0.3367 - val_acc: 0.9175\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.1733 - acc: 0.9482 - val_loss: 0.3379 - val_acc: 0.9131\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.1718 - acc: 0.9482 - val_loss: 0.3264 - val_acc: 0.9084\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.1770 - acc: 0.9472 - val_loss: 0.3123 - val_acc: 0.9226\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.1857 - acc: 0.9478 - val_loss: 0.3252 - val_acc: 0.8996\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.1692 - acc: 0.9475 - val_loss: 0.3208 - val_acc: 0.9131\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.1672 - acc: 0.9528 - val_loss: 0.3090 - val_acc: 0.9148\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.1827 - acc: 0.9465 - val_loss: 0.3289 - val_acc: 0.9158\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.1814 - acc: 0.9475 - val_loss: 0.3128 - val_acc: 0.8999\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.1691 - acc: 0.9483 - val_loss: 0.3428 - val_acc: 0.9013\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.1641 - acc: 0.9490 - val_loss: 0.3360 - val_acc: 0.9097\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.1837 - acc: 0.9448 - val_loss: 0.3218 - val_acc: 0.9172\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.1594 - acc: 0.9514 - val_loss: 0.3166 - val_acc: 0.9063\n",
      "Train accuracy 0.9511697497279652 Test accuracy: 0.9063454360366474\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_133 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_67 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,110\n",
      "Trainable params: 68,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 29.5171 - acc: 0.7307 - val_loss: 9.1926 - val_acc: 0.8324\n",
      "Epoch 2/30\n",
      " - 2s - loss: 3.8775 - acc: 0.9041 - val_loss: 1.6253 - val_acc: 0.8778\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.7419 - acc: 0.9215 - val_loss: 0.7882 - val_acc: 0.8904\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.4066 - acc: 0.9280 - val_loss: 0.6613 - val_acc: 0.8683\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.3569 - acc: 0.9283 - val_loss: 0.5926 - val_acc: 0.8975\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.3445 - acc: 0.9264 - val_loss: 0.5981 - val_acc: 0.8907\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3012 - acc: 0.9373 - val_loss: 0.5547 - val_acc: 0.8775\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.2942 - acc: 0.9308 - val_loss: 0.5063 - val_acc: 0.8894\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.2903 - acc: 0.9314 - val_loss: 0.4836 - val_acc: 0.8924\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.2852 - acc: 0.9350 - val_loss: 0.4911 - val_acc: 0.8982\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.2793 - acc: 0.9327 - val_loss: 0.5159 - val_acc: 0.8772\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.2785 - acc: 0.9336 - val_loss: 0.4482 - val_acc: 0.8890\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.2623 - acc: 0.9369 - val_loss: 0.4668 - val_acc: 0.8911\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.2623 - acc: 0.9361 - val_loss: 0.4482 - val_acc: 0.8901\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2557 - acc: 0.9377 - val_loss: 0.4461 - val_acc: 0.8938\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.2694 - acc: 0.9329 - val_loss: 0.4687 - val_acc: 0.8823\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2367 - acc: 0.9433 - val_loss: 0.4488 - val_acc: 0.8918\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2474 - acc: 0.9378 - val_loss: 0.4090 - val_acc: 0.8989\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2393 - acc: 0.9403 - val_loss: 0.4958 - val_acc: 0.8687\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2498 - acc: 0.9369 - val_loss: 0.4526 - val_acc: 0.8928\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2361 - acc: 0.9388 - val_loss: 0.4225 - val_acc: 0.8870\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2403 - acc: 0.9366 - val_loss: 0.5166 - val_acc: 0.8666\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2404 - acc: 0.9403 - val_loss: 0.4329 - val_acc: 0.8850\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2283 - acc: 0.9403 - val_loss: 0.4088 - val_acc: 0.8955\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2335 - acc: 0.9395 - val_loss: 0.4425 - val_acc: 0.8639\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2246 - acc: 0.9374 - val_loss: 0.4459 - val_acc: 0.8870\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2145 - acc: 0.9430 - val_loss: 0.4187 - val_acc: 0.8860\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2271 - acc: 0.9402 - val_loss: 0.4269 - val_acc: 0.8656\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2235 - acc: 0.9403 - val_loss: 0.4065 - val_acc: 0.8968\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2315 - acc: 0.9414 - val_loss: 0.3931 - val_acc: 0.8924\n",
      "Train accuracy 0.9420565832426551 Test accuracy: 0.8924329826942654\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_135 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_68 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,110\n",
      "Trainable params: 68,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 92.7670 - acc: 0.7641 - val_loss: 39.0706 - val_acc: 0.7974\n",
      "Epoch 2/30\n",
      " - 2s - loss: 19.4374 - acc: 0.9094 - val_loss: 7.9359 - val_acc: 0.8660\n",
      "Epoch 3/30\n",
      " - 2s - loss: 3.7507 - acc: 0.9168 - val_loss: 1.9581 - val_acc: 0.8035\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.9449 - acc: 0.9123 - val_loss: 0.9198 - val_acc: 0.8446\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.5073 - acc: 0.9208 - val_loss: 0.7195 - val_acc: 0.8901\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.4332 - acc: 0.9184 - val_loss: 0.6707 - val_acc: 0.8911\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3975 - acc: 0.9253 - val_loss: 0.6230 - val_acc: 0.8843\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.3860 - acc: 0.9207 - val_loss: 0.6279 - val_acc: 0.8907\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.3573 - acc: 0.9313 - val_loss: 0.5995 - val_acc: 0.8924\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.3411 - acc: 0.9320 - val_loss: 0.5888 - val_acc: 0.8904\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.3395 - acc: 0.9282 - val_loss: 0.5476 - val_acc: 0.9077\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.3151 - acc: 0.9300 - val_loss: 0.5552 - val_acc: 0.8853\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.3013 - acc: 0.9339 - val_loss: 0.5454 - val_acc: 0.9023\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.3146 - acc: 0.9289 - val_loss: 0.5326 - val_acc: 0.9019\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2978 - acc: 0.9331 - val_loss: 0.5256 - val_acc: 0.8948\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.3063 - acc: 0.9323 - val_loss: 0.5137 - val_acc: 0.8829\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.3023 - acc: 0.9343 - val_loss: 0.5029 - val_acc: 0.8975\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2842 - acc: 0.9332 - val_loss: 0.4836 - val_acc: 0.9006\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2704 - acc: 0.9387 - val_loss: 0.4692 - val_acc: 0.8968\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2799 - acc: 0.9344 - val_loss: 0.4859 - val_acc: 0.8972\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2814 - acc: 0.9344 - val_loss: 0.4948 - val_acc: 0.8755\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2672 - acc: 0.9381 - val_loss: 0.4504 - val_acc: 0.8968\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2564 - acc: 0.9395 - val_loss: 0.4577 - val_acc: 0.8935\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2830 - acc: 0.9316 - val_loss: 0.4942 - val_acc: 0.8785\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2639 - acc: 0.9354 - val_loss: 0.4717 - val_acc: 0.8795\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2492 - acc: 0.9369 - val_loss: 0.4660 - val_acc: 0.8880\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2395 - acc: 0.9408 - val_loss: 0.4492 - val_acc: 0.8928\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2478 - acc: 0.9353 - val_loss: 0.4508 - val_acc: 0.8928\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2549 - acc: 0.9351 - val_loss: 0.4313 - val_acc: 0.9050\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2472 - acc: 0.9388 - val_loss: 0.4157 - val_acc: 0.8924\n",
      "Train accuracy 0.9423286180631121 Test accuracy: 0.8924329826942654\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_137 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_69 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,110\n",
      "Trainable params: 68,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 29.0453 - acc: 0.7511 - val_loss: 13.1608 - val_acc: 0.8514\n",
      "Epoch 2/30\n",
      " - 2s - loss: 6.9638 - acc: 0.9128 - val_loss: 3.5920 - val_acc: 0.8897\n",
      "Epoch 3/30\n",
      " - 2s - loss: 1.8805 - acc: 0.9301 - val_loss: 1.3210 - val_acc: 0.8975\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.6821 - acc: 0.9355 - val_loss: 0.7726 - val_acc: 0.8955\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.4126 - acc: 0.9361 - val_loss: 0.6183 - val_acc: 0.8982\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.3370 - acc: 0.9397 - val_loss: 0.5280 - val_acc: 0.9182\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3102 - acc: 0.9348 - val_loss: 0.5408 - val_acc: 0.9043\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.2801 - acc: 0.9396 - val_loss: 0.5202 - val_acc: 0.8958\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.2709 - acc: 0.9391 - val_loss: 0.4887 - val_acc: 0.9111\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.2675 - acc: 0.9378 - val_loss: 0.4514 - val_acc: 0.9114\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.2620 - acc: 0.9372 - val_loss: 0.4769 - val_acc: 0.8873\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.2606 - acc: 0.9376 - val_loss: 0.4476 - val_acc: 0.9053\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.2486 - acc: 0.9410 - val_loss: 0.4487 - val_acc: 0.9040\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.2293 - acc: 0.9455 - val_loss: 0.4811 - val_acc: 0.8856\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2293 - acc: 0.9437 - val_loss: 0.4151 - val_acc: 0.9019\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.2244 - acc: 0.9446 - val_loss: 0.4569 - val_acc: 0.8877\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2293 - acc: 0.9404 - val_loss: 0.3932 - val_acc: 0.9125\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2202 - acc: 0.9431 - val_loss: 0.4416 - val_acc: 0.8778\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2229 - acc: 0.9423 - val_loss: 0.4611 - val_acc: 0.8870\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2167 - acc: 0.9434 - val_loss: 0.3924 - val_acc: 0.8941\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2459 - acc: 0.9355 - val_loss: 0.4056 - val_acc: 0.9019\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2239 - acc: 0.9415 - val_loss: 0.4165 - val_acc: 0.8918\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.1976 - acc: 0.9459 - val_loss: 0.3863 - val_acc: 0.9006\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.1961 - acc: 0.9474 - val_loss: 0.3605 - val_acc: 0.9053\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2142 - acc: 0.9388 - val_loss: 0.4033 - val_acc: 0.8850\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.1952 - acc: 0.9483 - val_loss: 0.3589 - val_acc: 0.9023\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2327 - acc: 0.9368 - val_loss: 0.3625 - val_acc: 0.9104\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.1893 - acc: 0.9504 - val_loss: 0.3898 - val_acc: 0.8887\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.1947 - acc: 0.9429 - val_loss: 0.3832 - val_acc: 0.9067\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.1856 - acc: 0.9506 - val_loss: 0.3595 - val_acc: 0.9114\n",
      "Train accuracy 0.9544341675734495 Test accuracy: 0.9114353579911775\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_139 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_70 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,110\n",
      "Trainable params: 68,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 67.8996 - acc: 0.7432 - val_loss: 24.4306 - val_acc: 0.8188\n",
      "Epoch 2/30\n",
      " - 2s - loss: 10.9655 - acc: 0.8953 - val_loss: 3.9665 - val_acc: 0.8649\n",
      "Epoch 3/30\n",
      " - 2s - loss: 1.7413 - acc: 0.9237 - val_loss: 1.0921 - val_acc: 0.8870\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.5724 - acc: 0.9257 - val_loss: 0.7842 - val_acc: 0.8880\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.4326 - acc: 0.9298 - val_loss: 0.6701 - val_acc: 0.8782\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.4042 - acc: 0.9278 - val_loss: 0.6308 - val_acc: 0.8785\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3742 - acc: 0.9295 - val_loss: 0.5984 - val_acc: 0.8972\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.3513 - acc: 0.9321 - val_loss: 0.5696 - val_acc: 0.8843\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.3320 - acc: 0.9313 - val_loss: 0.5557 - val_acc: 0.9057\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.3324 - acc: 0.9310 - val_loss: 0.5364 - val_acc: 0.9009\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.3244 - acc: 0.9301 - val_loss: 0.5411 - val_acc: 0.9023\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.3305 - acc: 0.9294 - val_loss: 0.5092 - val_acc: 0.9152\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.2984 - acc: 0.9385 - val_loss: 0.4965 - val_acc: 0.8965\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.2830 - acc: 0.9382 - val_loss: 0.4861 - val_acc: 0.8856\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2737 - acc: 0.9404 - val_loss: 0.4907 - val_acc: 0.8853\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.3046 - acc: 0.9324 - val_loss: 0.4850 - val_acc: 0.8829\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2844 - acc: 0.9323 - val_loss: 0.4600 - val_acc: 0.8992\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2738 - acc: 0.9362 - val_loss: 0.4696 - val_acc: 0.8816\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2674 - acc: 0.9389 - val_loss: 0.4743 - val_acc: 0.8968\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2862 - acc: 0.9324 - val_loss: 0.4601 - val_acc: 0.9023\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2418 - acc: 0.9448 - val_loss: 0.4581 - val_acc: 0.8870\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2558 - acc: 0.9373 - val_loss: 0.5145 - val_acc: 0.8578\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2639 - acc: 0.9374 - val_loss: 0.4366 - val_acc: 0.8945\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2462 - acc: 0.9400 - val_loss: 0.4139 - val_acc: 0.9013\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2413 - acc: 0.9419 - val_loss: 0.4236 - val_acc: 0.8965\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2530 - acc: 0.9373 - val_loss: 0.4354 - val_acc: 0.8982\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2452 - acc: 0.9377 - val_loss: 0.4397 - val_acc: 0.8856\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2346 - acc: 0.9407 - val_loss: 0.4121 - val_acc: 0.8999\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2428 - acc: 0.9396 - val_loss: 0.4186 - val_acc: 0.8894\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2467 - acc: 0.9366 - val_loss: 0.4019 - val_acc: 0.9040\n",
      "Train accuracy 0.9462731229597389 Test accuracy: 0.9039701391245334\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_141 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 118, 24)           3864      \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_71 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,270\n",
      "Trainable params: 66,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 15.5199 - acc: 0.7844 - val_loss: 2.4015 - val_acc: 0.8880\n",
      "Epoch 2/25\n",
      " - 3s - loss: 0.9192 - acc: 0.9115 - val_loss: 0.7775 - val_acc: 0.8683\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.4096 - acc: 0.9202 - val_loss: 0.6144 - val_acc: 0.8877\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.3681 - acc: 0.9196 - val_loss: 0.5921 - val_acc: 0.9043\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.3259 - acc: 0.9316 - val_loss: 0.5209 - val_acc: 0.8836\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.3377 - acc: 0.9272 - val_loss: 0.5020 - val_acc: 0.8894\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.2968 - acc: 0.9329 - val_loss: 0.5164 - val_acc: 0.8772\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.2822 - acc: 0.9350 - val_loss: 0.4769 - val_acc: 0.8802\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.2743 - acc: 0.9351 - val_loss: 0.4823 - val_acc: 0.8758\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.2813 - acc: 0.9348 - val_loss: 0.4356 - val_acc: 0.8826\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.2667 - acc: 0.9351 - val_loss: 0.4359 - val_acc: 0.9087\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.3117 - acc: 0.9257 - val_loss: 0.4691 - val_acc: 0.8911\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.2724 - acc: 0.9314 - val_loss: 0.5162 - val_acc: 0.8697\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.2854 - acc: 0.9347 - val_loss: 0.4723 - val_acc: 0.8890\n",
      "Epoch 15/25\n",
      " - 3s - loss: 0.2510 - acc: 0.9381 - val_loss: 0.4187 - val_acc: 0.8945\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.2441 - acc: 0.9378 - val_loss: 0.4044 - val_acc: 0.8904\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.2425 - acc: 0.9362 - val_loss: 0.4547 - val_acc: 0.8884\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.2552 - acc: 0.9354 - val_loss: 0.4103 - val_acc: 0.8975\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.2460 - acc: 0.9327 - val_loss: 0.6146 - val_acc: 0.8385\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.2429 - acc: 0.9400 - val_loss: 0.4179 - val_acc: 0.8938\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.2237 - acc: 0.9391 - val_loss: 0.4486 - val_acc: 0.8707\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2403 - acc: 0.9381 - val_loss: 0.3819 - val_acc: 0.8935\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.2235 - acc: 0.9423 - val_loss: 0.3933 - val_acc: 0.8924\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.2319 - acc: 0.9406 - val_loss: 0.4706 - val_acc: 0.8636\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2130 - acc: 0.9475 - val_loss: 0.3838 - val_acc: 0.8955\n",
      "Train accuracy 0.9533460282916213 Test accuracy: 0.8954869358669834\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_143 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 116, 24)           7080      \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 116, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 38, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_72 (Flatten)         (None, 912)               0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 64)                58432     \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,590\n",
      "Trainable params: 68,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 5s - loss: 27.2431 - acc: 0.7874 - val_loss: 3.7998 - val_acc: 0.7923\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.2754 - acc: 0.9078 - val_loss: 0.7984 - val_acc: 0.8870\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4591 - acc: 0.9127 - val_loss: 0.6392 - val_acc: 0.8856\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.3798 - acc: 0.9219 - val_loss: 0.6127 - val_acc: 0.8544\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.3484 - acc: 0.9282 - val_loss: 0.5440 - val_acc: 0.9033\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.3507 - acc: 0.9275 - val_loss: 0.4836 - val_acc: 0.8935\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.3274 - acc: 0.9294 - val_loss: 0.4867 - val_acc: 0.9030\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.2922 - acc: 0.9346 - val_loss: 0.4747 - val_acc: 0.8924\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.2849 - acc: 0.9363 - val_loss: 0.4774 - val_acc: 0.8850\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.2943 - acc: 0.9283 - val_loss: 0.5930 - val_acc: 0.8504\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.2843 - acc: 0.9362 - val_loss: 0.4536 - val_acc: 0.8938\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.2734 - acc: 0.9361 - val_loss: 0.5401 - val_acc: 0.8385\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.2774 - acc: 0.9334 - val_loss: 0.4452 - val_acc: 0.9006\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.3009 - acc: 0.9302 - val_loss: 0.4144 - val_acc: 0.9016\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.2690 - acc: 0.9346 - val_loss: 0.4409 - val_acc: 0.8941\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.2630 - acc: 0.9384 - val_loss: 0.4487 - val_acc: 0.8996\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.3041 - acc: 0.9259 - val_loss: 0.4295 - val_acc: 0.9060\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.2521 - acc: 0.9389 - val_loss: 0.4089 - val_acc: 0.8948\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.2532 - acc: 0.9340 - val_loss: 0.4498 - val_acc: 0.8897\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.2550 - acc: 0.9377 - val_loss: 0.3967 - val_acc: 0.8962\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.2706 - acc: 0.9334 - val_loss: 0.3973 - val_acc: 0.9030\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.2388 - acc: 0.9395 - val_loss: 0.3989 - val_acc: 0.8890\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.2490 - acc: 0.9359 - val_loss: 0.3506 - val_acc: 0.9080\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.3043 - acc: 0.9272 - val_loss: 0.4080 - val_acc: 0.8948\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.2515 - acc: 0.9366 - val_loss: 0.4404 - val_acc: 0.8823\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.2451 - acc: 0.9372 - val_loss: 0.4079 - val_acc: 0.8924\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.2366 - acc: 0.9353 - val_loss: 0.3978 - val_acc: 0.8931\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.2492 - acc: 0.9366 - val_loss: 0.3909 - val_acc: 0.8921\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2677 - acc: 0.9305 - val_loss: 0.4165 - val_acc: 0.8992\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2637 - acc: 0.9305 - val_loss: 0.4102 - val_acc: 0.9019\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.2502 - acc: 0.9377 - val_loss: 0.3708 - val_acc: 0.8948\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2598 - acc: 0.9325 - val_loss: 0.3991 - val_acc: 0.8948\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2349 - acc: 0.9399 - val_loss: 0.3973 - val_acc: 0.8829\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.2256 - acc: 0.9418 - val_loss: 0.3926 - val_acc: 0.8846\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.2524 - acc: 0.9368 - val_loss: 0.3700 - val_acc: 0.8958\n",
      "Train accuracy 0.9503536452665942 Test accuracy: 0.8958262639972854\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_145 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 118, 24)           3864      \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_73 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,270\n",
      "Trainable params: 66,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 34.0518 - acc: 0.7050 - val_loss: 17.5698 - val_acc: 0.8300\n",
      "Epoch 2/30\n",
      " - 3s - loss: 10.0857 - acc: 0.9032 - val_loss: 5.4524 - val_acc: 0.8890\n",
      "Epoch 3/30\n",
      " - 3s - loss: 3.1206 - acc: 0.9195 - val_loss: 1.9977 - val_acc: 0.8897\n",
      "Epoch 4/30\n",
      " - 3s - loss: 1.1367 - acc: 0.9270 - val_loss: 0.9758 - val_acc: 0.8945\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.5683 - acc: 0.9332 - val_loss: 0.6821 - val_acc: 0.8962\n",
      "Epoch 6/30\n",
      " - 3s - loss: 0.4013 - acc: 0.9347 - val_loss: 0.6074 - val_acc: 0.8955\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3439 - acc: 0.9399 - val_loss: 0.5377 - val_acc: 0.8958\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.3169 - acc: 0.9373 - val_loss: 0.4940 - val_acc: 0.9138\n",
      "Epoch 9/30\n",
      " - 3s - loss: 0.3115 - acc: 0.9392 - val_loss: 0.4829 - val_acc: 0.9114\n",
      "Epoch 10/30\n",
      " - 3s - loss: 0.3061 - acc: 0.9348 - val_loss: 0.4744 - val_acc: 0.8982\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.2746 - acc: 0.9427 - val_loss: 0.4870 - val_acc: 0.8856\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.2723 - acc: 0.9416 - val_loss: 0.4525 - val_acc: 0.9141\n",
      "Epoch 13/30\n",
      " - 3s - loss: 0.2656 - acc: 0.9422 - val_loss: 0.4502 - val_acc: 0.9009\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.2523 - acc: 0.9422 - val_loss: 0.4230 - val_acc: 0.9046\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.2580 - acc: 0.9381 - val_loss: 0.4662 - val_acc: 0.9019\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.2454 - acc: 0.9423 - val_loss: 0.4090 - val_acc: 0.9019\n",
      "Epoch 17/30\n",
      " - 3s - loss: 0.2395 - acc: 0.9450 - val_loss: 0.4077 - val_acc: 0.9013\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.2290 - acc: 0.9463 - val_loss: 0.4243 - val_acc: 0.8979\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.2375 - acc: 0.9431 - val_loss: 0.4058 - val_acc: 0.9040\n",
      "Epoch 20/30\n",
      " - 3s - loss: 0.2209 - acc: 0.9471 - val_loss: 0.4012 - val_acc: 0.9125\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.2193 - acc: 0.9453 - val_loss: 0.4056 - val_acc: 0.9087\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.2138 - acc: 0.9479 - val_loss: 0.3649 - val_acc: 0.9104\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.2122 - acc: 0.9498 - val_loss: 0.3880 - val_acc: 0.9053\n",
      "Epoch 24/30\n",
      " - 3s - loss: 0.2126 - acc: 0.9449 - val_loss: 0.3859 - val_acc: 0.9023\n",
      "Epoch 25/30\n",
      " - 3s - loss: 0.2083 - acc: 0.9452 - val_loss: 0.3560 - val_acc: 0.9063\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.2042 - acc: 0.9474 - val_loss: 0.3859 - val_acc: 0.9080\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.2128 - acc: 0.9446 - val_loss: 0.4133 - val_acc: 0.8860\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.1976 - acc: 0.9508 - val_loss: 0.3645 - val_acc: 0.8904\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.2048 - acc: 0.9434 - val_loss: 0.3408 - val_acc: 0.9094\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.1974 - acc: 0.9494 - val_loss: 0.3706 - val_acc: 0.8955\n",
      "Train accuracy 0.941784548422198 Test accuracy: 0.8954869358669834\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_147 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 116, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 116, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 38, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_74 (Flatten)         (None, 912)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 64)                58432     \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,270\n",
      "Trainable params: 66,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 61.7130 - acc: 0.7163 - val_loss: 39.9502 - val_acc: 0.8235\n",
      "Epoch 2/25\n",
      " - 2s - loss: 26.9145 - acc: 0.9070 - val_loss: 17.1180 - val_acc: 0.8626\n",
      "Epoch 3/25\n",
      " - 2s - loss: 11.1822 - acc: 0.9323 - val_loss: 7.0526 - val_acc: 0.8816\n",
      "Epoch 4/25\n",
      " - 2s - loss: 4.4350 - acc: 0.9410 - val_loss: 2.8886 - val_acc: 0.8985\n",
      "Epoch 5/25\n",
      " - 3s - loss: 1.7589 - acc: 0.9382 - val_loss: 1.3239 - val_acc: 0.9002\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.7859 - acc: 0.9387 - val_loss: 0.7564 - val_acc: 0.9019\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.4622 - acc: 0.9396 - val_loss: 0.5795 - val_acc: 0.9030\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3608 - acc: 0.9373 - val_loss: 0.5102 - val_acc: 0.9070\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.3236 - acc: 0.9338 - val_loss: 0.4910 - val_acc: 0.8982\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.2973 - acc: 0.9416 - val_loss: 0.4474 - val_acc: 0.9158\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2789 - acc: 0.9400 - val_loss: 0.5258 - val_acc: 0.8951\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.2746 - acc: 0.9426 - val_loss: 0.4475 - val_acc: 0.9030\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2661 - acc: 0.9382 - val_loss: 0.4392 - val_acc: 0.8968\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2473 - acc: 0.9470 - val_loss: 0.4180 - val_acc: 0.9101\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.2365 - acc: 0.9457 - val_loss: 0.4201 - val_acc: 0.9148\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.2591 - acc: 0.9425 - val_loss: 0.4360 - val_acc: 0.9033\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.2344 - acc: 0.9453 - val_loss: 0.4177 - val_acc: 0.9135\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2348 - acc: 0.9430 - val_loss: 0.3853 - val_acc: 0.9148\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.2208 - acc: 0.9463 - val_loss: 0.3782 - val_acc: 0.9036\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2236 - acc: 0.9464 - val_loss: 0.3845 - val_acc: 0.9070\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.2154 - acc: 0.9474 - val_loss: 0.3696 - val_acc: 0.9016\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2106 - acc: 0.9468 - val_loss: 0.3782 - val_acc: 0.9009\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2072 - acc: 0.9489 - val_loss: 0.3639 - val_acc: 0.9138\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2161 - acc: 0.9450 - val_loss: 0.3698 - val_acc: 0.9050\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2052 - acc: 0.9471 - val_loss: 0.3836 - val_acc: 0.8979\n",
      "Train accuracy 0.9472252448313384 Test accuracy: 0.8978622327790974\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_149 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 120, 24)           3048      \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 60, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_75 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 64)                92224     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 98,350\n",
      "Trainable params: 98,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 7.9329 - acc: 0.8075 - val_loss: 2.5448 - val_acc: 0.8931\n",
      "Epoch 2/25\n",
      " - 2s - loss: 1.1475 - acc: 0.9348 - val_loss: 0.7381 - val_acc: 0.8880\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.3857 - acc: 0.9406 - val_loss: 0.4919 - val_acc: 0.8951\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.2934 - acc: 0.9363 - val_loss: 0.4240 - val_acc: 0.8955\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.2481 - acc: 0.9425 - val_loss: 0.3938 - val_acc: 0.9050\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.2314 - acc: 0.9455 - val_loss: 0.4483 - val_acc: 0.8884\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.2300 - acc: 0.9415 - val_loss: 0.3637 - val_acc: 0.9023\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.2179 - acc: 0.9433 - val_loss: 0.3187 - val_acc: 0.9135\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.1921 - acc: 0.9480 - val_loss: 0.3382 - val_acc: 0.9080\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.1996 - acc: 0.9441 - val_loss: 0.3417 - val_acc: 0.9135\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2079 - acc: 0.9457 - val_loss: 0.3683 - val_acc: 0.8846\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.1995 - acc: 0.9455 - val_loss: 0.3114 - val_acc: 0.9121\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.1842 - acc: 0.9468 - val_loss: 0.3759 - val_acc: 0.8863\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2015 - acc: 0.9415 - val_loss: 0.3607 - val_acc: 0.8836\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.1890 - acc: 0.9476 - val_loss: 0.3487 - val_acc: 0.8941\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.1825 - acc: 0.9467 - val_loss: 0.3341 - val_acc: 0.8914\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.1778 - acc: 0.9474 - val_loss: 0.3169 - val_acc: 0.9094\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.1637 - acc: 0.9524 - val_loss: 0.3113 - val_acc: 0.8958\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.1932 - acc: 0.9438 - val_loss: 0.3447 - val_acc: 0.9043\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.1698 - acc: 0.9512 - val_loss: 0.3818 - val_acc: 0.8901\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.1862 - acc: 0.9449 - val_loss: 0.3214 - val_acc: 0.9104\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.1752 - acc: 0.9487 - val_loss: 0.2967 - val_acc: 0.9148\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.1763 - acc: 0.9464 - val_loss: 0.3132 - val_acc: 0.9074\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.1923 - acc: 0.9436 - val_loss: 0.2900 - val_acc: 0.9125\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.1629 - acc: 0.9540 - val_loss: 0.2942 - val_acc: 0.9040\n",
      "Train accuracy 0.9571545157780196 Test accuracy: 0.9039701391245334\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_151 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 116, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 116, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 38, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_76 (Flatten)         (None, 912)               0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 64)                58432     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,270\n",
      "Trainable params: 66,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 53.3607 - acc: 0.7465 - val_loss: 26.5124 - val_acc: 0.8476\n",
      "Epoch 2/30\n",
      " - 2s - loss: 14.5229 - acc: 0.9174 - val_loss: 6.8551 - val_acc: 0.8846\n",
      "Epoch 3/30\n",
      " - 2s - loss: 3.5500 - acc: 0.9382 - val_loss: 1.8605 - val_acc: 0.8751\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.9814 - acc: 0.9340 - val_loss: 0.8247 - val_acc: 0.8846\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.4950 - acc: 0.9377 - val_loss: 0.6401 - val_acc: 0.8850\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.3723 - acc: 0.9423 - val_loss: 0.5275 - val_acc: 0.8924\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3221 - acc: 0.9460 - val_loss: 0.5195 - val_acc: 0.8880\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.3207 - acc: 0.9414 - val_loss: 0.4919 - val_acc: 0.8914\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.2809 - acc: 0.9453 - val_loss: 0.5103 - val_acc: 0.8744\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.2699 - acc: 0.9449 - val_loss: 0.4766 - val_acc: 0.8853\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.2495 - acc: 0.9467 - val_loss: 0.4222 - val_acc: 0.8968\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.2303 - acc: 0.9471 - val_loss: 0.4444 - val_acc: 0.8748\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.2331 - acc: 0.9461 - val_loss: 0.4088 - val_acc: 0.8999\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.2339 - acc: 0.9444 - val_loss: 0.4471 - val_acc: 0.8968\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2299 - acc: 0.9452 - val_loss: 0.3831 - val_acc: 0.8979\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.2065 - acc: 0.9486 - val_loss: 0.3892 - val_acc: 0.8904\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2369 - acc: 0.9425 - val_loss: 0.3354 - val_acc: 0.9019\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.1894 - acc: 0.9486 - val_loss: 0.3434 - val_acc: 0.9002\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.1980 - acc: 0.9490 - val_loss: 0.3589 - val_acc: 0.8989\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.1857 - acc: 0.9474 - val_loss: 0.3341 - val_acc: 0.9046\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2183 - acc: 0.9461 - val_loss: 0.3572 - val_acc: 0.9125\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.1856 - acc: 0.9476 - val_loss: 0.3455 - val_acc: 0.9016\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.1858 - acc: 0.9491 - val_loss: 0.3610 - val_acc: 0.8979\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.1733 - acc: 0.9505 - val_loss: 0.3228 - val_acc: 0.9006\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.1759 - acc: 0.9495 - val_loss: 0.3542 - val_acc: 0.8836\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.1773 - acc: 0.9498 - val_loss: 0.3418 - val_acc: 0.9026\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.1743 - acc: 0.9479 - val_loss: 0.3195 - val_acc: 0.8907\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.1678 - acc: 0.9489 - val_loss: 0.3111 - val_acc: 0.8938\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.1645 - acc: 0.9516 - val_loss: 0.3460 - val_acc: 0.8941\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.1944 - acc: 0.9472 - val_loss: 0.3964 - val_acc: 0.8700\n",
      "Train accuracy 0.9476332970620239 Test accuracy: 0.8700373260943333\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_153 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 118, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 59, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_77 (Flatten)         (None, 1416)              0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 64)                90688     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 98,830\n",
      "Trainable params: 98,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 39.3390 - acc: 0.7852 - val_loss: 9.5518 - val_acc: 0.8683\n",
      "Epoch 2/25\n",
      " - 2s - loss: 3.4300 - acc: 0.9215 - val_loss: 1.0761 - val_acc: 0.8870\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.5285 - acc: 0.9211 - val_loss: 0.5803 - val_acc: 0.8938\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.3491 - acc: 0.9294 - val_loss: 0.5586 - val_acc: 0.8521\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.3307 - acc: 0.9270 - val_loss: 0.4401 - val_acc: 0.9043\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3070 - acc: 0.9285 - val_loss: 0.4785 - val_acc: 0.8823\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.2950 - acc: 0.9368 - val_loss: 0.4164 - val_acc: 0.8989\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.2775 - acc: 0.9339 - val_loss: 0.4677 - val_acc: 0.9036\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.2881 - acc: 0.9350 - val_loss: 0.4089 - val_acc: 0.9013\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.2454 - acc: 0.9427 - val_loss: 0.3907 - val_acc: 0.9006\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2743 - acc: 0.9357 - val_loss: 0.4031 - val_acc: 0.8975\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.2679 - acc: 0.9313 - val_loss: 0.4272 - val_acc: 0.9043\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2445 - acc: 0.9426 - val_loss: 0.4798 - val_acc: 0.8565\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2356 - acc: 0.9433 - val_loss: 0.3808 - val_acc: 0.8880\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.2688 - acc: 0.9338 - val_loss: 0.3623 - val_acc: 0.9043\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.2403 - acc: 0.9369 - val_loss: 0.3779 - val_acc: 0.8955\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.2883 - acc: 0.9314 - val_loss: 0.4009 - val_acc: 0.9043\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2402 - acc: 0.9403 - val_loss: 0.3530 - val_acc: 0.9118\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.2194 - acc: 0.9440 - val_loss: 0.5464 - val_acc: 0.8358\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2556 - acc: 0.9365 - val_loss: 0.3419 - val_acc: 0.9040\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2263 - acc: 0.9381 - val_loss: 0.3149 - val_acc: 0.9067\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2205 - acc: 0.9423 - val_loss: 0.3553 - val_acc: 0.8982\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2432 - acc: 0.9391 - val_loss: 0.3634 - val_acc: 0.9033\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2298 - acc: 0.9389 - val_loss: 0.3635 - val_acc: 0.8938\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2275 - acc: 0.9415 - val_loss: 0.3519 - val_acc: 0.9094\n",
      "Train accuracy 0.9416485310119695 Test accuracy: 0.9093993892093655\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_155 (Conv1D)          (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 122, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 122, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_78 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 64)                81984     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 86,950\n",
      "Trainable params: 86,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 6s - loss: 23.8866 - acc: 0.8035 - val_loss: 3.8662 - val_acc: 0.8398\n",
      "Epoch 2/35\n",
      " - 2s - loss: 1.3297 - acc: 0.9025 - val_loss: 0.8660 - val_acc: 0.7883\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4738 - acc: 0.9055 - val_loss: 0.6646 - val_acc: 0.8544\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.4083 - acc: 0.9108 - val_loss: 0.5563 - val_acc: 0.8853\n",
      "Epoch 5/35\n",
      " - 3s - loss: 0.3635 - acc: 0.9210 - val_loss: 0.5511 - val_acc: 0.8697\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.3423 - acc: 0.9217 - val_loss: 0.5860 - val_acc: 0.8514\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.3352 - acc: 0.9242 - val_loss: 0.5352 - val_acc: 0.8870\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.3175 - acc: 0.9237 - val_loss: 0.4922 - val_acc: 0.8833\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.3438 - acc: 0.9208 - val_loss: 0.5470 - val_acc: 0.8799\n",
      "Epoch 10/35\n",
      " - 3s - loss: 0.2848 - acc: 0.9342 - val_loss: 0.4420 - val_acc: 0.8880\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.3094 - acc: 0.9259 - val_loss: 0.4420 - val_acc: 0.8982\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.2784 - acc: 0.9362 - val_loss: 0.4529 - val_acc: 0.8744\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.2875 - acc: 0.9302 - val_loss: 0.4532 - val_acc: 0.8700\n",
      "Epoch 14/35\n",
      " - 3s - loss: 0.2624 - acc: 0.9368 - val_loss: 0.4088 - val_acc: 0.8806\n",
      "Epoch 15/35\n",
      " - 3s - loss: 0.2661 - acc: 0.9297 - val_loss: 0.4723 - val_acc: 0.8938\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.2745 - acc: 0.9300 - val_loss: 0.3850 - val_acc: 0.8935\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.2456 - acc: 0.9414 - val_loss: 0.4002 - val_acc: 0.8843\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.2683 - acc: 0.9270 - val_loss: 0.4058 - val_acc: 0.9165\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.2894 - acc: 0.9241 - val_loss: 0.5452 - val_acc: 0.8415\n",
      "Epoch 20/35\n",
      " - 3s - loss: 0.2852 - acc: 0.9327 - val_loss: 0.3998 - val_acc: 0.8806\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.2867 - acc: 0.9266 - val_loss: 0.4374 - val_acc: 0.8975\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.2513 - acc: 0.9381 - val_loss: 0.4121 - val_acc: 0.8931\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.2891 - acc: 0.9266 - val_loss: 0.5593 - val_acc: 0.8514\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.2608 - acc: 0.9391 - val_loss: 0.4083 - val_acc: 0.8829\n",
      "Epoch 25/35\n",
      " - 3s - loss: 0.2454 - acc: 0.9377 - val_loss: 0.3833 - val_acc: 0.9016\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.2512 - acc: 0.9377 - val_loss: 0.3716 - val_acc: 0.9019\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.2449 - acc: 0.9355 - val_loss: 0.4336 - val_acc: 0.8931\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.3009 - acc: 0.9251 - val_loss: 0.4719 - val_acc: 0.8897\n",
      "Epoch 29/35\n",
      " - 3s - loss: 0.2597 - acc: 0.9374 - val_loss: 0.3644 - val_acc: 0.9013\n",
      "Epoch 30/35\n",
      " - 3s - loss: 0.2248 - acc: 0.9425 - val_loss: 0.4016 - val_acc: 0.8856\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.2568 - acc: 0.9372 - val_loss: 0.3657 - val_acc: 0.8921\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2493 - acc: 0.9340 - val_loss: 0.3931 - val_acc: 0.8935\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2489 - acc: 0.9328 - val_loss: 0.4019 - val_acc: 0.8887\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.2609 - acc: 0.9344 - val_loss: 0.3853 - val_acc: 0.9043\n",
      "Epoch 35/35\n",
      " - 3s - loss: 0.2520 - acc: 0.9320 - val_loss: 0.3945 - val_acc: 0.8819\n",
      "Train accuracy 0.9269586507072906 Test accuracy: 0.8819138106549033\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_157 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 116, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 116, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 58, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_79 (Flatten)         (None, 1392)              0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 64)                89152     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 96,990\n",
      "Trainable params: 96,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 11s - loss: 3.1010 - acc: 0.8369 - val_loss: 0.6432 - val_acc: 0.8697\n",
      "Epoch 2/25\n",
      " - 7s - loss: 0.4064 - acc: 0.9317 - val_loss: 0.4303 - val_acc: 0.8982\n",
      "Epoch 3/25\n",
      " - 7s - loss: 0.3341 - acc: 0.9339 - val_loss: 0.4220 - val_acc: 0.9006\n",
      "Epoch 4/25\n",
      " - 7s - loss: 0.2637 - acc: 0.9450 - val_loss: 0.4492 - val_acc: 0.8795\n",
      "Epoch 5/25\n",
      " - 7s - loss: 0.2329 - acc: 0.9448 - val_loss: 0.4092 - val_acc: 0.8806\n",
      "Epoch 6/25\n",
      " - 7s - loss: 0.2239 - acc: 0.9486 - val_loss: 0.3333 - val_acc: 0.9080\n",
      "Epoch 7/25\n",
      " - 7s - loss: 0.2249 - acc: 0.9463 - val_loss: 0.3599 - val_acc: 0.9050\n",
      "Epoch 8/25\n",
      " - 7s - loss: 0.1811 - acc: 0.9514 - val_loss: 0.3340 - val_acc: 0.9101\n",
      "Epoch 9/25\n",
      " - 6s - loss: 0.2069 - acc: 0.9474 - val_loss: 0.3517 - val_acc: 0.9162\n",
      "Epoch 10/25\n",
      " - 7s - loss: 0.1801 - acc: 0.9527 - val_loss: 0.2969 - val_acc: 0.9257\n",
      "Epoch 11/25\n",
      " - 7s - loss: 0.1775 - acc: 0.9512 - val_loss: 0.2882 - val_acc: 0.9128\n",
      "Epoch 12/25\n",
      " - 7s - loss: 0.1835 - acc: 0.9502 - val_loss: 0.3008 - val_acc: 0.9247\n",
      "Epoch 13/25\n",
      " - 7s - loss: 0.2148 - acc: 0.9468 - val_loss: 0.4361 - val_acc: 0.8955\n",
      "Epoch 14/25\n",
      " - 7s - loss: 0.2154 - acc: 0.9494 - val_loss: 0.2789 - val_acc: 0.9125\n",
      "Epoch 15/25\n",
      " - 6s - loss: 0.1705 - acc: 0.9512 - val_loss: 0.3123 - val_acc: 0.9226\n",
      "Epoch 16/25\n",
      " - 7s - loss: 0.1715 - acc: 0.9521 - val_loss: 0.2865 - val_acc: 0.9145\n",
      "Epoch 17/25\n",
      " - 7s - loss: 0.1718 - acc: 0.9513 - val_loss: 0.3066 - val_acc: 0.9237\n",
      "Epoch 18/25\n",
      " - 7s - loss: 0.1798 - acc: 0.9527 - val_loss: 0.2820 - val_acc: 0.9237\n",
      "Epoch 19/25\n",
      " - 7s - loss: 0.1514 - acc: 0.9555 - val_loss: 0.2843 - val_acc: 0.9040\n",
      "Epoch 20/25\n",
      " - 7s - loss: 0.1531 - acc: 0.9533 - val_loss: 0.2990 - val_acc: 0.9114\n",
      "Epoch 21/25\n",
      " - 7s - loss: 0.1976 - acc: 0.9498 - val_loss: 0.2903 - val_acc: 0.9155\n",
      "Epoch 22/25\n",
      " - 7s - loss: 0.1678 - acc: 0.9514 - val_loss: 0.2984 - val_acc: 0.9158\n",
      "Epoch 23/25\n",
      " - 7s - loss: 0.1502 - acc: 0.9540 - val_loss: 0.2735 - val_acc: 0.9145\n",
      "Epoch 24/25\n",
      " - 7s - loss: 0.1489 - acc: 0.9551 - val_loss: 0.3228 - val_acc: 0.9036\n",
      "Epoch 25/25\n",
      " - 7s - loss: 0.1572 - acc: 0.9531 - val_loss: 0.3068 - val_acc: 0.8999\n",
      "Train accuracy 0.9600108813928183 Test accuracy: 0.8998982015609094\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_159 (Conv1D)          (None, 124, 42)           1932      \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 120, 24)           5064      \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_80 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 68,890\n",
      "Trainable params: 68,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 7.7646 - acc: 0.7401 - val_loss: 0.8961 - val_acc: 0.8314\n",
      "Epoch 2/30\n",
      " - 2s - loss: 0.5973 - acc: 0.8629 - val_loss: 0.5856 - val_acc: 0.8636\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.4353 - acc: 0.8972 - val_loss: 0.5480 - val_acc: 0.8931\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.3756 - acc: 0.9066 - val_loss: 0.5384 - val_acc: 0.8575\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.3465 - acc: 0.9121 - val_loss: 0.4354 - val_acc: 0.8789\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.3132 - acc: 0.9249 - val_loss: 0.4131 - val_acc: 0.9019\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3039 - acc: 0.9248 - val_loss: 0.3844 - val_acc: 0.8951\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.2837 - acc: 0.9306 - val_loss: 0.4228 - val_acc: 0.8836\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.2798 - acc: 0.9291 - val_loss: 0.4317 - val_acc: 0.8704\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.2724 - acc: 0.9300 - val_loss: 0.3784 - val_acc: 0.9026\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.2678 - acc: 0.9306 - val_loss: 0.3656 - val_acc: 0.9070\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.2641 - acc: 0.9313 - val_loss: 0.4314 - val_acc: 0.8605\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.2490 - acc: 0.9348 - val_loss: 0.4047 - val_acc: 0.8802\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.2505 - acc: 0.9324 - val_loss: 0.4241 - val_acc: 0.8473\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2669 - acc: 0.9309 - val_loss: 0.3784 - val_acc: 0.8853\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.2618 - acc: 0.9327 - val_loss: 0.3582 - val_acc: 0.8951\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2440 - acc: 0.9359 - val_loss: 0.6121 - val_acc: 0.7682\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2506 - acc: 0.9323 - val_loss: 0.3583 - val_acc: 0.8999\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2377 - acc: 0.9354 - val_loss: 0.3620 - val_acc: 0.8918\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2462 - acc: 0.9321 - val_loss: 0.4097 - val_acc: 0.8724\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2380 - acc: 0.9361 - val_loss: 0.4164 - val_acc: 0.8738\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2316 - acc: 0.9365 - val_loss: 0.3966 - val_acc: 0.8744\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2278 - acc: 0.9381 - val_loss: 0.3601 - val_acc: 0.8972\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2386 - acc: 0.9332 - val_loss: 0.3854 - val_acc: 0.8880\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2288 - acc: 0.9377 - val_loss: 0.4876 - val_acc: 0.8738\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2292 - acc: 0.9370 - val_loss: 0.4004 - val_acc: 0.8704\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2274 - acc: 0.9399 - val_loss: 0.5994 - val_acc: 0.8290\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2203 - acc: 0.9366 - val_loss: 0.5852 - val_acc: 0.7913\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2245 - acc: 0.9351 - val_loss: 0.3735 - val_acc: 0.8785\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2303 - acc: 0.9355 - val_loss: 0.3740 - val_acc: 0.8734\n",
      "Train accuracy 0.9394722524483133 Test accuracy: 0.8734306073973532\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_161 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 116, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 116, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 58, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_81 (Flatten)         (None, 1392)              0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 64)                89152     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 96,990\n",
      "Trainable params: 96,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 54.8862 - acc: 0.6699 - val_loss: 32.6824 - val_acc: 0.7981\n",
      "Epoch 2/25\n",
      " - 3s - loss: 20.6442 - acc: 0.8885 - val_loss: 12.1397 - val_acc: 0.8426\n",
      "Epoch 3/25\n",
      " - 3s - loss: 7.3965 - acc: 0.9223 - val_loss: 4.4355 - val_acc: 0.8721\n",
      "Epoch 4/25\n",
      " - 3s - loss: 2.5925 - acc: 0.9280 - val_loss: 1.7582 - val_acc: 0.8870\n",
      "Epoch 5/25\n",
      " - 3s - loss: 1.0096 - acc: 0.9335 - val_loss: 0.9414 - val_acc: 0.8918\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.5349 - acc: 0.9329 - val_loss: 0.6835 - val_acc: 0.8856\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.3866 - acc: 0.9365 - val_loss: 0.5878 - val_acc: 0.8887\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.3497 - acc: 0.9295 - val_loss: 0.6214 - val_acc: 0.8402\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.3301 - acc: 0.9362 - val_loss: 0.5042 - val_acc: 0.9040\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.2959 - acc: 0.9363 - val_loss: 0.5160 - val_acc: 0.8965\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.2742 - acc: 0.9450 - val_loss: 0.4609 - val_acc: 0.8951\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.2778 - acc: 0.9378 - val_loss: 0.4558 - val_acc: 0.9080\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.2655 - acc: 0.9406 - val_loss: 0.4475 - val_acc: 0.9138\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.2585 - acc: 0.9396 - val_loss: 0.4531 - val_acc: 0.8938\n",
      "Epoch 15/25\n",
      " - 3s - loss: 0.2537 - acc: 0.9408 - val_loss: 0.4117 - val_acc: 0.9057\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.2452 - acc: 0.9426 - val_loss: 0.4380 - val_acc: 0.9091\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.2468 - acc: 0.9403 - val_loss: 0.4145 - val_acc: 0.8985\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.2364 - acc: 0.9442 - val_loss: 0.3822 - val_acc: 0.9121\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.2501 - acc: 0.9381 - val_loss: 0.3974 - val_acc: 0.9111\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.2307 - acc: 0.9441 - val_loss: 0.3797 - val_acc: 0.8975\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.2393 - acc: 0.9400 - val_loss: 0.3906 - val_acc: 0.9084\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.2132 - acc: 0.9460 - val_loss: 0.4179 - val_acc: 0.8758\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.2261 - acc: 0.9430 - val_loss: 0.3617 - val_acc: 0.9114\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.2299 - acc: 0.9400 - val_loss: 0.3604 - val_acc: 0.9006\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.2330 - acc: 0.9404 - val_loss: 0.3658 - val_acc: 0.9080\n",
      "Train accuracy 0.948721436343852 Test accuracy: 0.9080420766881574\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_163 (Conv1D)          (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 122, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 122, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_82 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 64)                81984     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 86,950\n",
      "Trainable params: 86,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 12s - loss: 4.6894 - acc: 0.8033 - val_loss: 0.7175 - val_acc: 0.7815\n",
      "Epoch 2/25\n",
      " - 8s - loss: 0.5004 - acc: 0.8723 - val_loss: 0.7488 - val_acc: 0.8005\n",
      "Epoch 3/25\n",
      " - 8s - loss: 0.4297 - acc: 0.8897 - val_loss: 0.5473 - val_acc: 0.8765\n",
      "Epoch 4/25\n",
      " - 8s - loss: 0.3929 - acc: 0.8985 - val_loss: 0.5836 - val_acc: 0.8622\n",
      "Epoch 5/25\n",
      " - 8s - loss: 0.3985 - acc: 0.8992 - val_loss: 0.5505 - val_acc: 0.8385\n",
      "Epoch 6/25\n",
      " - 8s - loss: 0.3735 - acc: 0.9094 - val_loss: 0.4442 - val_acc: 0.8962\n",
      "Epoch 7/25\n",
      " - 8s - loss: 0.3496 - acc: 0.9144 - val_loss: 0.5137 - val_acc: 0.8711\n",
      "Epoch 8/25\n",
      " - 8s - loss: 0.3579 - acc: 0.9100 - val_loss: 0.4600 - val_acc: 0.8856\n",
      "Epoch 9/25\n",
      " - 8s - loss: 0.3408 - acc: 0.9158 - val_loss: 0.4608 - val_acc: 0.8880\n",
      "Epoch 10/25\n",
      " - 8s - loss: 0.3392 - acc: 0.9149 - val_loss: 0.4807 - val_acc: 0.8487\n",
      "Epoch 11/25\n",
      " - 8s - loss: 0.3717 - acc: 0.9098 - val_loss: 0.4334 - val_acc: 0.8924\n",
      "Epoch 12/25\n",
      " - 8s - loss: 0.3276 - acc: 0.9159 - val_loss: 0.4134 - val_acc: 0.8884\n",
      "Epoch 13/25\n",
      " - 8s - loss: 0.2905 - acc: 0.9253 - val_loss: 0.4337 - val_acc: 0.8680\n",
      "Epoch 14/25\n",
      " - 8s - loss: 0.3297 - acc: 0.9172 - val_loss: 0.4380 - val_acc: 0.8772\n",
      "Epoch 15/25\n",
      " - 8s - loss: 0.3198 - acc: 0.9204 - val_loss: 0.5433 - val_acc: 0.8483\n",
      "Epoch 16/25\n",
      " - 8s - loss: 0.3140 - acc: 0.9240 - val_loss: 0.4682 - val_acc: 0.8884\n",
      "Epoch 17/25\n",
      " - 8s - loss: 0.3221 - acc: 0.9200 - val_loss: 0.4319 - val_acc: 0.8901\n",
      "Epoch 18/25\n",
      " - 8s - loss: 0.3039 - acc: 0.9218 - val_loss: 0.4138 - val_acc: 0.8873\n",
      "Epoch 19/25\n",
      " - 8s - loss: 0.3235 - acc: 0.9196 - val_loss: 0.4169 - val_acc: 0.8918\n",
      "Epoch 20/25\n",
      " - 8s - loss: 0.3038 - acc: 0.9229 - val_loss: 0.3826 - val_acc: 0.8992\n",
      "Epoch 21/25\n",
      " - 8s - loss: 0.3186 - acc: 0.9215 - val_loss: 0.4471 - val_acc: 0.8673\n",
      "Epoch 22/25\n",
      " - 8s - loss: 0.3037 - acc: 0.9257 - val_loss: 0.4678 - val_acc: 0.8694\n",
      "Epoch 23/25\n",
      " - 8s - loss: 0.3028 - acc: 0.9237 - val_loss: 0.4534 - val_acc: 0.8741\n",
      "Epoch 24/25\n",
      " - 8s - loss: 0.3120 - acc: 0.9222 - val_loss: 0.5698 - val_acc: 0.8269\n",
      "Epoch 25/25\n",
      " - 8s - loss: 0.2912 - acc: 0.9283 - val_loss: 0.5051 - val_acc: 0.8286\n",
      "Train accuracy 0.8926822633945644 Test accuracy: 0.8286392941974889\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_165 (Conv1D)          (None, 122, 28)           1792      \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 116, 24)           4728      \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 116, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 58, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_83 (Flatten)         (None, 1392)              0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 64)                89152     \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 96,062\n",
      "Trainable params: 96,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 6s - loss: 12.5170 - acc: 0.7654 - val_loss: 0.9312 - val_acc: 0.7292\n",
      "Epoch 2/35\n",
      " - 2s - loss: 0.5538 - acc: 0.8720 - val_loss: 0.8257 - val_acc: 0.7170\n",
      "Epoch 3/35\n",
      " - 2s - loss: 0.4872 - acc: 0.8890 - val_loss: 0.6864 - val_acc: 0.7991\n",
      "Epoch 4/35\n",
      " - 2s - loss: 0.4289 - acc: 0.8984 - val_loss: 0.6905 - val_acc: 0.7801\n",
      "Epoch 5/35\n",
      " - 2s - loss: 0.4279 - acc: 0.8969 - val_loss: 0.7220 - val_acc: 0.8147\n",
      "Epoch 6/35\n",
      " - 2s - loss: 0.4583 - acc: 0.8961 - val_loss: 0.5878 - val_acc: 0.8602\n",
      "Epoch 7/35\n",
      " - 2s - loss: 0.4092 - acc: 0.9014 - val_loss: 0.6632 - val_acc: 0.8802\n",
      "Epoch 8/35\n",
      " - 2s - loss: 0.3901 - acc: 0.9056 - val_loss: 0.5972 - val_acc: 0.8602\n",
      "Epoch 9/35\n",
      " - 2s - loss: 0.3616 - acc: 0.9165 - val_loss: 0.5125 - val_acc: 0.8863\n",
      "Epoch 10/35\n",
      " - 2s - loss: 0.3666 - acc: 0.9076 - val_loss: 0.5473 - val_acc: 0.8812\n",
      "Epoch 11/35\n",
      " - 2s - loss: 0.3384 - acc: 0.9197 - val_loss: 0.5089 - val_acc: 0.8911\n",
      "Epoch 12/35\n",
      " - 2s - loss: 0.3157 - acc: 0.9234 - val_loss: 0.5284 - val_acc: 0.8683\n",
      "Epoch 13/35\n",
      " - 2s - loss: 0.3310 - acc: 0.9225 - val_loss: 0.4528 - val_acc: 0.8551\n",
      "Epoch 14/35\n",
      " - 2s - loss: 0.3199 - acc: 0.9159 - val_loss: 0.4809 - val_acc: 0.8799\n",
      "Epoch 15/35\n",
      " - 2s - loss: 0.2836 - acc: 0.9295 - val_loss: 0.4308 - val_acc: 0.8853\n",
      "Epoch 16/35\n",
      " - 2s - loss: 0.3236 - acc: 0.9195 - val_loss: 0.4061 - val_acc: 0.9006\n",
      "Epoch 17/35\n",
      " - 2s - loss: 0.2850 - acc: 0.9293 - val_loss: 0.4001 - val_acc: 0.8972\n",
      "Epoch 18/35\n",
      " - 2s - loss: 0.2738 - acc: 0.9310 - val_loss: 0.4429 - val_acc: 0.8999\n",
      "Epoch 19/35\n",
      " - 2s - loss: 0.3175 - acc: 0.9233 - val_loss: 0.4394 - val_acc: 0.8887\n",
      "Epoch 20/35\n",
      " - 2s - loss: 0.2712 - acc: 0.9310 - val_loss: 0.4083 - val_acc: 0.8748\n",
      "Epoch 21/35\n",
      " - 2s - loss: 0.2806 - acc: 0.9293 - val_loss: 0.4338 - val_acc: 0.8823\n",
      "Epoch 22/35\n",
      " - 2s - loss: 0.2759 - acc: 0.9285 - val_loss: 0.5863 - val_acc: 0.8242\n",
      "Epoch 23/35\n",
      " - 2s - loss: 0.2662 - acc: 0.9348 - val_loss: 0.3891 - val_acc: 0.8972\n",
      "Epoch 24/35\n",
      " - 2s - loss: 0.3477 - acc: 0.9207 - val_loss: 0.4052 - val_acc: 0.9009\n",
      "Epoch 25/35\n",
      " - 2s - loss: 0.2614 - acc: 0.9336 - val_loss: 0.4465 - val_acc: 0.8707\n",
      "Epoch 26/35\n",
      " - 2s - loss: 0.2644 - acc: 0.9319 - val_loss: 0.4639 - val_acc: 0.8649\n",
      "Epoch 27/35\n",
      " - 2s - loss: 0.2664 - acc: 0.9325 - val_loss: 0.4462 - val_acc: 0.8592\n",
      "Epoch 28/35\n",
      " - 2s - loss: 0.2705 - acc: 0.9297 - val_loss: 0.4355 - val_acc: 0.8717\n",
      "Epoch 29/35\n",
      " - 2s - loss: 0.2654 - acc: 0.9317 - val_loss: 0.3970 - val_acc: 0.8979\n",
      "Epoch 30/35\n",
      " - 2s - loss: 0.2656 - acc: 0.9317 - val_loss: 0.4432 - val_acc: 0.8867\n",
      "Epoch 31/35\n",
      " - 2s - loss: 0.2974 - acc: 0.9278 - val_loss: 0.3796 - val_acc: 0.8894\n",
      "Epoch 32/35\n",
      " - 2s - loss: 0.2556 - acc: 0.9324 - val_loss: 0.3961 - val_acc: 0.8975\n",
      "Epoch 33/35\n",
      " - 2s - loss: 0.2822 - acc: 0.9291 - val_loss: 0.4347 - val_acc: 0.8853\n",
      "Epoch 34/35\n",
      " - 2s - loss: 0.2478 - acc: 0.9381 - val_loss: 0.3841 - val_acc: 0.8951\n",
      "Epoch 35/35\n",
      " - 2s - loss: 0.2735 - acc: 0.9283 - val_loss: 0.4508 - val_acc: 0.8510\n",
      "Train accuracy 0.919885745375408 Test accuracy: 0.8510349507974211\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_167 (Conv1D)          (None, 124, 42)           1932      \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 122, 24)           3048      \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 122, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_84 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,874\n",
      "Trainable params: 66,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 14.9023 - acc: 0.7428 - val_loss: 1.7944 - val_acc: 0.7350\n",
      "Epoch 2/25\n",
      " - 2s - loss: 0.7719 - acc: 0.8549 - val_loss: 0.6923 - val_acc: 0.8375\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.4564 - acc: 0.8913 - val_loss: 0.6011 - val_acc: 0.8789\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.3951 - acc: 0.9021 - val_loss: 0.5297 - val_acc: 0.8819\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.3669 - acc: 0.9090 - val_loss: 0.5020 - val_acc: 0.8802\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.3349 - acc: 0.9173 - val_loss: 0.4600 - val_acc: 0.8799\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.3227 - acc: 0.9183 - val_loss: 0.4454 - val_acc: 0.8829\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.3061 - acc: 0.9192 - val_loss: 0.4239 - val_acc: 0.8744\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.2907 - acc: 0.9208 - val_loss: 0.5619 - val_acc: 0.8168\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.2821 - acc: 0.9238 - val_loss: 0.4140 - val_acc: 0.8853\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.2773 - acc: 0.9282 - val_loss: 0.4211 - val_acc: 0.8795\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.2723 - acc: 0.9272 - val_loss: 0.4598 - val_acc: 0.8721\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.2641 - acc: 0.9302 - val_loss: 0.4977 - val_acc: 0.8320\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.2656 - acc: 0.9286 - val_loss: 0.4492 - val_acc: 0.8744\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.2545 - acc: 0.9340 - val_loss: 0.3560 - val_acc: 0.9057\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.2544 - acc: 0.9304 - val_loss: 0.4466 - val_acc: 0.8867\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.2561 - acc: 0.9295 - val_loss: 0.3536 - val_acc: 0.9070\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.2553 - acc: 0.9297 - val_loss: 0.3867 - val_acc: 0.9002\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.2501 - acc: 0.9366 - val_loss: 0.4176 - val_acc: 0.8724\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.2461 - acc: 0.9317 - val_loss: 0.3663 - val_acc: 0.8965\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.2415 - acc: 0.9344 - val_loss: 0.3721 - val_acc: 0.8877\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.2360 - acc: 0.9357 - val_loss: 0.5405 - val_acc: 0.7978\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.2358 - acc: 0.9350 - val_loss: 0.3713 - val_acc: 0.9060\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.2462 - acc: 0.9327 - val_loss: 0.3475 - val_acc: 0.9013\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.2335 - acc: 0.9339 - val_loss: 0.3673 - val_acc: 0.8931\n",
      "Train accuracy 0.9468171926006529 Test accuracy: 0.8931116389548693\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_169 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 118, 32)           5152      \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 118, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 39, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_85 (Flatten)         (None, 1248)              0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 64)                79936     \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 87,526\n",
      "Trainable params: 87,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 9s - loss: 6.8475 - acc: 0.8289 - val_loss: 0.7355 - val_acc: 0.8456\n",
      "Epoch 2/30\n",
      " - 6s - loss: 0.4122 - acc: 0.9070 - val_loss: 0.5736 - val_acc: 0.8843\n",
      "Epoch 3/30\n",
      " - 6s - loss: 0.3670 - acc: 0.9120 - val_loss: 0.4935 - val_acc: 0.8941\n",
      "Epoch 4/30\n",
      " - 6s - loss: 0.3390 - acc: 0.9166 - val_loss: 0.4949 - val_acc: 0.8914\n",
      "Epoch 5/30\n",
      " - 6s - loss: 0.3328 - acc: 0.9170 - val_loss: 0.5045 - val_acc: 0.8806\n",
      "Epoch 6/30\n",
      " - 6s - loss: 0.3056 - acc: 0.9278 - val_loss: 0.4981 - val_acc: 0.8829\n",
      "Epoch 7/30\n",
      " - 6s - loss: 0.3170 - acc: 0.9215 - val_loss: 0.4750 - val_acc: 0.8914\n",
      "Epoch 8/30\n",
      " - 5s - loss: 0.2997 - acc: 0.9241 - val_loss: 0.4037 - val_acc: 0.9023\n",
      "Epoch 9/30\n",
      " - 6s - loss: 0.2868 - acc: 0.9270 - val_loss: 0.4186 - val_acc: 0.8931\n",
      "Epoch 10/30\n",
      " - 5s - loss: 0.2933 - acc: 0.9255 - val_loss: 0.3863 - val_acc: 0.8938\n",
      "Epoch 11/30\n",
      " - 6s - loss: 0.2903 - acc: 0.9274 - val_loss: 0.4444 - val_acc: 0.8850\n",
      "Epoch 12/30\n",
      " - 6s - loss: 0.2851 - acc: 0.9276 - val_loss: 0.4318 - val_acc: 0.8741\n",
      "Epoch 13/30\n",
      " - 6s - loss: 0.2883 - acc: 0.9276 - val_loss: 0.4381 - val_acc: 0.9033\n",
      "Epoch 14/30\n",
      " - 6s - loss: 0.2857 - acc: 0.9283 - val_loss: 0.4467 - val_acc: 0.8588\n",
      "Epoch 15/30\n",
      " - 6s - loss: 0.2770 - acc: 0.9317 - val_loss: 0.3837 - val_acc: 0.8755\n",
      "Epoch 16/30\n",
      " - 6s - loss: 0.2766 - acc: 0.9290 - val_loss: 0.4049 - val_acc: 0.8887\n",
      "Epoch 17/30\n",
      " - 6s - loss: 0.2685 - acc: 0.9294 - val_loss: 0.4797 - val_acc: 0.8490\n",
      "Epoch 18/30\n",
      " - 6s - loss: 0.2815 - acc: 0.9280 - val_loss: 0.4360 - val_acc: 0.8846\n",
      "Epoch 19/30\n",
      " - 5s - loss: 0.2594 - acc: 0.9323 - val_loss: 0.4327 - val_acc: 0.8839\n",
      "Epoch 20/30\n",
      " - 6s - loss: 0.2658 - acc: 0.9313 - val_loss: 0.4685 - val_acc: 0.8337\n",
      "Epoch 21/30\n",
      " - 6s - loss: 0.2836 - acc: 0.9259 - val_loss: 0.4454 - val_acc: 0.8660\n",
      "Epoch 22/30\n",
      " - 6s - loss: 0.2625 - acc: 0.9339 - val_loss: 0.4459 - val_acc: 0.8989\n",
      "Epoch 23/30\n",
      " - 6s - loss: 0.3047 - acc: 0.9253 - val_loss: 0.4848 - val_acc: 0.8473\n",
      "Epoch 24/30\n",
      " - 6s - loss: 0.2576 - acc: 0.9361 - val_loss: 0.3768 - val_acc: 0.8975\n",
      "Epoch 25/30\n",
      " - 6s - loss: 0.2795 - acc: 0.9286 - val_loss: 0.3878 - val_acc: 0.8945\n",
      "Epoch 26/30\n",
      " - 6s - loss: 0.2721 - acc: 0.9279 - val_loss: 0.3652 - val_acc: 0.8812\n",
      "Epoch 27/30\n",
      " - 5s - loss: 0.2715 - acc: 0.9328 - val_loss: 0.3949 - val_acc: 0.8918\n",
      "Epoch 28/30\n",
      " - 6s - loss: 0.2571 - acc: 0.9331 - val_loss: 0.4221 - val_acc: 0.8761\n",
      "Epoch 29/30\n",
      " - 6s - loss: 0.2488 - acc: 0.9353 - val_loss: 0.3859 - val_acc: 0.8704\n",
      "Epoch 30/30\n",
      " - 5s - loss: 0.2507 - acc: 0.9334 - val_loss: 0.4119 - val_acc: 0.8612\n",
      "Train accuracy 0.905467899891186 Test accuracy: 0.8612147947064812\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_171 (Conv1D)          (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 118, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 59, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_86 (Flatten)         (None, 1416)              0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 64)                90688     \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 97,950\n",
      "Trainable params: 97,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 15.9475 - acc: 0.8440 - val_loss: 1.1642 - val_acc: 0.8975\n",
      "Epoch 2/25\n",
      " - 3s - loss: 0.5140 - acc: 0.9172 - val_loss: 0.5033 - val_acc: 0.8941\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.3759 - acc: 0.9236 - val_loss: 0.4970 - val_acc: 0.8629\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.3284 - acc: 0.9274 - val_loss: 0.4429 - val_acc: 0.8924\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.3142 - acc: 0.9290 - val_loss: 0.4180 - val_acc: 0.9080\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.2808 - acc: 0.9332 - val_loss: 0.4399 - val_acc: 0.8951\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.2997 - acc: 0.9268 - val_loss: 0.5484 - val_acc: 0.8521\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.2535 - acc: 0.9403 - val_loss: 0.3941 - val_acc: 0.9023\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.2595 - acc: 0.9334 - val_loss: 0.3872 - val_acc: 0.8921\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.3227 - acc: 0.9226 - val_loss: 0.5766 - val_acc: 0.9043\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.3140 - acc: 0.9331 - val_loss: 0.3889 - val_acc: 0.8985\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.2310 - acc: 0.9422 - val_loss: 0.3395 - val_acc: 0.9097\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.2589 - acc: 0.9340 - val_loss: 0.3660 - val_acc: 0.8928\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.2451 - acc: 0.9389 - val_loss: 0.4025 - val_acc: 0.8850\n",
      "Epoch 15/25\n",
      " - 3s - loss: 0.3124 - acc: 0.9294 - val_loss: 0.4006 - val_acc: 0.8846\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.2450 - acc: 0.9374 - val_loss: 0.3918 - val_acc: 0.9013\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.2356 - acc: 0.9410 - val_loss: 0.3284 - val_acc: 0.8975\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.2434 - acc: 0.9376 - val_loss: 0.4164 - val_acc: 0.8965\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.2499 - acc: 0.9389 - val_loss: 0.3804 - val_acc: 0.8894\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.2785 - acc: 0.9362 - val_loss: 0.3768 - val_acc: 0.8772\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.2298 - acc: 0.9425 - val_loss: 0.3490 - val_acc: 0.9084\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.2165 - acc: 0.9414 - val_loss: 0.3712 - val_acc: 0.8962\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.2380 - acc: 0.9406 - val_loss: 0.3505 - val_acc: 0.9006\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.2295 - acc: 0.9412 - val_loss: 0.3346 - val_acc: 0.8989\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.2549 - acc: 0.9343 - val_loss: 0.4912 - val_acc: 0.8761\n",
      "Train accuracy 0.9477693144722524 Test accuracy: 0.8761452324397693\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_173 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 120, 24)           3048      \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_87 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 67,630\n",
      "Trainable params: 67,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 7s - loss: 6.4041 - acc: 0.7979 - val_loss: 0.7415 - val_acc: 0.8646\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.4519 - acc: 0.8988 - val_loss: 0.6598 - val_acc: 0.8541\n",
      "Epoch 3/30\n",
      " - 3s - loss: 0.3949 - acc: 0.9063 - val_loss: 0.5617 - val_acc: 0.8568\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.3700 - acc: 0.9094 - val_loss: 0.5769 - val_acc: 0.8738\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.3228 - acc: 0.9202 - val_loss: 0.4916 - val_acc: 0.8965\n",
      "Epoch 6/30\n",
      " - 3s - loss: 0.3155 - acc: 0.9189 - val_loss: 0.5600 - val_acc: 0.8524\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.3133 - acc: 0.9177 - val_loss: 0.4715 - val_acc: 0.8802\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.3089 - acc: 0.9219 - val_loss: 0.4474 - val_acc: 0.8938\n",
      "Epoch 9/30\n",
      " - 3s - loss: 0.2975 - acc: 0.9208 - val_loss: 0.4962 - val_acc: 0.8880\n",
      "Epoch 10/30\n",
      " - 3s - loss: 0.2819 - acc: 0.9293 - val_loss: 0.4874 - val_acc: 0.8524\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.2846 - acc: 0.9242 - val_loss: 0.4823 - val_acc: 0.8554\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.2776 - acc: 0.9294 - val_loss: 0.4660 - val_acc: 0.8982\n",
      "Epoch 13/30\n",
      " - 3s - loss: 0.2513 - acc: 0.9312 - val_loss: 0.4275 - val_acc: 0.8843\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.2539 - acc: 0.9319 - val_loss: 0.4575 - val_acc: 0.8738\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.2619 - acc: 0.9327 - val_loss: 0.5884 - val_acc: 0.7743\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.2529 - acc: 0.9339 - val_loss: 0.4617 - val_acc: 0.8446\n",
      "Epoch 17/30\n",
      " - 3s - loss: 0.2438 - acc: 0.9343 - val_loss: 0.4071 - val_acc: 0.9030\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.2294 - acc: 0.9396 - val_loss: 0.4409 - val_acc: 0.8561\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.2393 - acc: 0.9342 - val_loss: 0.4331 - val_acc: 0.8660\n",
      "Epoch 20/30\n",
      " - 3s - loss: 0.2593 - acc: 0.9334 - val_loss: 0.4077 - val_acc: 0.8887\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.2261 - acc: 0.9385 - val_loss: 0.5520 - val_acc: 0.7978\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.2192 - acc: 0.9400 - val_loss: 0.5806 - val_acc: 0.7584\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.2232 - acc: 0.9389 - val_loss: 0.4462 - val_acc: 0.8965\n",
      "Epoch 24/30\n",
      " - 3s - loss: 0.2285 - acc: 0.9414 - val_loss: 0.3967 - val_acc: 0.8856\n",
      "Epoch 25/30\n",
      " - 3s - loss: 0.2349 - acc: 0.9388 - val_loss: 0.3968 - val_acc: 0.8853\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.2248 - acc: 0.9393 - val_loss: 0.4679 - val_acc: 0.8751\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.2454 - acc: 0.9380 - val_loss: 0.4199 - val_acc: 0.8941\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.2097 - acc: 0.9418 - val_loss: 0.4381 - val_acc: 0.8442\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.2247 - acc: 0.9385 - val_loss: 0.4897 - val_acc: 0.8548\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.2471 - acc: 0.9351 - val_loss: 0.4025 - val_acc: 0.8843\n",
      "Train accuracy 0.9313112078346029 Test accuracy: 0.8842891075670173\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_175 (Conv1D)          (None, 124, 28)           1288      \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 120, 32)           4512      \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_88 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 129,134\n",
      "Trainable params: 129,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 7s - loss: 47.0935 - acc: 0.7297 - val_loss: 7.2658 - val_acc: 0.6956\n",
      "Epoch 2/25\n",
      " - 3s - loss: 2.5430 - acc: 0.8290 - val_loss: 1.1666 - val_acc: 0.7004\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.6609 - acc: 0.8626 - val_loss: 0.7725 - val_acc: 0.8439\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.5659 - acc: 0.8773 - val_loss: 0.7246 - val_acc: 0.8324\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.5049 - acc: 0.8885 - val_loss: 0.7236 - val_acc: 0.8093\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.5300 - acc: 0.8726 - val_loss: 0.7429 - val_acc: 0.8191\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.4973 - acc: 0.8856 - val_loss: 0.6963 - val_acc: 0.8497\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.4534 - acc: 0.8893 - val_loss: 0.6538 - val_acc: 0.8649\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.4438 - acc: 0.8928 - val_loss: 0.7178 - val_acc: 0.8059\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.4176 - acc: 0.9019 - val_loss: 0.5815 - val_acc: 0.8741\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.4012 - acc: 0.9045 - val_loss: 0.6130 - val_acc: 0.8544\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.4266 - acc: 0.8961 - val_loss: 0.5841 - val_acc: 0.8802\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.4083 - acc: 0.9010 - val_loss: 0.5891 - val_acc: 0.8544\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.3928 - acc: 0.9026 - val_loss: 0.5575 - val_acc: 0.8687\n",
      "Epoch 15/25\n",
      " - 3s - loss: 0.3791 - acc: 0.9070 - val_loss: 0.6087 - val_acc: 0.8361\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.3757 - acc: 0.9064 - val_loss: 0.5359 - val_acc: 0.8548\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.3535 - acc: 0.9094 - val_loss: 0.5105 - val_acc: 0.8799\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.3697 - acc: 0.9094 - val_loss: 0.6789 - val_acc: 0.8198\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.3585 - acc: 0.9100 - val_loss: 0.4999 - val_acc: 0.8836\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.3670 - acc: 0.9059 - val_loss: 0.4836 - val_acc: 0.8816\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.4010 - acc: 0.8980 - val_loss: 0.5057 - val_acc: 0.8683\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.3616 - acc: 0.9071 - val_loss: 0.5459 - val_acc: 0.8677\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.3730 - acc: 0.9087 - val_loss: 0.5147 - val_acc: 0.8690\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.3451 - acc: 0.9129 - val_loss: 0.5736 - val_acc: 0.8643\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.3576 - acc: 0.9100 - val_loss: 0.5336 - val_acc: 0.8599\n",
      "Train accuracy 0.9292709466811752 Test accuracy: 0.8598574821852731\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_177 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 116, 24)           5400      \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 116, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 38, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_89 (Flatten)         (None, 912)               0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 32)                29216     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 36,862\n",
      "Trainable params: 36,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 8s - loss: 3.5413 - acc: 0.7752 - val_loss: 0.5786 - val_acc: 0.8965\n",
      "Epoch 2/35\n",
      " - 4s - loss: 0.4774 - acc: 0.8917 - val_loss: 0.5546 - val_acc: 0.8602\n",
      "Epoch 3/35\n",
      " - 4s - loss: 0.3988 - acc: 0.8979 - val_loss: 0.6636 - val_acc: 0.7628\n",
      "Epoch 4/35\n",
      " - 4s - loss: 0.3867 - acc: 0.8989 - val_loss: 0.4883 - val_acc: 0.8731\n",
      "Epoch 5/35\n",
      " - 4s - loss: 0.3563 - acc: 0.9087 - val_loss: 0.5667 - val_acc: 0.8354\n",
      "Epoch 6/35\n",
      " - 4s - loss: 0.3477 - acc: 0.9076 - val_loss: 0.6794 - val_acc: 0.7995\n",
      "Epoch 7/35\n",
      " - 4s - loss: 0.3332 - acc: 0.9151 - val_loss: 0.4841 - val_acc: 0.8602\n",
      "Epoch 8/35\n",
      " - 4s - loss: 0.3369 - acc: 0.9115 - val_loss: 0.9915 - val_acc: 0.7122\n",
      "Epoch 9/35\n",
      " - 4s - loss: 0.3366 - acc: 0.9119 - val_loss: 0.4709 - val_acc: 0.8639\n",
      "Epoch 10/35\n",
      " - 4s - loss: 0.3364 - acc: 0.9087 - val_loss: 0.4429 - val_acc: 0.8873\n",
      "Epoch 11/35\n",
      " - 4s - loss: 0.3399 - acc: 0.9101 - val_loss: 0.4360 - val_acc: 0.8697\n",
      "Epoch 12/35\n",
      " - 4s - loss: 0.3455 - acc: 0.9101 - val_loss: 0.3995 - val_acc: 0.8826\n",
      "Epoch 13/35\n",
      " - 4s - loss: 0.3320 - acc: 0.9157 - val_loss: 0.4001 - val_acc: 0.8880\n",
      "Epoch 14/35\n",
      " - 4s - loss: 0.3362 - acc: 0.9083 - val_loss: 0.4408 - val_acc: 0.8711\n",
      "Epoch 15/35\n",
      " - 4s - loss: 0.3263 - acc: 0.9153 - val_loss: 0.4200 - val_acc: 0.8911\n",
      "Epoch 16/35\n",
      " - 4s - loss: 0.3398 - acc: 0.9117 - val_loss: 0.5621 - val_acc: 0.7838\n",
      "Epoch 17/35\n",
      " - 4s - loss: 0.3224 - acc: 0.9117 - val_loss: 0.6668 - val_acc: 0.8130\n",
      "Epoch 18/35\n",
      " - 4s - loss: 0.3120 - acc: 0.9193 - val_loss: 0.3908 - val_acc: 0.8907\n",
      "Epoch 19/35\n",
      " - 4s - loss: 0.3382 - acc: 0.9098 - val_loss: 0.4669 - val_acc: 0.8537\n",
      "Epoch 20/35\n",
      " - 4s - loss: 0.3083 - acc: 0.9195 - val_loss: 0.3803 - val_acc: 0.8829\n",
      "Epoch 21/35\n",
      " - 4s - loss: 0.3204 - acc: 0.9154 - val_loss: 0.5205 - val_acc: 0.8327\n",
      "Epoch 22/35\n",
      " - 4s - loss: 0.3271 - acc: 0.9112 - val_loss: 0.4133 - val_acc: 0.8714\n",
      "Epoch 23/35\n",
      " - 4s - loss: 0.3307 - acc: 0.9163 - val_loss: 0.6200 - val_acc: 0.8337\n",
      "Epoch 24/35\n",
      " - 4s - loss: 0.3266 - acc: 0.9123 - val_loss: 1.5387 - val_acc: 0.7044\n",
      "Epoch 25/35\n",
      " - 4s - loss: 0.3280 - acc: 0.9168 - val_loss: 0.4148 - val_acc: 0.8894\n",
      "Epoch 26/35\n",
      " - 4s - loss: 0.3205 - acc: 0.9169 - val_loss: 0.4315 - val_acc: 0.8697\n",
      "Epoch 27/35\n",
      " - 4s - loss: 0.3192 - acc: 0.9136 - val_loss: 0.5011 - val_acc: 0.8429\n",
      "Epoch 28/35\n",
      " - 4s - loss: 0.3146 - acc: 0.9153 - val_loss: 0.4253 - val_acc: 0.8731\n",
      "Epoch 29/35\n",
      " - 4s - loss: 0.3095 - acc: 0.9189 - val_loss: 0.4554 - val_acc: 0.8734\n",
      "Epoch 30/35\n",
      " - 4s - loss: 0.3188 - acc: 0.9177 - val_loss: 0.4661 - val_acc: 0.8887\n",
      "Epoch 31/35\n",
      " - 4s - loss: 0.3238 - acc: 0.9125 - val_loss: 0.4434 - val_acc: 0.8694\n",
      "Epoch 32/35\n",
      " - 4s - loss: 0.3187 - acc: 0.9157 - val_loss: 0.4362 - val_acc: 0.8551\n",
      "Epoch 33/35\n",
      " - 4s - loss: 0.3326 - acc: 0.9166 - val_loss: 0.4552 - val_acc: 0.8751\n",
      "Epoch 34/35\n",
      " - 4s - loss: 0.3079 - acc: 0.9232 - val_loss: 0.5428 - val_acc: 0.8599\n",
      "Epoch 35/35\n",
      " - 4s - loss: 0.3287 - acc: 0.9157 - val_loss: 0.3991 - val_acc: 0.8826\n",
      "Train accuracy 0.9396082698585418 Test accuracy: 0.8825924669155073\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_179 (Conv1D)          (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_180 (Conv1D)          (None, 122, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 122, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 61, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_90 (Flatten)         (None, 976)               0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 64)                62528     \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 65,942\n",
      "Trainable params: 65,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 10s - loss: 11.4304 - acc: 0.8188 - val_loss: 1.3101 - val_acc: 0.8307\n",
      "Epoch 2/25\n",
      " - 6s - loss: 0.5970 - acc: 0.9011 - val_loss: 0.6391 - val_acc: 0.8592\n",
      "Epoch 3/25\n",
      " - 6s - loss: 0.4156 - acc: 0.9037 - val_loss: 0.5854 - val_acc: 0.8690\n",
      "Epoch 4/25\n",
      " - 6s - loss: 0.3665 - acc: 0.9138 - val_loss: 0.5236 - val_acc: 0.8629\n",
      "Epoch 5/25\n",
      " - 5s - loss: 0.3455 - acc: 0.9157 - val_loss: 0.5405 - val_acc: 0.8785\n",
      "Epoch 6/25\n",
      " - 6s - loss: 0.3174 - acc: 0.9266 - val_loss: 0.4695 - val_acc: 0.8744\n",
      "Epoch 7/25\n",
      " - 5s - loss: 0.2955 - acc: 0.9291 - val_loss: 0.4959 - val_acc: 0.8670\n",
      "Epoch 8/25\n",
      " - 6s - loss: 0.2852 - acc: 0.9282 - val_loss: 0.5324 - val_acc: 0.8683\n",
      "Epoch 9/25\n",
      " - 5s - loss: 0.2830 - acc: 0.9295 - val_loss: 0.4038 - val_acc: 0.8938\n",
      "Epoch 10/25\n",
      " - 6s - loss: 0.2774 - acc: 0.9314 - val_loss: 0.4562 - val_acc: 0.8870\n",
      "Epoch 11/25\n",
      " - 6s - loss: 0.2708 - acc: 0.9323 - val_loss: 0.4688 - val_acc: 0.8666\n",
      "Epoch 12/25\n",
      " - 5s - loss: 0.2675 - acc: 0.9304 - val_loss: 0.4663 - val_acc: 0.8928\n",
      "Epoch 13/25\n",
      " - 6s - loss: 0.2492 - acc: 0.9357 - val_loss: 0.4438 - val_acc: 0.8945\n",
      "Epoch 14/25\n",
      " - 6s - loss: 0.2438 - acc: 0.9363 - val_loss: 0.5148 - val_acc: 0.8558\n",
      "Epoch 15/25\n",
      " - 6s - loss: 0.2394 - acc: 0.9368 - val_loss: 0.4394 - val_acc: 0.8646\n",
      "Epoch 16/25\n",
      " - 6s - loss: 0.2444 - acc: 0.9346 - val_loss: 0.4269 - val_acc: 0.8680\n",
      "Epoch 17/25\n",
      " - 6s - loss: 0.2381 - acc: 0.9361 - val_loss: 0.3736 - val_acc: 0.8965\n",
      "Epoch 18/25\n",
      " - 5s - loss: 0.2403 - acc: 0.9369 - val_loss: 0.4352 - val_acc: 0.8958\n",
      "Epoch 19/25\n",
      " - 6s - loss: 0.2276 - acc: 0.9396 - val_loss: 0.5363 - val_acc: 0.8582\n",
      "Epoch 20/25\n",
      " - 6s - loss: 0.2253 - acc: 0.9392 - val_loss: 0.4209 - val_acc: 0.8979\n",
      "Epoch 21/25\n",
      " - 6s - loss: 0.2287 - acc: 0.9391 - val_loss: 0.4006 - val_acc: 0.8880\n",
      "Epoch 22/25\n",
      " - 5s - loss: 0.2349 - acc: 0.9355 - val_loss: 0.4229 - val_acc: 0.8711\n",
      "Epoch 23/25\n",
      " - 6s - loss: 0.2156 - acc: 0.9412 - val_loss: 0.4436 - val_acc: 0.8829\n",
      "Epoch 24/25\n",
      " - 6s - loss: 0.2235 - acc: 0.9416 - val_loss: 0.4468 - val_acc: 0.8846\n",
      "Epoch 25/25\n",
      " - 5s - loss: 0.2299 - acc: 0.9382 - val_loss: 0.4252 - val_acc: 0.8812\n",
      "Train accuracy 0.9428726877040261 Test accuracy: 0.8812351543942993\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_181 (Conv1D)          (None, 122, 42)           2688      \n",
      "_________________________________________________________________\n",
      "conv1d_182 (Conv1D)          (None, 116, 24)           7080      \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 116, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 38, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_91 (Flatten)         (None, 912)               0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 32)                29216     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 39,182\n",
      "Trainable params: 39,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 65.4656 - acc: 0.7164 - val_loss: 20.4675 - val_acc: 0.8402\n",
      "Epoch 2/30\n",
      " - 2s - loss: 8.9991 - acc: 0.8847 - val_loss: 3.2005 - val_acc: 0.8361\n",
      "Epoch 3/30\n",
      " - 2s - loss: 1.4730 - acc: 0.8987 - val_loss: 1.0053 - val_acc: 0.8775\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.5934 - acc: 0.9066 - val_loss: 0.7331 - val_acc: 0.8812\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.4703 - acc: 0.9187 - val_loss: 0.7268 - val_acc: 0.8561\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.4237 - acc: 0.9225 - val_loss: 0.6516 - val_acc: 0.8483\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.3930 - acc: 0.9289 - val_loss: 0.6226 - val_acc: 0.8666\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.3979 - acc: 0.9207 - val_loss: 0.7269 - val_acc: 0.7581\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.3837 - acc: 0.9257 - val_loss: 0.5610 - val_acc: 0.8792\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.3744 - acc: 0.9200 - val_loss: 0.5664 - val_acc: 0.8595\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.3401 - acc: 0.9285 - val_loss: 0.5123 - val_acc: 0.8918\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.3287 - acc: 0.9319 - val_loss: 0.5590 - val_acc: 0.8680\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.3257 - acc: 0.9314 - val_loss: 0.5358 - val_acc: 0.8677\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.3241 - acc: 0.9276 - val_loss: 0.4924 - val_acc: 0.8948\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.3021 - acc: 0.9348 - val_loss: 0.4895 - val_acc: 0.8744\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.3010 - acc: 0.9351 - val_loss: 0.4600 - val_acc: 0.8884\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.3016 - acc: 0.9334 - val_loss: 0.4862 - val_acc: 0.8792\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2983 - acc: 0.9343 - val_loss: 0.4652 - val_acc: 0.8897\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.3004 - acc: 0.9317 - val_loss: 0.4425 - val_acc: 0.8911\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.3095 - acc: 0.9310 - val_loss: 0.4278 - val_acc: 0.8955\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2788 - acc: 0.9365 - val_loss: 0.4826 - val_acc: 0.8734\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2768 - acc: 0.9347 - val_loss: 0.4380 - val_acc: 0.8873\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2662 - acc: 0.9381 - val_loss: 0.4024 - val_acc: 0.8918\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2836 - acc: 0.9327 - val_loss: 0.4422 - val_acc: 0.8884\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2571 - acc: 0.9392 - val_loss: 0.4019 - val_acc: 0.8890\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2722 - acc: 0.9346 - val_loss: 0.4365 - val_acc: 0.8931\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2709 - acc: 0.9348 - val_loss: 0.4078 - val_acc: 0.8948\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2534 - acc: 0.9412 - val_loss: 0.4307 - val_acc: 0.8836\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2928 - acc: 0.9316 - val_loss: 0.4136 - val_acc: 0.8880\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2472 - acc: 0.9412 - val_loss: 0.3809 - val_acc: 0.8989\n",
      "Train accuracy 0.9503536452665942 Test accuracy: 0.8988802171700034\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_183 (Conv1D)          (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_184 (Conv1D)          (None, 120, 16)           2576      \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 60, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_92 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 65,942\n",
      "Trainable params: 65,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 8s - loss: 14.0002 - acc: 0.7871 - val_loss: 0.8703 - val_acc: 0.8347\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.5291 - acc: 0.8794 - val_loss: 0.6603 - val_acc: 0.8531\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.4731 - acc: 0.8837 - val_loss: 0.6648 - val_acc: 0.8242\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.4438 - acc: 0.8921 - val_loss: 0.6187 - val_acc: 0.8592\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.4142 - acc: 0.8979 - val_loss: 0.5915 - val_acc: 0.8480\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.3833 - acc: 0.9047 - val_loss: 0.5314 - val_acc: 0.8680\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.3656 - acc: 0.9078 - val_loss: 0.4996 - val_acc: 0.8717\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.3702 - acc: 0.9076 - val_loss: 0.4927 - val_acc: 0.8768\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.3383 - acc: 0.9155 - val_loss: 0.4732 - val_acc: 0.8717\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.3192 - acc: 0.9191 - val_loss: 0.5551 - val_acc: 0.8334\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.3342 - acc: 0.9123 - val_loss: 0.4763 - val_acc: 0.8816\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.3134 - acc: 0.9184 - val_loss: 0.4811 - val_acc: 0.8748\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.3011 - acc: 0.9218 - val_loss: 0.5402 - val_acc: 0.8185\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.3200 - acc: 0.9178 - val_loss: 0.4299 - val_acc: 0.8904\n",
      "Epoch 15/25\n",
      " - 4s - loss: 0.2990 - acc: 0.9236 - val_loss: 0.4294 - val_acc: 0.8873\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.2887 - acc: 0.9264 - val_loss: 0.5242 - val_acc: 0.8453\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.2784 - acc: 0.9274 - val_loss: 0.4284 - val_acc: 0.8758\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.2831 - acc: 0.9270 - val_loss: 0.5076 - val_acc: 0.8724\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.3172 - acc: 0.9193 - val_loss: 0.4167 - val_acc: 0.8982\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.2692 - acc: 0.9313 - val_loss: 0.3854 - val_acc: 0.8870\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.2656 - acc: 0.9263 - val_loss: 0.3891 - val_acc: 0.8867\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.2806 - acc: 0.9259 - val_loss: 0.4880 - val_acc: 0.8683\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.3071 - acc: 0.9192 - val_loss: 0.3980 - val_acc: 0.8938\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.2985 - acc: 0.9229 - val_loss: 0.4830 - val_acc: 0.8459\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.2700 - acc: 0.9298 - val_loss: 0.4018 - val_acc: 0.8938\n",
      "Train accuracy 0.9440968443960827 Test accuracy: 0.8937902952154734\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_185 (Conv1D)          (None, 122, 28)           1792      \n",
      "_________________________________________________________________\n",
      "conv1d_186 (Conv1D)          (None, 120, 24)           2040      \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_93 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 32)                30752     \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 34,782\n",
      "Trainable params: 34,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 6s - loss: 45.0374 - acc: 0.6583 - val_loss: 3.7365 - val_acc: 0.6742\n",
      "Epoch 2/25\n",
      " - 2s - loss: 1.1796 - acc: 0.7501 - val_loss: 0.9649 - val_acc: 0.7353\n",
      "Epoch 3/25\n",
      " - 2s - loss: 0.6859 - acc: 0.8123 - val_loss: 0.9124 - val_acc: 0.6837\n",
      "Epoch 4/25\n",
      " - 2s - loss: 0.6300 - acc: 0.8271 - val_loss: 0.8109 - val_acc: 0.7950\n",
      "Epoch 5/25\n",
      " - 2s - loss: 0.5839 - acc: 0.8406 - val_loss: 0.6856 - val_acc: 0.8446\n",
      "Epoch 6/25\n",
      " - 2s - loss: 0.5430 - acc: 0.8504 - val_loss: 0.6407 - val_acc: 0.8544\n",
      "Epoch 7/25\n",
      " - 2s - loss: 0.5274 - acc: 0.8547 - val_loss: 0.6374 - val_acc: 0.8463\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.5008 - acc: 0.8652 - val_loss: 0.8488 - val_acc: 0.7465\n",
      "Epoch 9/25\n",
      " - 2s - loss: 0.4984 - acc: 0.8602 - val_loss: 0.6576 - val_acc: 0.8446\n",
      "Epoch 10/25\n",
      " - 2s - loss: 0.4782 - acc: 0.8652 - val_loss: 0.6564 - val_acc: 0.8151\n",
      "Epoch 11/25\n",
      " - 2s - loss: 0.4433 - acc: 0.8799 - val_loss: 0.5606 - val_acc: 0.8660\n",
      "Epoch 12/25\n",
      " - 2s - loss: 0.4360 - acc: 0.8784 - val_loss: 0.5541 - val_acc: 0.8575\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.4313 - acc: 0.8825 - val_loss: 0.5527 - val_acc: 0.8480\n",
      "Epoch 14/25\n",
      " - 2s - loss: 0.4226 - acc: 0.8856 - val_loss: 0.5068 - val_acc: 0.8636\n",
      "Epoch 15/25\n",
      " - 2s - loss: 0.4041 - acc: 0.8898 - val_loss: 0.6078 - val_acc: 0.8551\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.4050 - acc: 0.8936 - val_loss: 0.5353 - val_acc: 0.8670\n",
      "Epoch 17/25\n",
      " - 2s - loss: 0.3961 - acc: 0.8951 - val_loss: 0.4961 - val_acc: 0.8568\n",
      "Epoch 18/25\n",
      " - 2s - loss: 0.3962 - acc: 0.8908 - val_loss: 0.5917 - val_acc: 0.8646\n",
      "Epoch 19/25\n",
      " - 2s - loss: 0.3949 - acc: 0.8946 - val_loss: 0.5251 - val_acc: 0.8463\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.3806 - acc: 0.8955 - val_loss: 0.4659 - val_acc: 0.8823\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.3818 - acc: 0.8988 - val_loss: 0.5506 - val_acc: 0.8188\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.3927 - acc: 0.8939 - val_loss: 0.7946 - val_acc: 0.7801\n",
      "Epoch 23/25\n",
      " - 2s - loss: 0.3684 - acc: 0.9022 - val_loss: 0.4481 - val_acc: 0.8792\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.3731 - acc: 0.9006 - val_loss: 0.4714 - val_acc: 0.8748\n",
      "Epoch 25/25\n",
      " - 2s - loss: 0.3646 - acc: 0.9027 - val_loss: 0.5423 - val_acc: 0.8286\n",
      "Train accuracy 0.8978509249183896 Test accuracy: 0.8286392941974889\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_187 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_188 (Conv1D)          (None, 116, 32)           7200      \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 116, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 38, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_94 (Flatten)         (None, 1216)              0         \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 64)                77888     \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 87,526\n",
      "Trainable params: 87,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/35\n",
      " - 8s - loss: 13.5111 - acc: 0.8187 - val_loss: 1.4059 - val_acc: 0.8809\n",
      "Epoch 2/35\n",
      " - 4s - loss: 0.5501 - acc: 0.9223 - val_loss: 0.6292 - val_acc: 0.8948\n",
      "Epoch 3/35\n",
      " - 4s - loss: 0.3531 - acc: 0.9261 - val_loss: 0.6608 - val_acc: 0.8755\n",
      "Epoch 4/35\n",
      " - 4s - loss: 0.3272 - acc: 0.9283 - val_loss: 0.5381 - val_acc: 0.8904\n",
      "Epoch 5/35\n",
      " - 4s - loss: 0.2936 - acc: 0.9350 - val_loss: 0.4766 - val_acc: 0.8901\n",
      "Epoch 6/35\n",
      " - 4s - loss: 0.2925 - acc: 0.9350 - val_loss: 0.4680 - val_acc: 0.8901\n",
      "Epoch 7/35\n",
      " - 4s - loss: 0.2739 - acc: 0.9373 - val_loss: 0.4565 - val_acc: 0.8887\n",
      "Epoch 8/35\n",
      " - 4s - loss: 0.2658 - acc: 0.9363 - val_loss: 0.4758 - val_acc: 0.8806\n",
      "Epoch 9/35\n",
      " - 4s - loss: 0.2597 - acc: 0.9376 - val_loss: 0.4578 - val_acc: 0.8921\n",
      "Epoch 10/35\n",
      " - 4s - loss: 0.2468 - acc: 0.9389 - val_loss: 0.4329 - val_acc: 0.8924\n",
      "Epoch 11/35\n",
      " - 4s - loss: 0.2795 - acc: 0.9329 - val_loss: 0.4237 - val_acc: 0.8935\n",
      "Epoch 12/35\n",
      " - 4s - loss: 0.2208 - acc: 0.9472 - val_loss: 0.3750 - val_acc: 0.9006\n",
      "Epoch 13/35\n",
      " - 4s - loss: 0.2418 - acc: 0.9402 - val_loss: 0.3963 - val_acc: 0.8962\n",
      "Epoch 14/35\n",
      " - 4s - loss: 0.2316 - acc: 0.9388 - val_loss: 0.3783 - val_acc: 0.8918\n",
      "Epoch 15/35\n",
      " - 4s - loss: 0.2376 - acc: 0.9372 - val_loss: 0.4122 - val_acc: 0.9053\n",
      "Epoch 16/35\n",
      " - 4s - loss: 0.2361 - acc: 0.9368 - val_loss: 0.4057 - val_acc: 0.8717\n",
      "Epoch 17/35\n",
      " - 4s - loss: 0.2291 - acc: 0.9387 - val_loss: 0.3826 - val_acc: 0.8962\n",
      "Epoch 18/35\n",
      " - 4s - loss: 0.2250 - acc: 0.9402 - val_loss: 0.3872 - val_acc: 0.8985\n",
      "Epoch 19/35\n",
      " - 4s - loss: 0.2309 - acc: 0.9382 - val_loss: 0.3794 - val_acc: 0.8911\n",
      "Epoch 20/35\n",
      " - 4s - loss: 0.2487 - acc: 0.9317 - val_loss: 0.4265 - val_acc: 0.8958\n",
      "Epoch 21/35\n",
      " - 4s - loss: 0.2346 - acc: 0.9410 - val_loss: 0.4008 - val_acc: 0.8867\n",
      "Epoch 22/35\n",
      " - 4s - loss: 0.2187 - acc: 0.9427 - val_loss: 0.3837 - val_acc: 0.9002\n",
      "Epoch 23/35\n",
      " - 4s - loss: 0.2490 - acc: 0.9357 - val_loss: 0.3745 - val_acc: 0.8928\n",
      "Epoch 24/35\n",
      " - 4s - loss: 0.2001 - acc: 0.9468 - val_loss: 0.3740 - val_acc: 0.8894\n",
      "Epoch 25/35\n",
      " - 4s - loss: 0.2365 - acc: 0.9369 - val_loss: 0.3419 - val_acc: 0.8985\n",
      "Epoch 26/35\n",
      " - 4s - loss: 0.2291 - acc: 0.9381 - val_loss: 0.3988 - val_acc: 0.8965\n",
      "Epoch 27/35\n",
      " - 4s - loss: 0.2247 - acc: 0.9388 - val_loss: 0.3955 - val_acc: 0.8945\n",
      "Epoch 28/35\n",
      " - 4s - loss: 0.2240 - acc: 0.9395 - val_loss: 0.4063 - val_acc: 0.8785\n",
      "Epoch 29/35\n",
      " - 4s - loss: 0.2066 - acc: 0.9440 - val_loss: 0.3714 - val_acc: 0.8884\n",
      "Epoch 30/35\n",
      " - 4s - loss: 0.2121 - acc: 0.9395 - val_loss: 0.3521 - val_acc: 0.8911\n",
      "Epoch 31/35\n",
      " - 4s - loss: 0.2124 - acc: 0.9436 - val_loss: 0.3807 - val_acc: 0.8819\n",
      "Epoch 32/35\n",
      " - 4s - loss: 0.2256 - acc: 0.9377 - val_loss: 0.4341 - val_acc: 0.8734\n",
      "Epoch 33/35\n",
      " - 4s - loss: 0.2252 - acc: 0.9418 - val_loss: 0.4033 - val_acc: 0.8870\n",
      "Epoch 34/35\n",
      " - 4s - loss: 0.2067 - acc: 0.9452 - val_loss: 0.3971 - val_acc: 0.8945\n",
      "Epoch 35/35\n",
      " - 4s - loss: 0.2113 - acc: 0.9431 - val_loss: 0.3885 - val_acc: 0.8751\n",
      "Train accuracy 0.9287268770402611 Test accuracy: 0.8751272480488632\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_189 (Conv1D)          (None, 124, 42)           1932      \n",
      "_________________________________________________________________\n",
      "conv1d_190 (Conv1D)          (None, 122, 16)           2032      \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 122, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 61, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_95 (Flatten)         (None, 976)               0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 32)                31264     \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 35,426\n",
      "Trainable params: 35,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 101.5560 - acc: 0.6560 - val_loss: 44.9517 - val_acc: 0.7720\n",
      "Epoch 2/30\n",
      " - 2s - loss: 23.1844 - acc: 0.8052 - val_loss: 9.8165 - val_acc: 0.7431\n",
      "Epoch 3/30\n",
      " - 2s - loss: 4.8652 - acc: 0.8617 - val_loss: 2.3456 - val_acc: 0.8297\n",
      "Epoch 4/30\n",
      " - 2s - loss: 1.2572 - acc: 0.8746 - val_loss: 1.0283 - val_acc: 0.8392\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.6465 - acc: 0.8881 - val_loss: 0.7658 - val_acc: 0.8463\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.5241 - acc: 0.8946 - val_loss: 0.7202 - val_acc: 0.8422\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.4840 - acc: 0.8951 - val_loss: 0.6374 - val_acc: 0.8734\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.4620 - acc: 0.8965 - val_loss: 0.7188 - val_acc: 0.8117\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.4430 - acc: 0.8984 - val_loss: 0.6645 - val_acc: 0.8378\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.4339 - acc: 0.9007 - val_loss: 0.6147 - val_acc: 0.8565\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.4076 - acc: 0.9056 - val_loss: 0.5563 - val_acc: 0.8778\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.4180 - acc: 0.9025 - val_loss: 0.5621 - val_acc: 0.8799\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.3738 - acc: 0.9127 - val_loss: 0.5695 - val_acc: 0.8320\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.3912 - acc: 0.9032 - val_loss: 0.5305 - val_acc: 0.8799\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.3719 - acc: 0.9106 - val_loss: 0.5372 - val_acc: 0.8765\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.3717 - acc: 0.9098 - val_loss: 0.5217 - val_acc: 0.8846\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.3756 - acc: 0.9110 - val_loss: 0.5204 - val_acc: 0.8609\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.3356 - acc: 0.9219 - val_loss: 0.4466 - val_acc: 0.8850\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.3470 - acc: 0.9134 - val_loss: 0.4731 - val_acc: 0.8741\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.3342 - acc: 0.9184 - val_loss: 0.4912 - val_acc: 0.8860\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.3280 - acc: 0.9208 - val_loss: 0.4896 - val_acc: 0.8914\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.3140 - acc: 0.9222 - val_loss: 0.4720 - val_acc: 0.8802\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.3299 - acc: 0.9163 - val_loss: 0.4775 - val_acc: 0.8904\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.3059 - acc: 0.9274 - val_loss: 0.5021 - val_acc: 0.8660\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2991 - acc: 0.9253 - val_loss: 0.4421 - val_acc: 0.9009\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.3073 - acc: 0.9253 - val_loss: 0.4416 - val_acc: 0.8907\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.3129 - acc: 0.9202 - val_loss: 0.5320 - val_acc: 0.8558\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.3017 - acc: 0.9290 - val_loss: 0.4403 - val_acc: 0.8996\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.3007 - acc: 0.9267 - val_loss: 0.4520 - val_acc: 0.8979\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2998 - acc: 0.9270 - val_loss: 0.4421 - val_acc: 0.8823\n",
      "Train accuracy 0.9393362350380848 Test accuracy: 0.8822531387852053\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_191 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_192 (Conv1D)          (None, 118, 24)           3864      \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 118, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 39, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_96 (Flatten)         (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 64)                59968     \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,270\n",
      "Trainable params: 66,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 11s - loss: 4.9231 - acc: 0.8377 - val_loss: 0.8762 - val_acc: 0.8985\n",
      "Epoch 2/25\n",
      " - 6s - loss: 0.4481 - acc: 0.9313 - val_loss: 0.5428 - val_acc: 0.8507\n",
      "Epoch 3/25\n",
      " - 7s - loss: 0.3025 - acc: 0.9295 - val_loss: 0.4260 - val_acc: 0.9006\n",
      "Epoch 4/25\n",
      " - 7s - loss: 0.2469 - acc: 0.9410 - val_loss: 0.3910 - val_acc: 0.8931\n",
      "Epoch 5/25\n",
      " - 7s - loss: 0.2328 - acc: 0.9426 - val_loss: 0.3538 - val_acc: 0.9074\n",
      "Epoch 6/25\n",
      " - 7s - loss: 0.2245 - acc: 0.9408 - val_loss: 0.3913 - val_acc: 0.8867\n",
      "Epoch 7/25\n",
      " - 7s - loss: 0.2118 - acc: 0.9434 - val_loss: 0.3481 - val_acc: 0.8972\n",
      "Epoch 8/25\n",
      " - 7s - loss: 0.2128 - acc: 0.9418 - val_loss: 0.3904 - val_acc: 0.8731\n",
      "Epoch 9/25\n",
      " - 7s - loss: 0.2049 - acc: 0.9429 - val_loss: 0.3794 - val_acc: 0.8877\n",
      "Epoch 10/25\n",
      " - 7s - loss: 0.2063 - acc: 0.9400 - val_loss: 0.3409 - val_acc: 0.9121\n",
      "Epoch 11/25\n",
      " - 7s - loss: 0.1903 - acc: 0.9431 - val_loss: 0.3484 - val_acc: 0.8924\n",
      "Epoch 12/25\n",
      " - 7s - loss: 0.1928 - acc: 0.9436 - val_loss: 0.3431 - val_acc: 0.8884\n",
      "Epoch 13/25\n",
      " - 7s - loss: 0.1965 - acc: 0.9434 - val_loss: 0.3697 - val_acc: 0.8948\n",
      "Epoch 14/25\n",
      " - 7s - loss: 0.1908 - acc: 0.9457 - val_loss: 0.3354 - val_acc: 0.8914\n",
      "Epoch 15/25\n",
      " - 7s - loss: 0.1900 - acc: 0.9467 - val_loss: 0.3377 - val_acc: 0.8873\n",
      "Epoch 16/25\n",
      " - 6s - loss: 0.1932 - acc: 0.9421 - val_loss: 0.3192 - val_acc: 0.8962\n",
      "Epoch 17/25\n",
      " - 7s - loss: 0.1807 - acc: 0.9457 - val_loss: 0.3560 - val_acc: 0.8839\n",
      "Epoch 18/25\n",
      " - 7s - loss: 0.2014 - acc: 0.9444 - val_loss: 0.4726 - val_acc: 0.8619\n",
      "Epoch 19/25\n",
      " - 7s - loss: 0.1910 - acc: 0.9456 - val_loss: 0.3210 - val_acc: 0.9097\n",
      "Epoch 20/25\n",
      " - 7s - loss: 0.1807 - acc: 0.9463 - val_loss: 0.3456 - val_acc: 0.9026\n",
      "Epoch 21/25\n",
      " - 7s - loss: 0.1802 - acc: 0.9470 - val_loss: 0.4341 - val_acc: 0.8935\n",
      "Epoch 22/25\n",
      " - 7s - loss: 0.1832 - acc: 0.9484 - val_loss: 0.3219 - val_acc: 0.8924\n",
      "Epoch 23/25\n",
      " - 7s - loss: 0.1814 - acc: 0.9489 - val_loss: 0.3298 - val_acc: 0.8975\n",
      "Epoch 24/25\n",
      " - 7s - loss: 0.1912 - acc: 0.9437 - val_loss: 0.3173 - val_acc: 0.9101\n",
      "Epoch 25/25\n",
      " - 7s - loss: 0.1712 - acc: 0.9514 - val_loss: 0.3109 - val_acc: 0.9030\n",
      "Train accuracy 0.9502176278563657 Test accuracy: 0.9029521547336274\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_193 (Conv1D)          (None, 124, 42)           1932      \n",
      "_________________________________________________________________\n",
      "conv1d_194 (Conv1D)          (None, 118, 16)           4720      \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 118, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 59, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_97 (Flatten)         (None, 944)               0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 32)                30240     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,090\n",
      "Trainable params: 37,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 7s - loss: 20.0633 - acc: 0.7391 - val_loss: 2.1763 - val_acc: 0.8130\n",
      "Epoch 2/25\n",
      " - 3s - loss: 0.8582 - acc: 0.8762 - val_loss: 0.7603 - val_acc: 0.8293\n",
      "Epoch 3/25\n",
      " - 3s - loss: 0.4883 - acc: 0.8893 - val_loss: 0.6756 - val_acc: 0.8171\n",
      "Epoch 4/25\n",
      " - 3s - loss: 0.4394 - acc: 0.8945 - val_loss: 0.5831 - val_acc: 0.8656\n",
      "Epoch 5/25\n",
      " - 3s - loss: 0.4184 - acc: 0.9032 - val_loss: 0.5638 - val_acc: 0.8741\n",
      "Epoch 6/25\n",
      " - 3s - loss: 0.3750 - acc: 0.9139 - val_loss: 0.6264 - val_acc: 0.8575\n",
      "Epoch 7/25\n",
      " - 3s - loss: 0.3726 - acc: 0.9121 - val_loss: 0.5143 - val_acc: 0.8765\n",
      "Epoch 8/25\n",
      " - 3s - loss: 0.3521 - acc: 0.9165 - val_loss: 0.5094 - val_acc: 0.8724\n",
      "Epoch 9/25\n",
      " - 3s - loss: 0.3458 - acc: 0.9158 - val_loss: 0.4961 - val_acc: 0.8734\n",
      "Epoch 10/25\n",
      " - 3s - loss: 0.3458 - acc: 0.9146 - val_loss: 0.5334 - val_acc: 0.8697\n",
      "Epoch 11/25\n",
      " - 3s - loss: 0.3104 - acc: 0.9229 - val_loss: 0.5088 - val_acc: 0.8778\n",
      "Epoch 12/25\n",
      " - 3s - loss: 0.3058 - acc: 0.9242 - val_loss: 0.4776 - val_acc: 0.8704\n",
      "Epoch 13/25\n",
      " - 3s - loss: 0.3059 - acc: 0.9252 - val_loss: 0.4857 - val_acc: 0.8639\n",
      "Epoch 14/25\n",
      " - 3s - loss: 0.3034 - acc: 0.9293 - val_loss: 0.4869 - val_acc: 0.8751\n",
      "Epoch 15/25\n",
      " - 3s - loss: 0.3074 - acc: 0.9226 - val_loss: 0.4195 - val_acc: 0.8884\n",
      "Epoch 16/25\n",
      " - 3s - loss: 0.2977 - acc: 0.9253 - val_loss: 0.4551 - val_acc: 0.8826\n",
      "Epoch 17/25\n",
      " - 3s - loss: 0.2872 - acc: 0.9302 - val_loss: 0.4481 - val_acc: 0.9030\n",
      "Epoch 18/25\n",
      " - 3s - loss: 0.2909 - acc: 0.9286 - val_loss: 0.5166 - val_acc: 0.8646\n",
      "Epoch 19/25\n",
      " - 3s - loss: 0.2792 - acc: 0.9308 - val_loss: 0.4778 - val_acc: 0.8670\n",
      "Epoch 20/25\n",
      " - 3s - loss: 0.2778 - acc: 0.9286 - val_loss: 0.4626 - val_acc: 0.8782\n",
      "Epoch 21/25\n",
      " - 3s - loss: 0.2897 - acc: 0.9279 - val_loss: 0.5614 - val_acc: 0.8310\n",
      "Epoch 22/25\n",
      " - 3s - loss: 0.2848 - acc: 0.9266 - val_loss: 0.4592 - val_acc: 0.8548\n",
      "Epoch 23/25\n",
      " - 3s - loss: 0.2725 - acc: 0.9323 - val_loss: 0.4801 - val_acc: 0.8392\n",
      "Epoch 24/25\n",
      " - 3s - loss: 0.2913 - acc: 0.9271 - val_loss: 0.4791 - val_acc: 0.8856\n",
      "Epoch 25/25\n",
      " - 3s - loss: 0.2956 - acc: 0.9301 - val_loss: 0.4798 - val_acc: 0.8649\n",
      "Train accuracy 0.9468171926006529 Test accuracy: 0.8649474041398032\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_195 (Conv1D)          (None, 122, 28)           1792      \n",
      "_________________________________________________________________\n",
      "conv1d_196 (Conv1D)          (None, 120, 24)           2040      \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_98 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 65,726\n",
      "Trainable params: 65,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 8.3842 - acc: 0.7356 - val_loss: 1.2760 - val_acc: 0.8602\n",
      "Epoch 2/30\n",
      " - 2s - loss: 0.6686 - acc: 0.8787 - val_loss: 0.6373 - val_acc: 0.8907\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.4356 - acc: 0.9079 - val_loss: 0.5604 - val_acc: 0.8649\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.3612 - acc: 0.9134 - val_loss: 0.4945 - val_acc: 0.8755\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.3316 - acc: 0.9169 - val_loss: 0.3994 - val_acc: 0.9053\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.3078 - acc: 0.9223 - val_loss: 0.3707 - val_acc: 0.9104\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.2969 - acc: 0.9257 - val_loss: 0.4432 - val_acc: 0.8707\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.2853 - acc: 0.9271 - val_loss: 0.3801 - val_acc: 0.8924\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.2797 - acc: 0.9272 - val_loss: 0.4271 - val_acc: 0.8744\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.2716 - acc: 0.9282 - val_loss: 0.4296 - val_acc: 0.8670\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.2632 - acc: 0.9334 - val_loss: 0.5736 - val_acc: 0.8327\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.2748 - acc: 0.9286 - val_loss: 0.3467 - val_acc: 0.9186\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.2599 - acc: 0.9310 - val_loss: 0.3441 - val_acc: 0.8992\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.2646 - acc: 0.9295 - val_loss: 0.3369 - val_acc: 0.9203\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.2677 - acc: 0.9298 - val_loss: 0.3484 - val_acc: 0.9040\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.2497 - acc: 0.9336 - val_loss: 0.3331 - val_acc: 0.9019\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.2481 - acc: 0.9327 - val_loss: 0.3384 - val_acc: 0.8941\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.2477 - acc: 0.9335 - val_loss: 0.3527 - val_acc: 0.9040\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.2343 - acc: 0.9366 - val_loss: 0.3344 - val_acc: 0.9036\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.2463 - acc: 0.9359 - val_loss: 0.3297 - val_acc: 0.8982\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.2494 - acc: 0.9347 - val_loss: 0.3404 - val_acc: 0.9057\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.2552 - acc: 0.9304 - val_loss: 0.3234 - val_acc: 0.9087\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.2522 - acc: 0.9353 - val_loss: 0.3195 - val_acc: 0.8962\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.2428 - acc: 0.9331 - val_loss: 0.3441 - val_acc: 0.8914\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.2451 - acc: 0.9323 - val_loss: 0.4233 - val_acc: 0.8639\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.2443 - acc: 0.9325 - val_loss: 0.3649 - val_acc: 0.8901\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.2268 - acc: 0.9385 - val_loss: 0.3710 - val_acc: 0.8728\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.2675 - acc: 0.9327 - val_loss: 0.3127 - val_acc: 0.9019\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.2410 - acc: 0.9368 - val_loss: 0.3636 - val_acc: 0.8897\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.2271 - acc: 0.9384 - val_loss: 0.3242 - val_acc: 0.9013\n",
      "Train accuracy 0.9357997823721437 Test accuracy: 0.9012555140821175\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_197 (Conv1D)          (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_198 (Conv1D)          (None, 120, 16)           2576      \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 120, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 40, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_99 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 32)                20512     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 24,758\n",
      "Trainable params: 24,758\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      " - 9s - loss: 4.5669 - acc: 0.7935 - val_loss: 0.8646 - val_acc: 0.8656\n",
      "Epoch 2/25\n",
      " - 4s - loss: 0.4426 - acc: 0.9064 - val_loss: 0.5971 - val_acc: 0.8748\n",
      "Epoch 3/25\n",
      " - 5s - loss: 0.3473 - acc: 0.9214 - val_loss: 0.5384 - val_acc: 0.8819\n",
      "Epoch 4/25\n",
      " - 5s - loss: 0.3153 - acc: 0.9227 - val_loss: 0.5751 - val_acc: 0.8578\n",
      "Epoch 5/25\n",
      " - 4s - loss: 0.2910 - acc: 0.9291 - val_loss: 0.5726 - val_acc: 0.8276\n",
      "Epoch 6/25\n",
      " - 4s - loss: 0.2886 - acc: 0.9325 - val_loss: 0.4760 - val_acc: 0.8853\n",
      "Epoch 7/25\n",
      " - 5s - loss: 0.2862 - acc: 0.9293 - val_loss: 0.4660 - val_acc: 0.8918\n",
      "Epoch 8/25\n",
      " - 4s - loss: 0.2534 - acc: 0.9365 - val_loss: 0.4801 - val_acc: 0.8714\n",
      "Epoch 9/25\n",
      " - 5s - loss: 0.2551 - acc: 0.9380 - val_loss: 0.4702 - val_acc: 0.8795\n",
      "Epoch 10/25\n",
      " - 5s - loss: 0.2356 - acc: 0.9374 - val_loss: 0.4707 - val_acc: 0.8707\n",
      "Epoch 11/25\n",
      " - 4s - loss: 0.2498 - acc: 0.9328 - val_loss: 0.4411 - val_acc: 0.8853\n",
      "Epoch 12/25\n",
      " - 4s - loss: 0.2408 - acc: 0.9373 - val_loss: 0.4557 - val_acc: 0.8744\n",
      "Epoch 13/25\n",
      " - 5s - loss: 0.2391 - acc: 0.9388 - val_loss: 0.4413 - val_acc: 0.8609\n",
      "Epoch 14/25\n",
      " - 4s - loss: 0.2460 - acc: 0.9351 - val_loss: 0.4033 - val_acc: 0.8795\n",
      "Epoch 15/25\n",
      " - 5s - loss: 0.2366 - acc: 0.9380 - val_loss: 0.3867 - val_acc: 0.8921\n",
      "Epoch 16/25\n",
      " - 4s - loss: 0.2438 - acc: 0.9358 - val_loss: 0.4143 - val_acc: 0.8802\n",
      "Epoch 17/25\n",
      " - 5s - loss: 0.2167 - acc: 0.9416 - val_loss: 0.4161 - val_acc: 0.8639\n",
      "Epoch 18/25\n",
      " - 5s - loss: 0.2247 - acc: 0.9377 - val_loss: 0.3815 - val_acc: 0.8914\n",
      "Epoch 19/25\n",
      " - 4s - loss: 0.2324 - acc: 0.9393 - val_loss: 0.4458 - val_acc: 0.8717\n",
      "Epoch 20/25\n",
      " - 4s - loss: 0.2228 - acc: 0.9407 - val_loss: 0.4284 - val_acc: 0.8802\n",
      "Epoch 21/25\n",
      " - 5s - loss: 0.2199 - acc: 0.9406 - val_loss: 0.5000 - val_acc: 0.8191\n",
      "Epoch 22/25\n",
      " - 4s - loss: 0.2427 - acc: 0.9357 - val_loss: 0.4173 - val_acc: 0.8921\n",
      "Epoch 23/25\n",
      " - 5s - loss: 0.2445 - acc: 0.9347 - val_loss: 0.3632 - val_acc: 0.8955\n",
      "Epoch 24/25\n",
      " - 5s - loss: 0.2191 - acc: 0.9425 - val_loss: 0.4164 - val_acc: 0.8982\n",
      "Epoch 25/25\n",
      " - 4s - loss: 0.2149 - acc: 0.9446 - val_loss: 0.5544 - val_acc: 0.8432\n",
      "Train accuracy 0.899619151186502 Test accuracy: 0.8432304038004751\n",
      "-------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_199 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_200 (Conv1D)          (None, 120, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_100 (Flatten)        (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 128,486\n",
      "Trainable params: 128,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      " - 7s - loss: 30.5532 - acc: 0.7618 - val_loss: 2.2024 - val_acc: 0.8246\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.8391 - acc: 0.8853 - val_loss: 0.8323 - val_acc: 0.8035\n",
      "Epoch 3/30\n",
      " - 3s - loss: 0.5331 - acc: 0.8849 - val_loss: 0.7406 - val_acc: 0.8147\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.4779 - acc: 0.9004 - val_loss: 0.6211 - val_acc: 0.8778\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.4147 - acc: 0.9128 - val_loss: 0.5577 - val_acc: 0.8792\n",
      "Epoch 6/30\n",
      " - 3s - loss: 0.4284 - acc: 0.9057 - val_loss: 0.6300 - val_acc: 0.8334\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.3658 - acc: 0.9218 - val_loss: 0.5696 - val_acc: 0.8660\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.4054 - acc: 0.9089 - val_loss: 0.5670 - val_acc: 0.8371\n",
      "Epoch 9/30\n",
      " - 3s - loss: 0.3656 - acc: 0.9154 - val_loss: 0.5273 - val_acc: 0.8904\n",
      "Epoch 10/30\n",
      " - 3s - loss: 0.3714 - acc: 0.9166 - val_loss: 0.5122 - val_acc: 0.8812\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.3268 - acc: 0.9274 - val_loss: 0.5266 - val_acc: 0.8660\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.3229 - acc: 0.9298 - val_loss: 0.4563 - val_acc: 0.9026\n",
      "Epoch 13/30\n",
      " - 3s - loss: 0.3243 - acc: 0.9245 - val_loss: 0.5118 - val_acc: 0.8945\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.3167 - acc: 0.9264 - val_loss: 0.4692 - val_acc: 0.8792\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.3177 - acc: 0.9264 - val_loss: 0.5565 - val_acc: 0.8677\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.3127 - acc: 0.9290 - val_loss: 0.4644 - val_acc: 0.8938\n",
      "Epoch 17/30\n",
      " - 3s - loss: 0.2869 - acc: 0.9319 - val_loss: 0.4130 - val_acc: 0.9023\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.2899 - acc: 0.9289 - val_loss: 0.4489 - val_acc: 0.8938\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.3160 - acc: 0.9229 - val_loss: 0.4860 - val_acc: 0.8843\n",
      "Epoch 20/30\n",
      " - 3s - loss: 0.3489 - acc: 0.9193 - val_loss: 0.5221 - val_acc: 0.8683\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.3036 - acc: 0.9339 - val_loss: 0.5230 - val_acc: 0.8537\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.3286 - acc: 0.9260 - val_loss: 0.4599 - val_acc: 0.8887\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.2815 - acc: 0.9335 - val_loss: 0.4687 - val_acc: 0.8768\n",
      "Epoch 24/30\n",
      " - 3s - loss: 0.2894 - acc: 0.9331 - val_loss: 0.4849 - val_acc: 0.8636\n",
      "Epoch 25/30\n",
      " - 3s - loss: 0.2874 - acc: 0.9340 - val_loss: 0.4531 - val_acc: 0.8755\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.2595 - acc: 0.9376 - val_loss: 0.4596 - val_acc: 0.8758\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.2937 - acc: 0.9287 - val_loss: 0.4175 - val_acc: 0.9050\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.2621 - acc: 0.9381 - val_loss: 0.4344 - val_acc: 0.8819\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.2722 - acc: 0.9325 - val_loss: 0.4049 - val_acc: 0.8887\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.2669 - acc: 0.9340 - val_loss: 0.3827 - val_acc: 0.9145\n",
      "Train accuracy 0.9525299238302503 Test accuracy: 0.9144893111638955\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = data_scaled()\n",
    "trials = Trials()\n",
    "best_run, best_model, space = optim.minimize(model=model_cnn,\n",
    "                                      data=data_scaled,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=100,\n",
    "                                      trials=trials,notebook_name = 'Human Activity Recognition',\n",
    "                                      return_space = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperas.utils import eval_hyperopt_space\n",
    "total_trials = dict()\n",
    "total_list = []\n",
    "for t, trial in enumerate(trials):\n",
    "        vals = trial.get('misc').get('vals')\n",
    "        z = eval_hyperopt_space(space, vals)\n",
    "        total_trials['M'+str(t+1)] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense': 1,\n",
       " 'Dropout': 0.6397045095598795,\n",
       " 'batch_size': 2,\n",
       " 'choiceval': 0,\n",
       " 'filters': 1,\n",
       " 'filters_1': 1,\n",
       " 'kernel_size': 2,\n",
       " 'kernel_size_1': 0,\n",
       " 'l2': 0.07999281751224634,\n",
       " 'l2_1': 0.0012673510937627475,\n",
       " 'lr': 0.0011215010543928203,\n",
       " 'lr_1': 0.0021517590741381726,\n",
       " 'nb_epoch': 0,\n",
       " 'pool_size': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense': 64,\n",
       " 'Dropout': 0.6397045095598795,\n",
       " 'batch_size': 64,\n",
       " 'choiceval': 'adam',\n",
       " 'filters': 32,\n",
       " 'filters_1': 24,\n",
       " 'kernel_size': 7,\n",
       " 'kernel_size_1': 3,\n",
       " 'l2': 0.07999281751224634,\n",
       " 'l2_1': 0.0012673510937627475,\n",
       " 'lr': 0.0011215010543928203,\n",
       " 'lr_1': 0.0021517590741381726,\n",
       " 'nb_epoch': 25,\n",
       " 'pool_size': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best Hyper params from hyperas\n",
    "eval_hyperopt_space(space, best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_119 (Conv1D)          (None, 122, 32)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 120, 24)           2328      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 120, 24)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 40, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_60 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 66,270\n",
      "Trainable params: 66,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_accuracy 0.963139281828074 test_accuracy 0.9229725144214456\n"
     ]
    }
   ],
   "source": [
    "_,acc_val = best_model.evaluate(X_val,Y_val,verbose=0)\n",
    "_,acc_train = best_model.evaluate(X_train,Y_train,verbose=0)\n",
    "print('Train_accuracy',acc_train,'test_accuracy',acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[537   0   0   0   0   0]\n",
      " [  0 385  81   0   0  25]\n",
      " [  0  80 452   0   0   0]\n",
      " [  0   0   0 484  10   2]\n",
      " [  0   0   0   0 415   5]\n",
      " [  0   1   0   0  23 447]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix_rnn(Y_val, best_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f2465d4da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f24226c4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f234cbe860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAIxCAYAAABaRiKwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f23a53af60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "cm = confusion_matrix_rnn(Y_val, best_model.predict(X_val))\n",
    "plot_confusion_matrix(cm, classes=labels, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Greens)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
